{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9c895fb-bd91-4c9c-be14-6a3d9e6ed799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30686/3210334984.py:6: DeprecationWarning: OpenAI is deprecated and will be removed in a future release. Please use DynamicString instead.\n",
      "  llm = RBIOpenAI(key=key, client_id=client_id)\n"
     ]
    }
   ],
   "source": [
    "from aa_llm_utils.llms.openai import RBIOpenAI\n",
    "\n",
    "client_id = \"dc-pj2kzmc9fsuvmouyfta3ehqqm\"\n",
    "key = {\"d\": \"AdVmOnx2tYXVcUy20b2Gb2TgkjG7zTN-NGlc4HeiIFJ2y70SrczXzzu2vRCF6jNmeMnb_dF4kG3eANNuY-kCDQDxdEEW_Sb9crCBD7ypko8uMSDzYniwhFaDlIfPagQbEe2xnen4jm-jjQN01n8crBjt2nNWeY8VNjwizBdFfyej9o1sHHnSpgrZZ5plO0wEo232IbUSjuAmzyebRmZKFrZriBtoXnkCRGSu9Ps960hCTNwg7Q2B29p54-37nV7I968BGP9TN24xxCfEH-cZSnM86BKSXBiJUdkTMNsrMzQlBtGv2busm8OThgpz1lShHxZnpwkBoLwKOqgrmZ0rsQ\", \"dp\": \"WAE8eVJRjU0nDsb99W5kLUbihsM0R2QtNKz0-RJ8ki6vldnhp-msMHl2oYwxxqwYqW4EO0H1TDg2bzUB5LfUnbK1_LOjmNQr5vVm7yH611k3kjkkEWpzNe56zLQqfeLrDUi5A7oboPsK4WKcpVC3O2k-PQNHEsyjkY8XQJl4JF0\", \"dq\": \"PGl3DzCwiOaIUgy8lhTjjZdQtBBD93WJ9tiqi4koMM1OXD9Bbd-ZMv-Z0QkYS73FAMYFCGynwJcVVAs9XF4gIfx42aud0anRqxhEfcuwxmsQNg1z2RQPZZmq6fGF6RoJITHKR3VHrgVxeOfijqAif51VDmxtPumaXroVrWREYKE\", \"e\": \"AQAB\", \"kty\": \"RSA\", \"n\": \"qUxpRdukrLznYO5ezWorwW3Ykayc3aBtB9nNKDfBqThzV3Mz49cILbRk-nfOM2Z0faF_oZm1hdFp7MC-xUh6xkqbOrIvHjdTfI5x6a72RRYgkkPYjR5vmYKac-oNNbXOYoVINTrQUpcvoG0n32C4FjerPIQxX7SJ0QXIQDkf9uUavg1hsBVcfHXQPLQhcjWimP3x3bHYfWopPUA9OW81UnjuD6nzGs4yF6XIPL9iid_iBvBAQZzvNlgoQRO0Wfuxr1-vbjgrv_OneA69WEvHe_BzChI1kKlmp1OPltg5ZgfykwvUlGhSTbn0P8vTGNm6nMrX5wBUW0exWIVZnXKqvw\", \"p\": \"0xilmyIAaKEM6S0AGQByMfz2XVa8blehos9i8di8yarTr6irXt8mkTV-KeP1m5LuFKN2FuH3QBWc3Nu2QfEO8x6i1y6SBbtrnNfIuTrESivgsyf0ji5nogTERQbLfhLcVzYfViy009GP8SKEtlkOHK0Er_C_MxmQaIQojKC3egc\", \"q\": \"zU-k_lm8sGOiOzi_M3l2trSghCDRG6-Ei5WaogHa2vSSeSUWNhIKwsj_h9FlHY00mpBn2E2HovOZjnpB1w1jWn3-Rq8DoLtidh9S-J8SWQxathsAI8nzEL2vBAqeRp-muhrPHEwHelwSCE1BPcrOxaPFvrSXmDmvSnQjJVsXe4k\", \"qi\": \"m7PxMw6LTYERSjJ-_1-yjRWP6-DGI3ZZjRZt4r_C3uNbhsOui4cw7Lt_B46gzNxCtnSBAQWpQHg0xduGuKNnf6FzjfRD8YdLJR_WUoSeCB7Du3D0jgHBNntXNDNkDIJtPZflzkgqmrRTA2Vsld7qr0DRqYqrqpGyV0g-qdGaFWE\", \"kid\": \"42bae44e-6061-45e1-8572-bd7aae3ef26d\"}\n",
    "\n",
    "llm = RBIOpenAI(key=key, client_id=client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "239b846e-5a55-44b9-8a1a-ee28aa237636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pydantic import BaseModel, Field, computed_field, TypeAdapter\n",
    "from itertools import chain\n",
    "from devtools import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "agent_prompt = \"\"\"\n",
    "You are a top of the line chat agent trying to provide comprehensive and useful answers to your users.\n",
    "Always remember that you have tools available and use them if appropriate.\n",
    "If you are not sure about details regarding a user question you can ask the user for additional input.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class History(BaseModel):\n",
    "    messages: list[dict] = Field(default_factory=list, description=\"List of messages in the conversation.\")\n",
    "\n",
    "    def add_system_message(self, content: str):\n",
    "        self.messages.append({\"role\": \"system\", \"cotnent\": content})\n",
    "    \n",
    "    def add_user_message(self, content: str):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "    def add_tool_message(self, tool_call_id: str, content: str):\n",
    "        self.messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call_id, \"content\": content})\n",
    "\n",
    "history = History()\n",
    "\n",
    "\n",
    "\n",
    "f_get_delivery_date = {\n",
    "    \"name\": \"get_delivery_date\",\n",
    "    \"description\":  (\n",
    "        \"Get the delivery date for a customer's order.\"\n",
    "        \"Call this whenever you need to know the delivery date of a package, for example when a customer asks 'What is the delivery date of my package'\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"order_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The customer's order ID.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"order_id\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "f_get_delivery_status = {\n",
    "    \"name\": \"get_delivery_status\",\n",
    "    \"description\":  (\n",
    "        \"Get the delivery status for a customer's order.\"\n",
    "        \"Call this whenever you need to know the delivery status of a package, for example when a customer asks 'What is the delivery status of my package'\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"order_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The customer's order ID.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"order_id\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "tools= [\n",
    "    {\n",
    "        \"type\": \"function\", \n",
    "        \"function\": f_get_delivery_date\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": f_get_delivery_status\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def get_delivery_status(order_id: str) -> str:\n",
    "    return \"in transport\"\n",
    "\n",
    "\n",
    "def get_delivery_date(order_id: str) -> str:\n",
    "    return str(datetime.now())\n",
    "\n",
    "actual_tools = {\n",
    "    \"get_delivery_date\": get_delivery_date,\n",
    "    \"get_delivery_status\": get_delivery_status\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, llm: RBIOpenAI):\n",
    "        self.llm = llm\n",
    "\n",
    "    def process_user_message(self, content: str, messages: list[dict]) -> dict:\n",
    "        history = History(messages=messages)\n",
    "        history.add_user_message(content)\n",
    "        choice = self.do_model_call(history)\n",
    "        return self.handle_choice(choice, history)[\"message\"]\n",
    "\n",
    "    def handle_choice(self, choice: dict, history) -> dict:\n",
    "        if \"finish_reason\" in choice and choice[\"finish_reason\"] == \"tool_calls\":\n",
    "            choice = self.handle_tool_calls(choice, history)\n",
    "            return self.handle_choice(choice, history)\n",
    "        else:\n",
    "            return choice\n",
    "        \n",
    "    def handle_tool_calls(self, choice: dict, history: History) -> dict:\n",
    "        message = choice[\"message\"]\n",
    "        history.messages.append(message)\n",
    "        tool_calls = message[\"tool_calls\"]\n",
    "        for tool_call in tool_calls:\n",
    "            call_id = tool_call[\"id\"]\n",
    "            function = tool_call[\"function\"]\n",
    "            name = function[\"name\"]\n",
    "            arguments = json.loads(function[\"arguments\"])\n",
    "            print(f\"CALLING: {name} with {arguments!r}\")\n",
    "            result = actual_tools[name](*arguments)\n",
    "            history.add_tool_message(call_id, result)\n",
    "\n",
    "        return self.do_model_call(history)\n",
    "\n",
    "\n",
    "    def do_model_call(self, history) -> dict:\n",
    "        response = self.llm.chat.completions.create(\n",
    "            messages=history.messages,\n",
    "            model=\"gpt-4o\",\n",
    "            tools=tools\n",
    "        )\n",
    "        return response.choices[0].dict()\n",
    "        \n",
    "\n",
    "def assemble_tool_call_message(stream) -> dict:\n",
    "    calls = {}\n",
    "    for choice in stream:\n",
    "        delta = choice[\"delta\"]\n",
    "        if delta[\"tool_calls\"] is not None:\n",
    "            for tool_call in delta[\"tool_calls\"]:\n",
    "                idx = tool_call[\"index\"]\n",
    "                if idx not in calls:\n",
    "                    calls[idx] = {\"name\": tool_call[\"function\"][\"name\"], \"arguments\": tool_call[\"function\"][\"arguments\"], \"id\": tool_call[\"id\"]}\n",
    "                else:\n",
    "                    calls[idx][\"arguments\"] += tool_call[\"function\"][\"arguments\"]\n",
    "    \n",
    "    return  {\n",
    "        \"content\": None, \"role\": \"assistant\", \"function_call\": None, \n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": c[\"id\"], \"function\": {\"name\": c[\"name\"], \"arguments\": c[\"arguments\"]}, \"type\": \"function\"\n",
    "            } for c in calls.values()\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "class StreamAgent:\n",
    "    def __init__(self, llm: RBIOpenAI):\n",
    "        self.llm = llm\n",
    "\n",
    "    def process_user_message(self, content: str, messages: list[dict]):\n",
    "        history = History(messages=messages)\n",
    "        history.add_user_message(content)\n",
    "        response = self.do_model_call(history)\n",
    "        yield from self.handle_stream(response, history)\n",
    "\n",
    "    def _get_choice(self, chunk) -> dict:\n",
    "        return chunk.choices[0].dict()\n",
    "\n",
    "\n",
    "    def handle_tool_calls(self, message: dict, history: History) -> dict:\n",
    "        history.messages.append(message)\n",
    "        tool_calls = message[\"tool_calls\"]\n",
    "        for tool_call in tool_calls:\n",
    "            call_id = tool_call[\"id\"]\n",
    "            function = tool_call[\"function\"]\n",
    "            name = function[\"name\"]\n",
    "            arguments = json.loads(function[\"arguments\"])\n",
    "            print(f\"CALLING: {name} with {arguments!r}\")\n",
    "            result = actual_tools[name](*arguments)\n",
    "            history.add_tool_message(call_id, result)\n",
    "\n",
    "        return self.do_model_call(history)\n",
    "\n",
    "    \n",
    "    def handle_stream(self, response, history: History):\n",
    "        start = self._get_choice(next(response))\n",
    "        if \"tool_calls\" in start[\"delta\"] and start[\"delta\"][\"tool_calls\"] is not None:\n",
    "            tool_call_message = assemble_tool_call_message(chain([start], map(self._get_choice, response)))\n",
    "            tool_response = self.handle_tool_calls(tool_call_message, history)\n",
    "            yield from self.handle_stream(tool_response, history)\n",
    "        else:\n",
    "            yield start\n",
    "            yield from map(self._get_choice, response)\n",
    "\n",
    "    \n",
    "    def do_model_call(self, history) -> dict:\n",
    "        response = self.llm.chat.completions.create(\n",
    "            messages=history.messages,\n",
    "            model=\"gpt-4o\",\n",
    "            tools=tools,\n",
    "            stream=True\n",
    "        )\n",
    "        return response\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": agent_prompt},\n",
    "]\n",
    "\n",
    "# agent = Agent(llm)\n",
    "# m = agent.process_user_message(\"Tell me the delivery date my order\", messages)\n",
    "# print(m)\n",
    "# messages.append(m)\n",
    "# m = agent.process_user_message(\"My order id is 123badger\", messages)\n",
    "# print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e54df9a8-a1aa-4e5e-8e51-02a0210f9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING: get_delivery_date with {'order_id': '124badger'}\n",
      "CALLING: get_delivery_status with {'order_id': '124badger'}\n",
      "Your order with ID \"124badger\" is currently **in transport** and the estimated delivery date is **October 2, 2024**.None"
     ]
    }
   ],
   "source": [
    "agent = StreamAgent(llm)\n",
    "for r in agent.process_user_message(\"Tell me the delivery date and status of my order 124badger\", messages):\n",
    "    print(r.get(\"delta\", {}).get(\"content\", \"\"), end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e246e-9892-48c3-81a7-dca65a011481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
