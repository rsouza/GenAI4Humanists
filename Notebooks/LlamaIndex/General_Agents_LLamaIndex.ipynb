{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0L5n3kwNdj9"
   },
   "source": [
    "# Agents with LlamaIndex II - \n",
    "\n",
    "Sources [1](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/), [2](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/agents/), [3](https://docs.llamaindex.ai/en/stable/examples/agent/custom_agent/), [4](https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent/), [5](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner/), [6](https://medium.com/llamaindex-blog/data-agents-eed797d7972f), [LlamaHub Tools](https://llamahub.ai/?tab=tools)  \n",
    "    \n",
    "--- \n",
    "### Agents\n",
    "\n",
    "An \"agent\" is an automated reasoning and decision engine. It takes in a user input/query and can make internal decisions for executing that query in order to return the correct result. The key agent components can include, but are not limited to:\n",
    "\n",
    "+ Breaking down a complex question into smaller ones\n",
    "+ Choosing an external Tool to use + coming up with parameters for calling the Tool\n",
    "+ Planning out a set of tasks\n",
    "+ Storing previously completed tasks in a memory module\n",
    "\n",
    "LlamaIndex provides a comprehensive framework for building agents. This includes the following components:\n",
    "\n",
    "+ Using agents with tools at a high-level to build agentic RAG and workflow automation use cases **(Previous Notebook)**\n",
    "+ Low-level components for building and debugging agents\n",
    "+ Core agent ingredients that can be used as standalone modules: query planning, tool use, and more **(Previous Notebook)**\n",
    "\n",
    "### Tools\n",
    "\n",
    "Having proper tool abstractions is at the core of building data agents. Defining a set of Tools is similar to defining any API interface, with the exception that these Tools are meant for agent rather than human use. We allow users to define both a Tool as well as a ToolSpec containing a series of functions under the hood.\n",
    "\n",
    "When using an agent or LLM with function calling, the tool selected (and the arguments written for that tool) rely strongly on the tool name and description of the tools purpose and arguments. Spending time tuning these parameters can result in larges changes in how the LLM calls these tools.\n",
    "\n",
    "A Tool implements a very generic interface - simply define __call__ and also return some basic metadata (name, description, function schema).\n",
    "LlamaIndex offer a few different types of Tools:\n",
    "\n",
    "+ FunctionTool: A function tool allows users to easily convert any user-defined function into a Tool. It can also auto-infer the function schema. **(Previous Notebook)**\n",
    "+ QueryEngineTool: A tool that wraps an existing query engine. Note: since our agent abstractions inherit from BaseQueryEngine, these tools can also wrap other agents. **(Previous Notebook)**\n",
    "+ Community contributed ToolSpecs that define one or more tools around a single service (like Gmail): see [LlamaHub](https://llamahub.ai/)\n",
    "+ Utility tools for wrapping other tools to handle returning large amounts of data from a tool: see [OnDemandLoaderTool](https://docs.llamaindex.ai/en/stable/examples/tools/OnDemandLoaderTool/)\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "The scope of possible use cases for agents is vast and ever-expanding. That said, here are some practical use cases that can deliver immediate value.\n",
    "\n",
    "+ Agentic RAG: Build a context-augmented research assistant over your data that not only answers simple questions, but complex research tasks. (Previous Notebook)\n",
    "+ SQL Agent: A subset of the above is a \"text-to-SQL assistant\" that can interact with a structured database. \n",
    "+ Workflow Assistant: Build an agent that can operate over common workflow tools like email, calendar.\n",
    "+ Coding Assistant: Build an agent that can operate over code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyWM-ThgNdj_"
   },
   "source": [
    "## Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76369,
     "status": "ok",
     "timestamp": 1714682800048,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "1hOqc6qhNdkA",
    "outputId": "2e5cf4da-cc0e-40ae-8d26-ed5ca7e07f60"
   },
   "outputs": [],
   "source": [
    "#%pip install -qU openai\n",
    "#%pip install -qU llama-index\n",
    "#%pip install -qU llama_hub\n",
    "#%pip install -qU llama-index-experimental\n",
    "#%pip install llama-index-agent-openai\n",
    "#%pip install llama-index-readers-web\n",
    "#%pip install llama-index-tools-google\n",
    "\n",
    "\n",
    "#!pip install -q pypdf\n",
    "#!pip install -q docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG6gzO4zNdkB"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2T8UKZJNNdkC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<the key>\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import llama_index\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "## Llamaindex readers\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "## LlamaIndex Index Types\n",
    "from llama_index.core import ListIndex\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import TreeIndex\n",
    "from llama_index.core import KeywordTableIndex\n",
    "from llama_index.core import SimpleKeywordTableIndex\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "\n",
    "## LlamaIndex Context Managers\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.schema import Node\n",
    "\n",
    "## LlamaIndex Templates\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "## LlamaIndex Agents\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "## LlamaIndex Callbacks\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UlTWP4TITXbv"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "#model=\"gpt-4o\"\n",
    "model=\"gpt-4o-mini\"\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.llm = OpenAI(temperature=0, \n",
    "                      model=model, \n",
    "                      #max_tokens=512\n",
    "                      PRESENCE_PENALTY=-2,\n",
    "                      TOP_P=1,\n",
    "                     )\n",
    "\n",
    "llm = Settings.llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Function Tool  \n",
    "A function tool is a simple wrapper around any existing function (both sync and async are supported!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def subtract(x: int, y: int) -> int: \n",
    "    \"\"\"Subtract the second number from the first number.\"\"\"\n",
    "    return (x - y)\n",
    "\n",
    "def multiply(x: int, y: int) -> int: \n",
    "    \"\"\"Multiply one number by the other number.\"\"\"\n",
    "    return (x * y)\n",
    "\n",
    "def uppercase(x: str) -> str: \n",
    "    \"\"\"Return the input string in uppercase.\"\"\"\n",
    "    return (x.upper())\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "uppercase_tool = FunctionTool.from_defaults(fn=uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: subtract with args: {\"x\": 3, \"y\": 12}\n",
      "=== Function Output ===\n",
      "-9\n",
      "-9\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [add_tool, subtract_tool, multiply_tool, uppercase_tool], \n",
    "    \"Tell me the output of 3 - 12 \", \n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- [Coding Assistant and Interpreter](https://llamahub.ai/l/tools/llama-index-tools-code-interpreter?from=)  \n",
    "[Github](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-code-interpreter/examples/code_interpreter.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-code_interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.code_interpreter import CodeInterpreterToolSpec\n",
    "\n",
    "code_spec = CodeInterpreterToolSpec()\n",
    "tools = code_spec.to_tool_list()\n",
    "agent = OpenAIAgent.from_tools(tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you help me write some python code to pass to the code_interpreter tool\n",
      "Sure, I'd be happy to help. What would you like the Python code to do?\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Can you help me write some python code to pass to the code_interpreter tool\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: There is a california_housing_train.csv file in the `../Data` directory (relative path).\n",
      "                 Can you write and execute code to tell me its columns?\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\n",
      "  \"code\": \"import pandas as pd\\n\\n# Load the data\\nfile_path = '../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Get the column names\\ncolumns = data.columns.tolist()\\n\\n# Print the column names\\ncolumns\"\n",
      "}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\n",
      "  \"code\": \"import pandas as pd\\n\\n# Load the data\\nfile_path = '../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Get the column names\\ncolumns = data.columns.tolist()\\n\\n# Print the column names\\nprint(columns)\"\n",
      "}\n",
      "Got output: StdOut:\n",
      "b\"['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\\n\"\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "The columns in the `california_housing_train.csv` file are:\n",
      "\n",
      "1. longitude\n",
      "2. latitude\n",
      "3. housing_median_age\n",
      "4. total_rooms\n",
      "5. total_bedrooms\n",
      "6. population\n",
      "7. households\n",
      "8. median_income\n",
      "9. median_house_value\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\n",
    "        \"\"\"There is a california_housing_train.csv file in the `../Data` directory (relative path).\n",
    "                 Can you write and execute code to tell me its columns?\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: In which country are these latitudes and longitudes?\n",
      "The dataset is named `california_housing_train.csv`, which suggests that the latitudes and longitudes are likely from locations within the state of California, United States.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"In which country are these latitudes and longitudes?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you make a graph of the median income per total rooms?\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\n",
      "  \"code\": \"import matplotlib.pyplot as plt\\n\\n# Calculate median income per total rooms\\ndata['income_per_room'] = data['median_income'] / data['total_rooms']\\n\\n# Create a plot\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['income_per_room'])\\nplt.title('Median Income per Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income per Room')\\n\\n# Save the plot\\nplt.savefig('income_per_room.png')\\n\\n# Print a message\\n'Plot saved as income_per_room.png'\"\n",
      "}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b'Traceback (most recent call last):\\n  File \"<string>\", line 4, in <module>\\nNameError: name \\'data\\' is not defined\\n'\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\n",
      "  \"code\": \"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the data\\nfile_path = '../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Calculate median income per total rooms\\ndata['income_per_room'] = data['median_income'] / data['total_rooms']\\n\\n# Create a plot\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['income_per_room'])\\nplt.title('Median Income per Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income per Room')\\n\\n# Save the plot\\nplt.savefig('income_per_room.png')\\n\\n# Print a message\\n'Plot saved as income_per_room.png'\"\n",
      "}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\n",
      "  \"code\": \"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the data\\nfile_path = '../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Calculate median income per total rooms\\ndata['income_per_room'] = data['median_income'] / data['total_rooms']\\n\\n# Create a plot\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['income_per_room'])\\nplt.title('Median Income per Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income per Room')\\n\\n# Save the plot\\nplt.savefig('income_per_room.png')\\n\\n# Print a message\\nprint('Plot saved as income_per_room.png')\"\n",
      "}\n",
      "Got output: StdOut:\n",
      "b'Plot saved as income_per_room.png\\n'\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "The plot of Median Income per Total Rooms has been created and saved as 'income_per_room.png'. Please check the file in your local directory.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Can you make a graph of the median income per total rooms?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: I cant see the plot - can you save it locally with file name `output.png`?\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\n",
      "  \"code\": \"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the data\\nfile_path = '../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Calculate median income per total rooms\\ndata['income_per_room'] = data['median_income'] / data['total_rooms']\\n\\n# Create a plot\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['income_per_room'])\\nplt.title('Median Income per Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income per Room')\\n\\n# Save the plot\\nplt.savefig('output.png')\\n\\n# Print a message\\nprint('Plot saved as output.png')\"\n",
      "}\n",
      "Got output: StdOut:\n",
      "b'Plot saved as output.png\\n'\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "The plot of Median Income per Total Rooms has been created and saved as 'output.png'. Please check the file in your local directory.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"I cant see the plot - can you save it locally with file name `output.png`?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- [SQL Agent](https://llamahub.ai/l/tools/llama-index-tools-database?from=)  \n",
    "[GitHub](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-database/examples/database.ipynb), [article](https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-database\n",
    "%pip install -q sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.database import DatabaseToolSpec\n",
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    insert,\n",
    "    text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SQL Database   \n",
    "\n",
    "We first define our SQLDatabase abstraction (a light wrapper around SQLAlchemy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add some testing data to our SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Chicago\", \"population\": 2679000, \"country\": \"United States\",},\n",
    "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Chicago', 2679000, 'United States'), ('Seoul', 9776000, 'South Korea')]\n"
     ]
    }
   ],
   "source": [
    "# view current table\n",
    "stmt = select(\n",
    "    city_stats_table.c.city_name,\n",
    "    city_stats_table.c.population,\n",
    "    city_stats_table.c.country,\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Index  \n",
    "We first show how we can execute a raw SQL query, which directly executes over the table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chicago',)\n",
      "('Seoul',)\n",
      "('Tokyo',)\n",
      "('Toronto',)\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Text-to-SQL Query Engine¶\n",
    "\n",
    "Once we have constructed our SQL database, we can use the NLSQLTableQueryEngine to construct natural language queries that are synthesized into SQL queries.\n",
    "\n",
    "Note that we need to specify the tables we want to use with this query engine. If we don't the query engine will pull all the schema context, which could overflow the context window of the LLM.\n",
    "\n",
    "This query engine should be used in any case where you can specify the tables you want to query over beforehand, or the total size of all the table schema plus the rest of the prompt fits your context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database, tables=[\"city_stats\"], llm=llm\n",
    ")\n",
    "query_str = \"Which city has the highest population?\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The city with the highest population is Tokyo, with a population of 13,960,000.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Query-Time Retrieval of Tables for Text-to-SQL\n",
    "\n",
    "If we don't know ahead of time which table we would like to use, and the total size of the table schema overflows your context window size, we should store the table schema in an index so that during query time we can retrieve the right schema.\n",
    "\n",
    "The way we can do this is using the SQLTableNodeMapping object, which takes in a SQLDatabase and produces a Node object for each SQLTableSchema object passed into the ObjectIndex constructor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "#from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\"))\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can take our SQLTableRetrieverQueryEngine and query it for our response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The city with the highest population is Tokyo, with a population of 13,960,000.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Which city has the highest population?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tokyo', 13960000)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also fetch the raw result from SQLAlchemy!\n",
    "response.metadata[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You could also add additional context information for each table schema you define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set context text\n",
    "city_stats_text = (\n",
    "    \"This table gives information regarding the population and country of a\"\n",
    "    \" given city.\\nThe user will query with codewords, where 'foo' corresponds\"\n",
    "    \" to population and 'bar'corresponds to city.\"\n",
    ")\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\", context_str=city_stats_text))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Text-to-SQL Retriever\n",
    "\n",
    "So far our text-to-SQL capability is packaged in a query engine and consists of both retrieval and synthesis.\n",
    "\n",
    "You can use the SQL retriever on its own. We show you some different parameters you can try, and also show how to plug it into our RetrieverQueryEngine to get roughly the same results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import NLSQLRetriever\n",
    "\n",
    "# default retrieval (return_raw=True)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"city_stats\"], return_raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nl_sql_retriever.retrieve(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** a81d44d2-d88b-44bd-9746-66207d36cc6d<br>**Similarity:** None<br>**Text:** [('Tokyo', 13960000), ('Seoul', 9776000), ('Toronto', 2930000), ('Chicago', 2679000)]<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for n in results:\n",
    "    display_source_node(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default retrieval (return_raw=False)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"city_stats\"], return_raw=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = nl_sql_retriever.retrieve(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 74b280e8-be46-4b94-8306-c38ed4f21e9b<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Tokyo', 'population': 13960000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 81f913d9-5b29-42db-832b-2f5c3af96cb0<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Seoul', 'population': 9776000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8775e81d-d11c-4415-9fb8-b93bfdc8eaae<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Toronto', 'population': 2930000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d3f2acb6-f546-4f17-83f5-5869bcc00bd6<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Chicago', 'population': 2679000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: all the content is in the metadata\n",
    "for n in results:\n",
    "    display_source_node(n, show_source_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plug into our RetrieverQueryEngine\n",
    "\n",
    "We compose our SQL Retriever with our standard RetrieverQueryEngine to synthesize a response. The result is roughly similar to our packaged Text-to-SQL query engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tokyo - 13,960,000\n",
      "2. Seoul - 9,776,000\n",
      "3. Toronto - 2,930,000\n",
      "4. Chicago - 2,679,000\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Database Tool\n",
    "\n",
    "This tool connects to a database (using SQLAlchemy under the hood) and allows an Agent to query the database and get information about the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This database contains a table named 'city_stats'.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_tools = DatabaseToolSpec(sql_database)\n",
    "agent = OpenAIAgent.from_tools(db_tools.to_tool_list())\n",
    "\n",
    "agent.chat(\"What tables does this database contain\").response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'city_stats' table has the following structure:\n",
      "\n",
      "- `city_name`: A string (VARCHAR) of maximum 16 characters. This is the primary key and cannot be null.\n",
      "- `population`: An integer representing the population of the city.\n",
      "- `country`: A string (VARCHAR) of maximum 16 characters. This cannot be null.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Describe the first table\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first row of the 'city_stats' table is:\n",
      "\n",
      "- City Name: Toronto\n",
      "- Population: 2,930,000\n",
      "- Country: Canada\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Retrieve the first row of that table\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Community Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) [Wikipedia Tool](https://llamahub.ai/l/tools/llama-index-tools-wikipedia?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-wikipedia/examples/wikipedia.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben Affleck's current spouse is Jennifer Lopez. They got back together in 2021 after previously being engaged from 2002 to 2004. Before that, he was married to actress Jennifer Garner from 2005 to 2018.\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.wikipedia import WikipediaToolSpec\n",
    "\n",
    "tool_spec = WikipediaToolSpec()\n",
    "\n",
    "agent = OpenAIAgent.from_tools(tool_spec.to_tool_list()) #, verbose=True,)\n",
    "\n",
    "response= agent.chat(\"Who is Ben Afflecks spouse?\")\n",
    "\n",
    "#print(response.sources)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) [Arxiv Tool](https://llamahub.ai/l/tools/llama-index-tools-arxiv?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/tools/llama-index-tools-arxiv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Whats are the newest discoveries on Prompt Engineering?\n",
      "=== Calling Function ===\n",
      "Calling function: arxiv_query with args: {\n",
      "  \"query\": \"Prompt Engineering\",\n",
      "  \"sort_by\": \"recent\"\n",
      "}\n",
      "Got output: [Document(id_='8d38e7e5-66a6-4d0f-a3ea-cc1531d30f0e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='http://arxiv.org/pdf/2405.19325v1: Nearest Neighbor Speculative Decoding for LLM Generation and Attribution\\nLarge language models (LLMs) often hallucinate and lack the ability to\\nprovide attribution for their generations. Semi-parametric LMs, such as kNN-LM,\\napproach these limitations by refining the output of an LM for a given prompt\\nusing its nearest neighbor matches in a non-parametric data store. However,\\nthese models often exhibit slow inference speeds and produce non-fluent texts.\\nIn this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a\\nnovel semi-parametric language modeling approach that is capable of\\nincorporating real-world text spans of arbitrary length into the LM generations\\nand providing attribution to their sources. NEST performs token-level retrieval\\nat each inference step to compute a semi-parametric mixture distribution and\\nidentify promising span continuations in a corpus. It then uses an approximate\\nspeculative decoding procedure that accepts a prefix of the retrieved span or\\ngenerates a new token. NEST significantly enhances the generation quality and\\nattribution rate of the base LM across a variety of knowledge-intensive tasks,\\nsurpassing the conventional kNN-LM method and performing competitively with\\nin-context retrieval augmentation. In addition, NEST substantially improves the\\ngeneration speed, achieving a 1.8x speedup in inference time when applied to\\nLlama-2-Chat 70B.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='cc05bfba-b1d7-47ff-9f07-88e32d537881', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='http://arxiv.org/pdf/2405.19323v1: Are Large Language Models Chameleons?\\nDo large language models (LLMs) have their own worldviews and personality\\ntendencies? Simulations in which an LLM was asked to answer subjective\\nquestions were conducted more than 1 million times. Comparison of the responses\\nfrom different LLMs with real data from the European Social Survey (ESS)\\nsuggests that the effect of prompts on bias and variability is fundamental,\\nhighlighting major cultural, age, and gender biases. Methods for measuring the\\ndifference between LLMs and survey data are discussed, such as calculating\\nweighted means and a new proposed measure inspired by Jaccard similarity. We\\nconclude that it is important to analyze the robustness and variability of\\nprompts before using LLMs to model individual decisions or collective behavior,\\nas their imitation abilities are approximate at best.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='a7d48c48-33ab-4ea7-9a73-9db1306f18ee', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='http://arxiv.org/pdf/2405.19322v1: Optical superlattice for engineering Hubbard couplings in quantum simulation\\nQuantum simulations of Hubbard models with ultracold atoms rely on the\\nexceptional control of coherent motion provided by optical lattices. Here we\\ndemonstrate enhanced tunability using an optical superlattice in a fermionic\\nquantum gas microscope. With our phase-stable bichromatic design, we achieve a\\nprecise control of tunneling and tilt throughout the lattice, as evidenced by\\nlong-lived coherent double-well oscillations and next-nearest-neighbor quantum\\nwalks in a staggered configuration. We furthermore present correlated quantum\\nwalks of two particles initiated through a resonant pair-breaking mechanism.\\nFinally, we engineer tunable spin couplings through local offsets and create a\\nspin ladder with ferromagnetic and antiferromagnetic couplings along the rungs\\nand legs, respectively. Our work underscores the high potential of optical\\nsuperlattices for engineering, simulating, and detecting strongly correlated\\nmany-body quantum states.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n",
      "========================\n",
      "\n",
      "Here are some of the most recent discoveries in Prompt Engineering:\n",
      "\n",
      "1. [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](http://arxiv.org/pdf/2405.19325v1): This paper introduces a novel semi-parametric language modeling approach called Nearest Neighbor Speculative Decoding (NEST). NEST is capable of incorporating real-world text spans of arbitrary length into the language model generations and providing attribution to their sources. It significantly enhances the generation quality and attribution rate of the base language model across a variety of knowledge-intensive tasks.\n",
      "\n",
      "2. [Are Large Language Models Chameleons?](http://arxiv.org/pdf/2405.19323v1): This research investigates whether large language models (LLMs) have their own worldviews and personality tendencies. The study suggests that the effect of prompts on bias and variability is fundamental, highlighting major cultural, age, and gender biases. The paper concludes that it is important to analyze the robustness and variability of prompts before using LLMs to model individual decisions or collective behavior.\n",
      "\n",
      "3. [Optical superlattice for engineering Hubbard couplings in quantum simulation](http://arxiv.org/pdf/2405.19322v1): This paper presents a method for quantum simulations of Hubbard models with ultracold atoms using an optical superlattice in a fermionic quantum gas microscope. The method provides precise control of tunneling and tilt throughout the lattice, enabling the engineering, simulation, and detection of strongly correlated many-body quantum states.\n",
      "\n",
      "Please note that while the third paper is not directly related to Prompt Engineering in the context of AI, it does involve engineering in a quantum simulation context.\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.arxiv.base import ArxivToolSpec\n",
    "\n",
    "arxiv_tool = ArxivToolSpec()\n",
    "\n",
    "agent = OpenAIAgent.from_tools(arxiv_tool.to_tool_list(), verbose=True,)\n",
    "\n",
    "print(agent.chat(\"Whats are the newest discoveries on Prompt Engineering?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) [DuckDuckGoSearch Tool](https://llamahub.ai/l/tools/llama-index-tools-duckduckgo?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-duckduckgo/examples/duckduckgo_search.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-duckduckgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: what are the latest developments in machine learning\n",
      "=== Calling Function ===\n",
      "Calling function: duckduckgo_full_search with args: {\n",
      "  \"query\": \"latest developments in machine learning\",\n",
      "  \"max_results\": 5\n",
      "}\n",
      "Got output: [{'title': 'Machine learning | MIT News | Massachusetts Institute of Technology', 'href': 'https://news.mit.edu/topic/machine-learning', 'body': \"Machine learning. Download RSS feed: News Articles / In the Media / Audio. Displaying 1 - 15 of 900 news articles related to this topic. ... A new algorithm learns to squish, bend, or stretch a robot's entire body to accomplish diverse tasks like avoiding obstacles or retrieving items.\"}, {'title': '10 top AI and machine learning trends for 2024 | TechTarget', 'href': 'https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends', 'body': \"This year's trends reflect a deepening sophistication and caution in AI development and deployment strategies, with an eye to ethics, safety and the evolving regulatory landscape. Here are the top 10 AI and machine learning trends to prepare for in 2024. 1. Multimodal AI. Multimodal AI goes beyond traditional single-mode data processing to ...\"}, {'title': 'Latest Developments in Machine Learning: 2024 Update', 'href': 'https://waleed.dev/blog/latest-developments-in-machine-learning-2024-update', 'body': \"Some of the latest developments in machine learning that are shaping the industry in 2024 include: Generative AI - Models like DALL-E 3, Stable Diffusion, and Google's Imagen are producing highly realistic synthetic images and videos. This has implications for content creation, entertainment, art, and more.\"}, {'title': 'Top 7 Machine Learning Trends in 2023 - HackerRank Blog', 'href': 'https://www.hackerrank.com/blog/top-machine-learning-trends/', 'body': \"From no-code machine learning to tinyML, these seven trends are worth watching in 2023. 1. Automated Machine Learning. Automated machine learning, or AutoML, is one of the most significant machine learning trends we're witnessing. Roughly 61% of decision makers in companies utilizing AI said they've adopted autoML, and another 25% were ...\"}, {'title': 'Machine learning - Latest research and news | Nature', 'href': 'https://www.nature.com/subjects/machine-learning', 'body': 'Machine learning articles from across Nature Portfolio. Machine learning is the ability of a machine to improve its performance based on previous results. Machine learning methods enable computers ...'}]\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.duckduckgo import DuckDuckGoSearchToolSpec\n",
    "\n",
    "tool_spec = DuckDuckGoSearchToolSpec()\n",
    "\n",
    "agent = OpenAIAgent.from_tools(DuckDuckGoSearchToolSpec().to_tool_list(), verbose=True,)\n",
    "response = agent.chat(\"what are the latest developments in machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some of the latest developments in machine learning:\n",
      "\n",
      "1. [MIT News](https://news.mit.edu/topic/machine-learning) reports on a new algorithm that learns to manipulate a robot's entire body to accomplish diverse tasks like avoiding obstacles or retrieving items.\n",
      "\n",
      "2. [TechTarget](https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends) highlights the top 10 AI and machine learning trends for 2024, including Multimodal AI, which goes beyond traditional single-mode data processing.\n",
      "\n",
      "3. [Waleed's Blog](https://waleed.dev/blog/latest-developments-in-machine-learning-2024-update) mentions some of the latest developments shaping the industry in 2024, such as Generative AI. Models like DALL-E 3, Stable Diffusion, and Google's Imagen are producing highly realistic synthetic images and videos, impacting content creation, entertainment, art, and more.\n",
      "\n",
      "4. [HackerRank Blog](https://www.hackerrank.com/blog/top-machine-learning-trends/) discusses seven trends worth watching in 2023, including Automated Machine Learning (AutoML). Roughly 61% of decision makers in companies utilizing AI have adopted autoML.\n",
      "\n",
      "5. [Nature](https://www.nature.com/subjects/machine-learning) provides a collection of articles on machine learning, emphasizing its ability to improve performance based on previous results.\n",
      "\n",
      "Please visit the provided links for more detailed information.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Who is Goethe?\n",
      "=== Calling Function ===\n",
      "Calling function: duckduckgo_instant_search with args: {\n",
      "  \"query\": \"Goethe\"\n",
      "}\n",
      "Got output: [{'icon': None, 'text': 'Johann Wolfgang von Goethe was a German polymath and writer, who is widely regarded as the greatest and most influential writer in the German language. His work has had a profound and wide-ranging influence on Western literary, political, and philosophical thought from the late 18th century to the present day. Goethe was a German poet, playwright, novelist, scientist, statesman, theatre director, and critic. His works include plays, poetry and aesthetic criticism, as well as treatises on botany, anatomy, and color. Goethe took up residence in Weimar in November 1775 following the success of his first novel, The Sorrows of Young Werther. He was ennobled by the Duke of Saxe-Weimar, Karl August, in 1782. Goethe was an early participant in the Sturm und Drang literary movement.', 'topic': None, 'url': 'https://en.wikipedia.org/wiki/Johann_Wolfgang_von_Goethe'}, {'icon': 'https://duckduckgo.com/i/edd6fba6.jpg', 'text': 'Johann Wolfgang von Goethe A German poet, playwright, novelist, scientist, statesman, theatre director, and critic.', 'topic': None, 'url': 'https://duckduckgo.com/Johann_Wolfgang_von_Goethe'}, {'icon': 'https://duckduckgo.com/i/c819f955.png', 'text': 'Goethe University Frankfurt A university located in Frankfurt am Main, Germany.', 'topic': None, 'url': 'https://duckduckgo.com/Goethe_University_Frankfurt'}, {'icon': 'https://duckduckgo.com/i/www.goethe.de.ico', 'text': 'Goethe-Institut A non-profit German cultural association operational worldwide with 159 institutes, promoting the...', 'topic': None, 'url': 'https://duckduckgo.com/Goethe-Institut'}, {'icon': '', 'text': \"Goethe (grape) Goethe is one of the collection of grape varieties known as Rogers' Hybrids, created by E.S.\", 'topic': None, 'url': 'https://duckduckgo.com/Goethe_(grape)'}, {'icon': 'https://duckduckgo.com/i/6eff7e53.jpg', 'text': 'Goethe (train) An express train that, for most of its existence, linked Paris-Est in Paris, France, with...', 'topic': None, 'url': 'https://duckduckgo.com/Goethe_(train)'}, {'icon': 'https://duckduckgo.com/i/71aac73b.gif', 'text': '3047 Goethe A bright background asteroid from the central regions of the asteroid belt, approximately in...', 'topic': None, 'url': 'https://duckduckgo.com/3047_Goethe'}, {'icon': 'https://duckduckgo.com/i/c71989d7.jpg', 'text': 'Goethe! A 2010 German historical drama film directed by Philipp Stölzl and starring Alexander Fehling...', 'topic': None, 'url': 'https://duckduckgo.com/Young_Goethe_in_Love'}, {'icon': '', 'text': 'Mount Goethe A summit in Fresno County, California, in the United States.', 'topic': None, 'url': 'https://duckduckgo.com/Mount_Goethe'}, {'icon': '', 'text': 'Goethe Awards An American series of comic book fan awards, first presented in 1971 for comics published in 1970.', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Awards'}, {'icon': 'https://duckduckgo.com/i/b41b9fb4.jpg', 'text': 'Goethe Prize An award for achievement \"worthy of honour in memory of Johann Wolfgang von Goethe\" made by the...', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Prize'}, {'icon': '', 'text': 'Goethe Medal A yearly prize given by the Goethe-Institut honoring non-Germans \"who have performed outstanding...', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Medal'}, {'icon': '', 'text': 'Goethe Basin An impact basin at 81.4° N, 54.3° W on Mercury approximately 317 kilometers in diameter.', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Basin'}, {'icon': '', 'text': \"Goethe (surname) See related meanings for the phrase 'Goethe (surname)'.\", 'topic': 'See also', 'url': 'https://duckduckgo.com/d/Goethe_(surname)'}, {'icon': '', 'text': \"Gote See related meanings for the word 'Gote'.\", 'topic': 'See also', 'url': 'https://duckduckgo.com/d/Gote'}]\n",
      "========================\n",
      "\n",
      "Johann Wolfgang von Goethe was a German polymath and writer, who is widely regarded as the greatest and most influential writer in the German language. His work has had a profound and wide-ranging influence on Western literary, political, and philosophical thought from the late 18th century to the present day. \n",
      "\n",
      "Goethe was a German poet, playwright, novelist, scientist, statesman, theatre director, and critic. His works include plays, poetry and aesthetic criticism, as well as treatises on botany, anatomy, and color. \n",
      "\n",
      "Goethe took up residence in Weimar in November 1775 following the success of his first novel, The Sorrows of Young Werther. He was ennobled by the Duke of Saxe-Weimar, Karl August, in 1782. Goethe was an early participant in the Sturm und Drang literary movement. \n",
      "\n",
      "For more information, you can visit his [Wikipedia page](https://en.wikipedia.org/wiki/Johann_Wolfgang_von_Goethe).\n"
     ]
    }
   ],
   "source": [
    "agent.chat_history.clear()\n",
    "print(agent.chat(\"Who is Goethe?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) [Yahoo Finance Tool](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/)  \n",
    "[Github](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/tools/llama-index-tools-yahoo-finance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-yahoo-finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current price of Apple Inc. (AAPL) stock is $191.865.\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.yahoo_finance import YahooFinanceToolSpec\n",
    "\n",
    "tool_spec = YahooFinanceToolSpec()\n",
    "agent = OpenAIAgent.from_tools(tool_spec.to_tool_list())\n",
    "\n",
    "print(agent.chat(\"What is the price of Apple stock?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the latest news headlines about Apple:\n",
      "\n",
      "1. \"Magnificent Seven Stocks: Nvidia Stock Reverses From Record Highs\"\n",
      "2. \"Apple iPhone Sales Weak In China, U.S.: Report\"\n",
      "3. \"Warner Bros. Discovery CEO says company has 'full buffet' of sports as NBA rights decision looms\"\n",
      "4. \"Apple Stock Isn’t a Buy Yet, Says Analyst. China-iPhone Demand Remains an Issue.\"\n",
      "5. \"Fighting Off Nvidia, This Mag 7 Stock Looks To Break Out\"\n",
      "6. \"Apple Expected to Accelerate Growth on Strength of Investment in AI, Tigress Financial Partners Says\"\n",
      "7. \"Dow Jones Futures Fall As Salesforce Plunges After Stock Market Slides Despite Nvidia\"\n",
      "8. \"The Most Prosperous Nation in the World\"\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"What is the latest news about Apple?\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) [Open Weather Map Tool](https://llamahub.ai/l/tools/llama-index-tools-weather?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/tools/llama-index-tools-weather)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-weather\n",
    "%pip install -q pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"In Paris, the current weather is as follows:\\n- Detailed status: moderate rain\\n- Wind speed: 7.2 m/s, direction: 290°\\n- Humidity: 77%\\n- Temperature: \\n  - Current: 14.88°C\\n  - High: 16.64°C\\n  - Low: 12.78°C\\n  - Feels like: 14.43°C\\n- Rain: {'1h': 0.12}\\n- Heat index: None\\n- Cloud cover: 75%\", sources=[ToolOutput(content='[Document(id_=\\'09ac82fa-8c96-472c-bac3-31727d21cc3b\\', embedding=None, metadata={\\'weather from\\': \\'Paris\\'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Paris, the current weather is as follows:\\\\nDetailed status: moderate rain\\\\nWind speed: 7.2 m/s, direction: 290°\\\\nHumidity: 77%\\\\nTemperature: \\\\n  - Current: 14.88°C\\\\n  - High: 16.64°C\\\\n  - Low: 12.78°C\\\\n  - Feels like: 14.43°C\\\\nRain: {\\'1h\\': 0.12}\\\\nHeat index: None\\\\nCloud cover: 75%\", start_char_idx=None, end_char_idx=None, text_template=\\'{metadata_str}\\\\n\\\\n{content}\\', metadata_template=\\'{key}: {value}\\', metadata_seperator=\\'\\\\n\\')]', tool_name='weather_at_location', raw_input={'args': (), 'kwargs': {'location': 'Paris'}}, raw_output=[Document(id_='09ac82fa-8c96-472c-bac3-31727d21cc3b', embedding=None, metadata={'weather from': 'Paris'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Paris, the current weather is as follows:\\nDetailed status: moderate rain\\nWind speed: 7.2 m/s, direction: 290°\\nHumidity: 77%\\nTemperature: \\n  - Current: 14.88°C\\n  - High: 16.64°C\\n  - Low: 12.78°C\\n  - Feels like: 14.43°C\\nRain: {'1h': 0.12}\\nHeat index: None\\nCloud cover: 75%\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')], is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.weather import OpenWeatherMapToolSpec\n",
    "\n",
    "os.environ[\"OPENWEATHER_API_KEY\"]=\"your key\"\n",
    "\n",
    "## https://openweathermap.org/api\n",
    "tool_spec = OpenWeatherMapToolSpec(key=os.environ[\"OPENWEATHER_API_KEY\"])\n",
    "\n",
    "agent = OpenAIAgent.from_tools(tool_spec.to_tool_list())\n",
    "\n",
    "agent.chat(\"What is the temperature like in Paris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"In Vienna, the current weather is as follows:\\n- Detailed status: light rain\\n- Wind speed: 2.57 m/s, direction: 210°\\n- Humidity: 86%\\n- Temperature: \\n  - Current: 17.13°C\\n  - High: 18.93°C\\n  - Low: 15.64°C\\n  - Feels like: 17.14°C\\n- Rain: {'1h': 0.23}\\n- Heat index: None\\n- Cloud cover: 20%\", sources=[ToolOutput(content='[Document(id_=\\'5153a3c3-5dad-4193-b3e5-15d3e0bc10a6\\', embedding=None, metadata={\\'weather from\\': \\'Vienna\\'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Vienna, the current weather is as follows:\\\\nDetailed status: light rain\\\\nWind speed: 2.57 m/s, direction: 210°\\\\nHumidity: 86%\\\\nTemperature: \\\\n  - Current: 17.13°C\\\\n  - High: 18.93°C\\\\n  - Low: 15.64°C\\\\n  - Feels like: 17.14°C\\\\nRain: {\\'1h\\': 0.23}\\\\nHeat index: None\\\\nCloud cover: 20%\", start_char_idx=None, end_char_idx=None, text_template=\\'{metadata_str}\\\\n\\\\n{content}\\', metadata_template=\\'{key}: {value}\\', metadata_seperator=\\'\\\\n\\')]', tool_name='weather_at_location', raw_input={'args': (), 'kwargs': {'location': 'Vienna'}}, raw_output=[Document(id_='5153a3c3-5dad-4193-b3e5-15d3e0bc10a6', embedding=None, metadata={'weather from': 'Vienna'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Vienna, the current weather is as follows:\\nDetailed status: light rain\\nWind speed: 2.57 m/s, direction: 210°\\nHumidity: 86%\\nTemperature: \\n  - Current: 17.13°C\\n  - High: 18.93°C\\n  - Low: 15.64°C\\n  - Feels like: 17.14°C\\nRain: {'1h': 0.23}\\nHeat index: None\\nCloud cover: 20%\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')], is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What is the temperature in Vienna today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- [OnDemandLoaderTool](https://docs.llamaindex.ai/en/stable/examples/tools/OnDemandLoaderTool/)  \n",
    "\n",
    "OnDemandLoaderTool is a powerful agent tool that allows for \"on-demand\" data querying from any data source on LlamaHub.  \n",
    "\n",
    "This tool takes in a BaseReader data loader, and when called will 1) load data, 2) index data, and 3) query the data.  \n",
    "\n",
    "In this walkthrough, we show how to use the OnDemandLoaderTool to convert our Wikipedia data loader into an accessible search tool for a LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-readers-wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools.ondemand_loader_tool import OnDemandLoaderTool\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tool¶\n",
    "\n",
    "First it is defined the WikipediaReader. Note that the load_data interface to WikipediaReader takes in a list of pages.   \n",
    "By default, this queries the Wikipedia search endpoint which will autosuggest the relevant pages.  \n",
    "Then it wraps it into our OnDemandLoaderTool.  \n",
    "By default since we don't specify the index_cls, a simple vector store index is initialized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolOutput(content=\"Berlin has a rich and diverse arts and culture scene. The city is known for its vibrant nightlife, with a history of being a hub for punk music and culture, and a premier nightlife venue for people from all over the world. It has many nightclubs, and is known for its uninhibited parties. Berlin also has a long history of gay culture and hosts a number of queer clubs and festivals.\\n\\nThe city is home to 44 theaters and stages, including the Deutsches Theater, the Volksbühne, and the Berliner Ensemble. It also has three major opera houses: the Deutsche Oper, the Berlin State Opera, and the Komische Oper. The city's main venue for musical theater performances are the Theater am Potsdamer Platz and Theater des Westens. Contemporary dance can be seen at the Radialsystem V.\\n\\nBerlin also hosts the Berlin International Film Festival, which is considered to be the largest publicly attended film festival in the world. Other cultural festivals include the Karneval der Kulturen, Berliner Festspiele, JazzFest Berlin, and Young Euro Classic. The city also hosts one of the largest New Year's Eve celebrations in the world.\\n\\nIn terms of cuisine, Berlin offers a wide variety, with 23 restaurants awarded one or more Michelin stars. The city is known for its vegetarian and vegan cuisine, as well as its street food. The cuisine reflects the city's immigrant history, with Turkish, Arab, Chinese, Vietnamese, Thai, Indian, Korean, Japanese, Spanish, Italian, and Greek food available in many parts of the city.\", tool_name='Wikipedia Tool', raw_input={'query': \"What's the arts and culture scene in Berlin?\"}, raw_output=Response(response=\"Berlin has a rich and diverse arts and culture scene. The city is known for its vibrant nightlife, with a history of being a hub for punk music and culture, and a premier nightlife venue for people from all over the world. It has many nightclubs, and is known for its uninhibited parties. Berlin also has a long history of gay culture and hosts a number of queer clubs and festivals.\\n\\nThe city is home to 44 theaters and stages, including the Deutsches Theater, the Volksbühne, and the Berliner Ensemble. It also has three major opera houses: the Deutsche Oper, the Berlin State Opera, and the Komische Oper. The city's main venue for musical theater performances are the Theater am Potsdamer Platz and Theater des Westens. Contemporary dance can be seen at the Radialsystem V.\\n\\nBerlin also hosts the Berlin International Film Festival, which is considered to be the largest publicly attended film festival in the world. Other cultural festivals include the Karneval der Kulturen, Berliner Festspiele, JazzFest Berlin, and Young Euro Classic. The city also hosts one of the largest New Year's Eve celebrations in the world.\\n\\nIn terms of cuisine, Berlin offers a wide variety, with 23 restaurants awarded one or more Michelin stars. The city is known for its vegetarian and vegan cuisine, as well as its street food. The cuisine reflects the city's immigrant history, with Turkish, Arab, Chinese, Vietnamese, Thai, Indian, Korean, Japanese, Spanish, Italian, and Greek food available in many parts of the city.\", source_nodes=[NodeWithScore(node=TextNode(id_='af87073a-a1a3-4d11-a28e-c951f32aae49', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3354', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='694dbc56c4449f00addfa9d97ba64df9b1bf7f32ce1ba3f61c2fc04e8b562baf'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b9824a06-6f30-4b01-98c0-175d1e18fe1b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='794667dfdc2dfb766a086d1a3d64c811d1e86e682da58a1c4aababae3e81506c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0140ff4e-11d3-4368-bae2-d2ec323a24f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e4d6a6c9670dd3861a30f0d72b7aae960b7adc667534f29664ca302c3dc73ec')}, text=\"=== Nightlife and festivals ===\\n\\nBerlin's nightlife has been celebrated as one of the most diverse and vibrant of its kind. In the 1970s and 80s, the SO36 in Kreuzberg was a center for punk music and culture. The SOUND and the Dschungel gained notoriety. Throughout the 1990s, people in their 20s from all over the world, particularly those in Western and Central Europe, made Berlin's club scene a premier nightlife venue. After the fall of the Berlin Wall in 1989, many historic buildings in Mitte, the former city center of East Berlin, were illegally occupied and re-built by young squatters and became a fertile ground for underground and counterculture gatherings. The central boroughs are home to many nightclubs, including the Watergate, Tresor and Berghain. The KitKatClub and several other locations are known for their sexually uninhibited parties.\\nClubs are not required to close at a fixed time during the weekends, and many parties last well into the morning or even all weekend. The Weekend Club near Alexanderplatz features a roof terrace that allows partying at night. Several venues have become a popular stage for the Neo-Burlesque scene.\\n\\nBerlin has a long history of gay culture, and is an important birthplace of the LGBT rights movement. Same-sex bars and dance halls operated freely as early as the 1880s, and the first gay magazine, Der Eigene, started in 1896. By the 1920s, gays and lesbians had an unprecedented visibility. Today, in addition to a positive atmosphere in the wider club scene, the city again has a huge number of queer clubs and festivals. The most famous and largest are Berlin Pride, the Christopher Street Day, the Lesbian and Gay City Festival in Berlin-Schöneberg, the Kreuzberg Pride.\\nThe annual Berlin International Film Festival (Berlinale) with around 500,000 admissions is considered to be the largest publicly attended film festival in the world. The Karneval der Kulturen (Carnival of Cultures), a multi-ethnic street parade, is celebrated every Pentecost weekend. Berlin is also well known for the cultural festival Berliner Festspiele, which includes the jazz festival JazzFest Berlin, and Young Euro Classic, the largest international festival of youth orchestras in the world. Several technology and media art festivals and conferences are held in the city, including Transmediale and Chaos Communication Congress. The annual Berlin Festival focuses on indie rock, electronic music and synthpop and is part of the International Berlin Music Week. Every year Berlin hosts one of the largest New Year's Eve celebrations in the world, attended by well over a million people. The focal point is the Brandenburg Gate, where midnight fireworks are centered, but various private fireworks displays take place throughout the entire city. Partygoers in Germany often toast the New Year with a glass of sparkling wine.\", start_char_idx=65875, end_char_idx=68743, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8748883465802275), NodeWithScore(node=TextNode(id_='0140ff4e-11d3-4368-bae2-d2ec323a24f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3354', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='694dbc56c4449f00addfa9d97ba64df9b1bf7f32ce1ba3f61c2fc04e8b562baf'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af87073a-a1a3-4d11-a28e-c951f32aae49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13a52a6eadaac5f23b46f425b978208ecb0fddc6651f3596176b8e06b7fb8c7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5806991c-2497-4c7b-8923-940ba6b5e608', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1a49e873a004985fc911edc086f4b9d58ad65cd1556c83526d7237f4ef0d9e0b')}, text='=== Performing arts ===\\n\\nBerlin is home to 44 theaters and stages. The Deutsches Theater in Mitte was built in 1849–50 and has operated almost continuously since then. The Volksbühne at Rosa-Luxemburg-Platz was built in 1913–14, though the company had been founded in 1890. The Berliner Ensemble, famous for performing the works of Bertolt Brecht, was established in 1949. The Schaubühne was founded in 1962 and moved to the building of the former Universum Cinema on Kurfürstendamm in 1981. With a seating capacity of 1,895 and a stage floor of 2,854 square meters (30,720 sq ft), the Friedrichstadt-Palast in Berlin Mitte is the largest show palace in Europe. For Berlin\\'s independent dance and theatre scene, venues such as the Sophiensäle in Mitte and the three houses of the Hebbel am Ufer (HAU) in Kreuzberg are important. Most productions there are also accessible to an English-speaking audience. Some of the dance and theatre groups that also work internationally (Gob Squad, Rimini Protokoll) are based there, as well as festivals such as the international festival Dance in August.\\nBerlin has three major opera houses: the Deutsche Oper, the Berlin State Opera, and the Komische Oper. The Berlin State Opera on Unter den Linden opened in 1742 and is the oldest of the three. Its musical director is Daniel Barenboim. The Komische Oper has traditionally specialized in operettas and is also at Unter den Linden. The Deutsche Oper opened in 1912 in Charlottenburg.\\nThe city\\'s main venue for musical theater performances are the Theater am Potsdamer Platz and Theater des Westens (built in 1895). Contemporary dance can be seen at the Radialsystem V. The Tempodrom is host to concerts and circus-inspired entertainment. It also houses a multi-sensory spa experience. The Admiralspalast in Mitte has a vibrant program of variety and music events.\\nThere are seven symphony orchestras in Berlin. The Berlin Philharmonic Orchestra is one of the preeminent orchestras in the world; it is housed in the Berliner Philharmonie near Potsdamer Platz on a street named for the orchestra\\'s longest-serving conductor, Herbert von Karajan. Simon Rattle was its principal conductor from 1999 to 2018, a position now held by Kirill Petrenko. The Konzerthausorchester Berlin was founded in 1952 as the orchestra for East Berlin. Christoph Eschenbach is its principal conductor. The Haus der Kulturen der Welt presents exhibitions dealing with intercultural issues and stages world music and conferences. The Kookaburra and the Quatsch Comedy Club are known for satire and comedy shows. In 2018, the New York Times described Berlin as \"arguably the world capital of underground electronic music\".\\n\\n\\n=== Cuisine ===\\n\\nThe cuisine and culinary offerings of Berlin vary greatly. 23 restaurants in Berlin have been awarded one or more Michelin stars in the Michelin Guide of 2021, which ranks the city at the top for the number of restaurants having this distinction in Germany. Berlin is well known for its offerings of vegetarian and vegan cuisine and is home to an innovative entrepreneurial food scene promoting cosmopolitan flavors, local and sustainable ingredients, pop-up street food markets, supper clubs, as well as food festivals, such as Berlin Food Week.\\nMany local foods originated from north German culinary traditions and include rustic and hearty dishes with pork, goose, fish, peas, beans, cucumbers, or potatoes. Typical Berliner fare include popular street food like the Currywurst (which gained popularity with postwar construction workers rebuilding the city), Buletten and the Berliner donut, known in Berlin as Pfannkuchen (German: [ˈp͡fanˌkuːxn̩] ). German bakeries offering a variety of breads and pastries are widespread. One of Europe\\'s largest delicatessen markets is found at the KaDeWe, and among the world\\'s largest chocolate stores is Rausch.\\nBerlin is also home to a diverse gastronomy scene reflecting the immigrant history of the city. Turkish and Arab immigrants brought their culinary traditions to the city, such as the lahmajoun and falafel, which have become common fast food staples. The modern fast-food version of the doner kebab sandwich which evolved in Berlin in the 1970s, has since become a favorite dish in Germany and elsewhere in the world. Asian cuisine like Chinese, Vietnamese, Thai, Indian, Korean, and Japanese restaurants, as well as Spanish tapas bars, Italian, and Greek cuisine, can be found in many parts of the city.', start_char_idx=68746, end_char_idx=73210, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8711962382361889)], metadata={'af87073a-a1a3-4d11-a28e-c951f32aae49': {}, '0140ff4e-11d3-4368-bae2-d2ec323a24f1': {}}), is_error=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = WikipediaReader()\n",
    "\n",
    "tool = OnDemandLoaderTool.from_defaults(\n",
    "    reader,\n",
    "    name=\"Wikipedia Tool\",\n",
    "    description=\"A tool for loading and querying articles from Wikipedia\",\n",
    ")\n",
    "\n",
    "# run tool by itself\n",
    "tool([\"Berlin\"], query_str=\"What's the arts and culture scene in Berlin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.indices.vector_store import VectorStoreIndex\n",
    "\n",
    "reader = WikipediaReader()\n",
    "tool = OnDemandLoaderTool.from_defaults(\n",
    "    reader=reader,\n",
    "    index_cls=VectorStoreIndex,\n",
    "    index_kwargs={\"dim\": 768},\n",
    "    name=\"Wikipedia\",\n",
    "    description=\"A tool for querying Wikipedia articles.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tool([\"City of Vienna\"], query_str=\"What are the best universities in Vienna?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context information lists several universities in Vienna, including the Academy of Fine Arts Vienna, Central European University, Diplomatic Academy of Vienna, Medical University of Vienna, PEF Private University of Management Vienna, University of Applied Arts Vienna, University of Applied Sciences Campus Vienna, University of Music and Performing Arts Vienna, University of Veterinary Medicine Vienna, University of Vienna, Vienna University of Economics and Business, University of Natural Resources and Life Sciences, Vienna, University of Applied Sciences Technikum Wien, TU Wien, Webster Vienna Private University, and Sigmund Freud Private University. However, it does not rank them or specify which ones are considered the best.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also check [These Notebooks](https://github.com/run-llama/llama-hub/tree/main/llama_hub/tools/notebooks)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Indexing_Querying_LLamaIndex",
   "widgets": {}
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/rsouza/Prompt_Engineering_Course/blob/main/Notebooks/5_LlamaIndex/2-Indexing_Querying_LLamaIndex.ipynb",
     "timestamp": 1714082079174
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d311bf7ee564be781cfd48286066ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6efb132931b04655b350d09375a58bf1",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ad0d2d97514a2ab8dc2ab0a5591178",
      "value": " 10/10 [00:00&lt;00:00, 67.37it/s]"
     }
    },
    "1ece578683ef4f83b58288633c9bb975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2d2af3f1254498ca0ed0413fc2e3873",
      "placeholder": "​",
      "style": "IPY_MODEL_a87159485bc84f03889bd9ca3439d020",
      "value": "Parsing nodes: 100%"
     }
    },
    "2a51f4e1f37141848d9023722fe81e15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f735494c12145f28654994ad79a0832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ee0f3679a34d8482515e78b478283a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48c37d7e447d49a8b911134d287d1ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56344af539034c34b5e98563675e6ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1cdb05547004947986e416042a3c758",
      "placeholder": "​",
      "style": "IPY_MODEL_9a7cc7cb31fa4ea5afea4f3ef812e68d",
      "value": " 30/30 [00:01&lt;00:00, 28.29it/s]"
     }
    },
    "5a0c1216c09d45caae2855d23accd01a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68fc88da1157414192a92094331375ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ece578683ef4f83b58288633c9bb975",
       "IPY_MODEL_6d704507f27e42f8a89b4fe41f875b8a",
       "IPY_MODEL_1d311bf7ee564be781cfd48286066ba0"
      ],
      "layout": "IPY_MODEL_44ee0f3679a34d8482515e78b478283a"
     }
    },
    "6d704507f27e42f8a89b4fe41f875b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c37d7e447d49a8b911134d287d1ab8",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a0c1216c09d45caae2855d23accd01a",
      "value": 10
     }
    },
    "6efb132931b04655b350d09375a58bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c38119547645f591c78bcd8f67cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4f2c1a82f224dd0ba0faef7dca60d80",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce761a2a57694a4f80c6319cbe633693",
      "value": 30
     }
    },
    "9a7cc7cb31fa4ea5afea4f3ef812e68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ad0d2d97514a2ab8dc2ab0a5591178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ff4a0af9d444128c464b97cb9f13dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ccfb889b464e40c489f0a873681c3463",
       "IPY_MODEL_75c38119547645f591c78bcd8f67cc10",
       "IPY_MODEL_56344af539034c34b5e98563675e6ef1"
      ],
      "layout": "IPY_MODEL_3f735494c12145f28654994ad79a0832"
     }
    },
    "a87159485bc84f03889bd9ca3439d020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4f2c1a82f224dd0ba0faef7dca60d80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1cdb05547004947986e416042a3c758": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccfb889b464e40c489f0a873681c3463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5e9a34c12b5444db998dd9f3735f83d",
      "placeholder": "​",
      "style": "IPY_MODEL_2a51f4e1f37141848d9023722fe81e15",
      "value": "Generating embeddings: 100%"
     }
    },
    "ce761a2a57694a4f80c6319cbe633693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2d2af3f1254498ca0ed0413fc2e3873": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5e9a34c12b5444db998dd9f3735f83d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
