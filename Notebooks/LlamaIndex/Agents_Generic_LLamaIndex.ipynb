{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0L5n3kwNdj9"
   },
   "source": [
    "# Agents with LlamaIndex II - \n",
    "\n",
    "Sources [1](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/), [2](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/agents/), [3](https://docs.llamaindex.ai/en/stable/examples/agent/custom_agent/), [4](https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent/), [5](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner/), [6](https://medium.com/llamaindex-blog/data-agents-eed797d7972f), [LlamaHub Tools](https://llamahub.ai/?tab=tools)  \n",
    "    \n",
    "--- \n",
    "### Agents\n",
    "\n",
    "An \"agent\" is an automated reasoning and decision engine. It takes in a user input/query and can make internal decisions for executing that query in order to return the correct result. The key agent components can include, but are not limited to:\n",
    "\n",
    "+ Breaking down a complex question into smaller ones\n",
    "+ Choosing an external Tool to use + coming up with parameters for calling the Tool\n",
    "+ Planning out a set of tasks\n",
    "+ Storing previously completed tasks in a memory module\n",
    "\n",
    "LlamaIndex provides a comprehensive framework for building agents. This includes the following components:\n",
    "\n",
    "+ Using agents with tools at a high-level to build agentic RAG and workflow automation use cases **(Previous Notebook)**\n",
    "+ Low-level components for building and debugging agents\n",
    "+ Core agent ingredients that can be used as standalone modules: query planning, tool use, and more **(Previous Notebook)**\n",
    "\n",
    "### Tools\n",
    "\n",
    "Having proper tool abstractions is at the core of building data agents. Defining a set of Tools is similar to defining any API interface, with the exception that these Tools are meant for agent rather than human use. We allow users to define both a Tool as well as a ToolSpec containing a series of functions under the hood.\n",
    "\n",
    "When using an agent or LLM with function calling, the tool selected (and the arguments written for that tool) rely strongly on the tool name and description of the tools purpose and arguments. Spending time tuning these parameters can result in larges changes in how the LLM calls these tools.\n",
    "\n",
    "A Tool implements a very generic interface - simply define __call__ and also return some basic metadata (name, description, function schema).\n",
    "LlamaIndex offer a few different types of Tools:\n",
    "\n",
    "+ FunctionTool: A function tool allows users to easily convert any user-defined function into a Tool. It can also auto-infer the function schema. **(Previous Notebook)**\n",
    "+ QueryEngineTool: A tool that wraps an existing query engine. Note: since our agent abstractions inherit from BaseQueryEngine, these tools can also wrap other agents. **(Previous Notebook)**\n",
    "+ Community contributed ToolSpecs that define one or more tools around a single service (like Gmail): see [LlamaHub](https://llamahub.ai/)\n",
    "+ Utility tools for wrapping other tools to handle returning large amounts of data from a tool: see [OnDemandLoaderTool](https://docs.llamaindex.ai/en/stable/examples/tools/OnDemandLoaderTool/)\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "The scope of possible use cases for agents is vast and ever-expanding. That said, here are some practical use cases that can deliver immediate value.\n",
    "\n",
    "+ Agentic RAG: Build a context-augmented research assistant over your data that not only answers simple questions, but complex research tasks. (Previous Notebook)\n",
    "+ SQL Agent: A subset of the above is a \"text-to-SQL assistant\" that can interact with a structured database. \n",
    "+ Workflow Assistant: Build an agent that can operate over common workflow tools like email, calendar.\n",
    "+ Coding Assistant: Build an agent that can operate over code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyWM-ThgNdj_"
   },
   "source": [
    "## Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76369,
     "status": "ok",
     "timestamp": 1714682800048,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "1hOqc6qhNdkA",
    "outputId": "2e5cf4da-cc0e-40ae-8d26-ed5ca7e07f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-agent-openai in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (0.4.8)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.18 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-agent-openai) (0.12.38)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4,>=0.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-agent-openai) (0.3.44)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-agent-openai) (1.82.1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.12.4)\n",
      "Requirement already satisfied: aiosqlite in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.11.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.17.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai) (3.10)\n",
      "Requirement already satisfied: griffe in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (4.3.7)\n",
      "Requirement already satisfied: certifi in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.18->llama-index-agent-openai) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-readers-web\n",
      "  Downloading llama_index_readers_web-0.4.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.9.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-readers-web) (3.12.4)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-readers-web) (4.13.3)\n",
      "Collecting chromedriver-autoinstaller<0.7,>=0.6.3 (from llama-index-readers-web)\n",
      "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting defusedxml<0.8,>=0.7.1 (from llama-index-readers-web)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting html2text<2025,>=2024.2.26 (from llama-index-readers-web)\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.28.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-readers-web) (0.28.1)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-readers-web) (0.12.38)\n",
      "Collecting lxml-html-clean>=0.4.2 (from llama-index-readers-web)\n",
      "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting lxml>=5.4.0 (from llama-index-readers-web)\n",
      "  Downloading lxml-5.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting markdownify>=1.1.0 (from llama-index-readers-web)\n",
      "  Downloading markdownify-1.1.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting newspaper3k<0.3,>=0.2.8 (from llama-index-readers-web)\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oxylabs>=2.0.0 (from llama-index-readers-web)\n",
      "  Downloading oxylabs-2.0.0-py3-none-any.whl.metadata (687 bytes)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
      "  Downloading playwright-1.52.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-readers-web) (2.32.3)\n",
      "Collecting selenium<5,>=4.17.2 (from llama-index-readers-web)\n",
      "  Downloading selenium-4.33.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\n",
      "  Downloading spider-client-0.0.27.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.1.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-readers-web) (2.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.20.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from chromedriver-autoinstaller<0.7,>=0.6.3->llama-index-readers-web) (24.2)\n",
      "Requirement already satisfied: anyio in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->llama-index-readers-web) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->llama-index-readers-web) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->llama-index-readers-web) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx>=0.28.1->llama-index-readers-web) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->llama-index-readers-web) (0.14.0)\n",
      "Requirement already satisfied: aiosqlite in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2025.5.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2.11.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (6.0.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (4.67.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.17.2)\n",
      "Requirement already satisfied: six<2,>=1.15 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from markdownify>=1.1.0->llama-index-readers-web) (1.17.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyee<14,>=13 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests<3,>=2.31.0->llama-index-readers-web) (3.4.1)\n",
      "Collecting trio~=0.30.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting certifi (from httpx>=0.28.1->llama-index-readers-web)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting websocket-client~=1.8.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: griffe in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (4.3.7)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: click in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.4.0)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (3.18.0)\n",
      "Collecting sortedcontainers (from trio~=0.30.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.30.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from trio~=0.30.0->selenium<5,>=4.17.2->llama-index-readers-web) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (1.1.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]~=2.4.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-readers-web) (3.0.2)\n",
      "Downloading llama_index_readers_web-0.4.1-py3-none-any.whl (101 kB)\n",
      "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-5.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading markdownify-1.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading oxylabs-2.0.0-py3-none-any.whl (34 kB)\n",
      "Downloading playwright-1.52.0-py3-none-manylinux1_x86_64.whl (45.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.33.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: html2text, tinysegmenter, spider-client, feedfinder2, jieba3k\n",
      "  Building wheel for html2text (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33168 sha256=05005bb055c6d0db7fec7c39e1e9dc4e476c0547b3209e0f8b52d0ecdd41d770\n",
      "  Stored in directory: /home/renato/.cache/pip/wheels/2b/01/23/578505d65e2a97d78bf1fe3fc8256ecf37572dc1df598b0eaf\n",
      "  Building wheel for tinysegmenter (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13634 sha256=e35c54798861c9942ff5f441068378b12286a831a510fc7691a078ca9a859eeb\n",
      "  Stored in directory: /home/renato/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for spider-client (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spider-client: filename=spider_client-0.0.27-py3-none-any.whl size=6052 sha256=944eeff53b135e81152571fc6e056c86609e76a29b05d52e7c7c2a184fdb60d9\n",
      "  Stored in directory: /home/renato/.cache/pip/wheels/6c/41/42/4155300999390be7e455a6b05c602849f5810bf9383c43adb2\n",
      "  Building wheel for feedfinder2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3393 sha256=4e403280d6aaf9beea318a0dcfa411a98000d664008a3f8e1065cdb32b3b24ae\n",
      "  Stored in directory: /home/renato/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398402 sha256=b854ce737d37ef2fb0921284d01d9e4bb58cda59bd67b4ac7bd04940db0e7401\n",
      "  Stored in directory: /home/renato/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "Successfully built html2text tinysegmenter spider-client feedfinder2 jieba3k\n",
      "Installing collected packages: tinysegmenter, sortedcontainers, sgmllib3k, jieba3k, wsproto, websocket-client, pysocks, pyee, outcome, lxml, html2text, feedparser, defusedxml, cssselect, chromedriver-autoinstaller, certifi, trio, playwright, markdownify, lxml-html-clean, trio-websocket, spider-client, requests-file, oxylabs, feedfinder2, tldextract, selenium, newspaper3k, llama-index-readers-web\n",
      "  Attempting uninstall: html2text\n",
      "    Found existing installation: html2text 2025.4.15\n",
      "    Uninstalling html2text-2025.4.15:\n",
      "      Successfully uninstalled html2text-2025.4.15\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "Successfully installed certifi-2025.4.26 chromedriver-autoinstaller-0.6.4 cssselect-1.3.0 defusedxml-0.7.1 feedfinder2-0.0.4 feedparser-6.0.11 html2text-2024.2.26 jieba3k-0.35.1 llama-index-readers-web-0.4.1 lxml-5.4.0 lxml-html-clean-0.4.2 markdownify-1.1.0 newspaper3k-0.2.8 outcome-1.3.0.post0 oxylabs-2.0.0 playwright-1.52.0 pyee-13.0.0 pysocks-1.7.1 requests-file-2.1.0 selenium-4.33.0 sgmllib3k-1.0.0 sortedcontainers-2.4.0 spider-client-0.0.27 tinysegmenter-0.3 tldextract-5.3.0 trio-0.30.0 trio-websocket-0.12.2 websocket-client-1.8.0 wsproto-1.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-tools-google\n",
      "  Downloading llama_index_tools_google-0.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-tools-google) (4.13.3)\n",
      "Collecting google-api-python-client<3,>=2.115.0 (from llama-index-tools-google)\n",
      "  Downloading google_api_python_client-2.170.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth-httplib2<0.3,>=0.2.0 (from llama-index-tools-google)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib<2,>=1.2.0 (from llama-index-tools-google)\n",
      "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-tools-google) (0.12.38)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-tools-google) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-tools-google) (4.13.2)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 (from google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from google-auth-oauthlib<2,>=1.2.0->llama-index-tools-google) (2.0.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.12.4)\n",
      "Requirement already satisfied: aiosqlite in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2025.5.1)\n",
      "Requirement already satisfied: httpx in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.2.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.11.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (4.67.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.20.0)\n",
      "Requirement already satisfied: griffe in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (4.3.7)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: click in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (2025.4.26)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=1.2.0->llama-index-tools-google) (3.2.2)\n",
      "Requirement already satisfied: greenlet>=1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.26.1)\n",
      "Requirement already satisfied: anyio in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (24.2)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama-index-tools-google)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (1.3.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-tools-google) (3.0.2)\n",
      "Downloading llama_index_tools_google-0.3.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading google_api_python_client-2.170.0-py3-none-any.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, protobuf, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, google-auth, google-auth-oauthlib, google-auth-httplib2, google-api-core, google-api-python-client, llama-index-tools-google\n",
      "Successfully installed cachetools-5.5.2 google-api-core-2.24.2 google-api-python-client-2.170.0 google-auth-2.40.2 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.2 googleapis-common-protos-1.70.0 httplib2-0.22.0 llama-index-tools-google-0.3.1 proto-plus-1.26.1 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pyparsing-3.2.3 rsa-4.9.1 uritemplate-4.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pip\n",
    "\n",
    "%pip install -qU openai\n",
    "%pip install -qU llama-index\n",
    "%pip install -qU llama_hub\n",
    "%pip install -qU llama-index-experimental\n",
    "%pip install llama-index-agent-openai\n",
    "%pip install llama-index-readers-web\n",
    "%pip install llama-index-tools-google\n",
    "\n",
    "#%pip install -q pypdf\n",
    "#%pip install -q docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG6gzO4zNdkB"
   },
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2T8UKZJNNdkC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<the key>\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import llama_index\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "## Llamaindex readers\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "## LlamaIndex Index Types\n",
    "from llama_index.core import ListIndex\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import TreeIndex\n",
    "from llama_index.core import KeywordTableIndex\n",
    "from llama_index.core import SimpleKeywordTableIndex\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "\n",
    "## LlamaIndex Context Managers\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.schema import Node\n",
    "\n",
    "## LlamaIndex Templates\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "## LlamaIndex Agents\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "## LlamaIndex Callbacks\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UlTWP4TITXbv"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "model=\"gpt-4o\"\n",
    "#model=\"gpt-4o-mini\"\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.llm = OpenAI(temperature=0, \n",
    "                      model=model, \n",
    "                      #max_tokens=512\n",
    "                      PRESENCE_PENALTY=-2,\n",
    "                      TOP_P=1,\n",
    "                     )\n",
    "\n",
    "llm = Settings.llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Function Tool  \n",
    "A function tool is a simple wrapper around any existing function (both sync and async are supported!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "def subtract(x: int, y: int) -> int: \n",
    "    \"\"\"Subtract the second number from the first number.\"\"\"\n",
    "    return (x - y)\n",
    "\n",
    "def multiply(x: int, y: int) -> int: \n",
    "    \"\"\"Multiply one number by the other number.\"\"\"\n",
    "    return (x * y)\n",
    "\n",
    "def uppercase(x: str) -> str: \n",
    "    \"\"\"Return the input string in uppercase.\"\"\"\n",
    "    return (x.upper())\n",
    "\n",
    "def square(x: int) -> int: \n",
    "    \"\"\"Return the square of the give number.\"\"\"\n",
    "    return (x + x)\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "uppercase_tool = FunctionTool.from_defaults(fn=uppercase)\n",
    "square_tool = FunctionTool.from_defaults(fn=square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: subtract with args: {\"x\": 3, \"y\": 12}\n",
      "=== Function Output ===\n",
      "-9\n",
      "-9\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [add_tool, \n",
    "     subtract_tool, \n",
    "     multiply_tool, \n",
    "     uppercase_tool,\n",
    "     square_tool,\n",
    "    ], \n",
    "    \"Tell me the output of 3 - 12 \", \n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is no criticism on the functioning of the tool; tools are called by similarity of query vs docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: square with args: {\"x\": 3}\n",
      "=== Function Output ===\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    [add_tool, \n",
    "     subtract_tool, \n",
    "     multiply_tool, \n",
    "     uppercase_tool,\n",
    "     square_tool,\n",
    "    ], \n",
    "    \"Tell me how much is three to the power of two\", \n",
    "    verbose=True\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- [Coding Assistant and Interpreter](https://llamahub.ai/l/tools/llama-index-tools-code-interpreter?from=)  \n",
    "[Github](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-code-interpreter/examples/code_interpreter.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-code_interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.code_interpreter import CodeInterpreterToolSpec\n",
    "\n",
    "code_spec = CodeInterpreterToolSpec()\n",
    "tools = code_spec.to_tool_list()\n",
    "agent = OpenAIAgent.from_tools(tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you help me write some python code to pass to the code_interpreter tool\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Of course! What would you like the Python code to do? If you have a specific task or problem in mind, please let me know, and I can help you write the code for it.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Can you help me write some python code to pass to the code_interpreter tool\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you check if there is a file named ../../Data/california_housing_train.csv?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Certainly! Here's a Python code snippet that checks if a file named `california_housing_train.csv` exists in the `../../Data/` directory:\n",
      "\n",
      "```python\n",
      "import os\n",
      "\n",
      "# Define the file path\n",
      "file_path = '../../Data/california_housing_train.csv'\n",
      "\n",
      "# Check if the file exists\n",
      "file_exists = os.path.isfile(file_path)\n",
      "\n",
      "# Output the result\n",
      "file_exists\n",
      "```\n",
      "\n",
      "Would you like me to run this code to check for the file's existence?\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Can you check if there is a file named ../../Data/california_housing_train.csv?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Please do\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import os\\n\\n# Define the file path\\nfile_path = '../../Data/california_housing_train.csv'\\n\\n# Check if the file exists\\nfile_exists = os.path.isfile(file_path)\\n\\n# Output the result\\nfile_exists\"}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import os\\n\\n# Define the file path\\nfile_path = '../../Data/california_housing_train.csv'\\n\\n# Check if the file exists\\nfile_exists = os.path.isfile(file_path)\\n\\n# Print the result\\nif file_exists:\\n    print('The file exists.')\\nelse:\\n    print('The file does not exist.')\"}\n",
      "Got output: StdOut:\n",
      "b'The file exists.\\n'\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The file `california_housing_train.csv` does exist in the `../../Data/` directory.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Please do\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you write and execute code to tell me its columns?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import pandas as pd\\n\\n# Load the CSV file\\nfile_path = '../../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Get the columns of the DataFrame\\ncolumns = data.columns.tolist()\\n\\n# Print the columns\\ncolumns\"}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import pandas as pd\\n\\n# Load the CSV file\\nfile_path = '../../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Get the columns of the DataFrame\\ncolumns = data.columns.tolist()\\n\\n# Print the columns\\nprint(columns)\"}\n",
      "Got output: StdOut:\n",
      "b\"['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\\n\"\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The columns in the `california_housing_train.csv` file are:\n",
      "\n",
      "1. `longitude`\n",
      "2. `latitude`\n",
      "3. `housing_median_age`\n",
      "4. `total_rooms`\n",
      "5. `total_bedrooms`\n",
      "6. `population`\n",
      "7. `households`\n",
      "8. `median_income`\n",
      "9. `median_house_value`\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\n",
    "        \"\"\"Can you write and execute code to tell me its columns?\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: In which country are these latitudes and longitudes?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The latitudes and longitudes in the `california_housing_train.csv` file are likely to be in the United States, specifically in the state of California. This is inferred from the context of the dataset name, which suggests it pertains to housing data in California.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"In which country are these latitudes and longitudes?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you make a graph of the median income per total rooms?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import matplotlib.pyplot as plt\\n\\n# Plot median income vs total rooms\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['median_income'], alpha=0.5)\\nplt.title('Median Income vs Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income')\\nplt.grid(True)\\nplt.show()\"}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b'Traceback (most recent call last):\\n  File \"<string>\", line 5, in <module>\\nNameError: name \\'data\\' is not defined\\n'\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the CSV file again\\nfile_path = '../../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Plot median income vs total rooms\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['median_income'], alpha=0.5)\\nplt.title('Median Income vs Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income')\\nplt.grid(True)\\nplt.show()\"}\n",
      "Got output: StdOut:\n",
      "b'Figure(1000x600)\\n'\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "I have created the graph of median income versus total rooms. However, I can't display the graph directly here. If you would like to see it, I can save it to a file and provide you with the file path. Would you like me to do that?\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Can you make a graph of the median income per total rooms?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: I cant see the plot - can you save it locally with file name `output.png`?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"# Save the plot to a file\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['median_income'], alpha=0.5)\\nplt.title('Median Income vs Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income')\\nplt.grid(True)\\nplt.savefig('output.png')\"}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b'Traceback (most recent call last):\\n  File \"<string>\", line 2, in <module>\\nNameError: name \\'plt\\' is not defined\\n'\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: code_interpreter with args: {\"code\":\"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Load the CSV file again\\nfile_path = '../../Data/california_housing_train.csv'\\ndata = pd.read_csv(file_path)\\n\\n# Save the plot to a file\\nplt.figure(figsize=(10, 6))\\nplt.scatter(data['total_rooms'], data['median_income'], alpha=0.5)\\nplt.title('Median Income vs Total Rooms')\\nplt.xlabel('Total Rooms')\\nplt.ylabel('Median Income')\\nplt.grid(True)\\nplt.savefig('output.png')\"}\n",
      "Got output: StdOut:\n",
      "b''\n",
      "StdErr:\n",
      "b''\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The plot has been saved as `output.png` in the current directory. You can open this file to view the graph of median income versus total rooms.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"I cant see the plot - can you save it locally with file name `output.png`?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- [SQL Agent](https://llamahub.ai/l/tools/llama-index-tools-database?from=)  \n",
    "[GitHub](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-database/examples/database.ipynb), [article](https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-database\n",
    "%pip install -q sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.database import DatabaseToolSpec\n",
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    insert,\n",
    "    text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SQL Database   \n",
    "\n",
    "We first define our SQLDatabase abstraction (a light wrapper around SQLAlchemy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add some testing data to our SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Chicago\", \"population\": 2679000, \"country\": \"United States\",},\n",
    "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Chicago', 2679000, 'United States'), ('Seoul', 9776000, 'South Korea')]\n"
     ]
    }
   ],
   "source": [
    "# view current table\n",
    "stmt = select(\n",
    "    city_stats_table.c.city_name,\n",
    "    city_stats_table.c.population,\n",
    "    city_stats_table.c.country,\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Index  \n",
    "We first show how we can execute a raw SQL query, which directly executes over the table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chicago',)\n",
      "('Seoul',)\n",
      "('Tokyo',)\n",
      "('Toronto',)\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as con:\n",
    "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Text-to-SQL Query Engine¶\n",
    "\n",
    "Once we have constructed our SQL database, we can use the NLSQLTableQueryEngine to construct natural language queries that are synthesized into SQL queries.\n",
    "\n",
    "Note that we need to specify the tables we want to use with this query engine. If we don't the query engine will pull all the schema context, which could overflow the context window of the LLM.\n",
    "\n",
    "This query engine should be used in any case where you can specify the tables you want to query over beforehand, or the total size of all the table schema plus the rest of the prompt fits your context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database, tables=[\"city_stats\"], llm=llm\n",
    ")\n",
    "query_str = \"Which city has the highest population?\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The city with the highest population is Tokyo, with a population of 13,960,000.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Query-Time Retrieval of Tables for Text-to-SQL\n",
    "\n",
    "If we don't know ahead of time which table we would like to use, and the total size of the table schema overflows your context window size, we should store the table schema in an index so that during query time we can retrieve the right schema.\n",
    "\n",
    "The way we can do this is using the SQLTableNodeMapping object, which takes in a SQLDatabase and produces a Node object for each SQLTableSchema object passed into the ObjectIndex constructor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "#from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\"))\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can take our SQLTableRetrieverQueryEngine and query it for our response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The city with the highest population is Tokyo, with a population of 13,960,000.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Which city has the highest population?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tokyo', 13960000)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also fetch the raw result from SQLAlchemy!\n",
    "response.metadata[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You could also add additional context information for each table schema you define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set context text\n",
    "city_stats_text = (\n",
    "    \"This table gives information regarding the population and country of a\"\n",
    "    \" given city.\\nThe user will query with codewords, where 'foo' corresponds\"\n",
    "    \" to population and 'bar'corresponds to city.\"\n",
    ")\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\", context_str=city_stats_text))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Text-to-SQL Retriever\n",
    "\n",
    "So far our text-to-SQL capability is packaged in a query engine and consists of both retrieval and synthesis.\n",
    "\n",
    "You can use the SQL retriever on its own. We show you some different parameters you can try, and also show how to plug it into our RetrieverQueryEngine to get roughly the same results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import NLSQLRetriever\n",
    "\n",
    "# default retrieval (return_raw=True)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"city_stats\"], return_raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "results = nl_sql_retriever.retrieve(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5a845067-09e9-4d13-8379-e3a7eca90ed3<br>**Similarity:** None<br>**Text:** [('Tokyo', 13960000), ('Seoul', 9776000), ('Toronto', 2930000), ('Chicago', 2679000)]<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for n in results:\n",
    "    display_source_node(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default retrieval (return_raw=False)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"city_stats\"], return_raw=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "results = nl_sql_retriever.retrieve(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8bd08b58-e4ef-49a2-a603-3a9efa3faf8a<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Tokyo', 'population': 13960000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b7142c9a-5030-4178-80d8-e8eaf51776e1<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Seoul', 'population': 9776000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 570e1535-a8be-4f17-b79c-cf278c276864<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Toronto', 'population': 2930000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5c70d1d8-788b-44e7-acd1-be1ddb5b3efb<br>**Similarity:** None<br>**Text:** <br>**Metadata:** {'city_name': 'Chicago', 'population': 2679000}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: all the content is in the metadata\n",
    "for n in results:\n",
    "    display_source_node(n, show_source_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plug into our RetrieverQueryEngine\n",
    "\n",
    "We compose our SQL Retriever with our standard RetrieverQueryEngine to synthesize a response. The result is roughly similar to our packaged Text-to-SQL query engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "> Table desc str: Table 'city_stats' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), .\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Return the top 5 cities (along with their populations) with the highest population.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tokyo - 13,960,000  \n",
      "2. Seoul - 9,776,000  \n",
      "3. Toronto - 2,930,000  \n",
      "4. Chicago - 2,679,000  \n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Database Tool\n",
    "\n",
    "This tool connects to a database (using SQLAlchemy under the hood) and allows an Agent to query the database and get information about the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The database contains a table named `city_stats`.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_tools = DatabaseToolSpec(sql_database)\n",
    "agent = OpenAIAgent.from_tools(db_tools.to_tool_list())\n",
    "\n",
    "agent.chat(\"What tables does this database contain\").response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The `city_stats` table has the following structure:\n",
      "\n",
      "- `city_name` (VARCHAR(16), NOT NULL): The name of the city, serving as the primary key.\n",
      "- `population` (INTEGER): The population of the city.\n",
      "- `country` (VARCHAR(16), NOT NULL): The country where the city is located.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Describe the first table\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The first row of the `city_stats` table contains the following data:\n",
      "\n",
      "- City Name: Toronto\n",
      "- Population: 2,930,000\n",
      "- Country: Canada\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"Retrieve the first row of that table\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Community Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) [Wikipedia Tool](https://llamahub.ai/l/tools/llama-index-tools-wikipedia?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-wikipedia/examples/wikipedia.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Ben Affleck's spouse is Jennifer Lopez. They got married in July 2022.\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.wikipedia import WikipediaToolSpec\n",
    "\n",
    "tool_spec = WikipediaToolSpec()\n",
    "\n",
    "agent = OpenAIAgent.from_tools(tool_spec.to_tool_list()) #, verbose=True,)\n",
    "\n",
    "response= agent.chat(\"Who is Ben Afflecks spouse?\")\n",
    "\n",
    "#print(response.sources)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) [Arxiv Tool](https://llamahub.ai/l/tools/llama-index-tools-arxiv?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/tools/llama-index-tools-arxiv)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Whats are the newest discoveries on Prompt Engineering?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: arxiv_query with args: {\"query\":\"Prompt Engineering\",\"sort_by\":\"recent\"}\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=Prompt+Engineering&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=Prompt+Engineering&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 100 of 98739 total results\n",
      "Got first page: 100 of 98739 total results\n",
      "Got output: [Document(id_='9f64bfde-5ffb-4a50-9e16-09b76991b20c', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='http://arxiv.org/pdf/2412.04471v1: PaintScene4D: Consistent 4D Scene Generation from Text Prompts\\nRecent advances in diffusion models have revolutionized 2D and 3D content\\ncreation, yet generating photorealistic dynamic 4D scenes remains a significant\\nchallenge. Existing dynamic 4D generation methods typically rely on distilling\\nknowledge from pre-trained 3D generative models, often fine-tuned on synthetic\\nobject datasets. Consequently, the resulting scenes tend to be object-centric\\nand lack photorealism. While text-to-video models can generate more realistic\\nscenes with motion, they often struggle with spatial understanding and provide\\nlimited control over camera viewpoints during rendering. To address these\\nlimitations, we present PaintScene4D, a novel text-to-4D scene generation\\nframework that departs from conventional multi-view generative models in favor\\nof a streamlined architecture that harnesses video generative models trained on\\ndiverse real-world datasets. Our method first generates a reference video using\\na video generation model, and then employs a strategic camera array selection\\nfor rendering. We apply a progressive warping and inpainting technique to\\nensure both spatial and temporal consistency across multiple viewpoints.\\nFinally, we optimize multi-view images using a dynamic renderer, enabling\\nflexible camera control based on user preferences. Adopting a training-free\\narchitecture, our PaintScene4D efficiently produces realistic 4D scenes that\\ncan be viewed from arbitrary trajectories. The code will be made publicly\\navailable. Our project page is at https://paintscene4d.github.io/', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), Document(id_='acf2a6ae-fcf8-47df-b313-272c0cfcdfc3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"http://arxiv.org/pdf/2412.04465v1: UnZipLoRA: Separating Content and Style from a Single Image\\nThis paper introduces UnZipLoRA, a method for decomposing an image into its\\nconstituent subject and style, represented as two distinct LoRAs (Low-Rank\\nAdaptations). Unlike existing personalization techniques that focus on either\\nsubject or style in isolation, or require separate training sets for each,\\nUnZipLoRA disentangles these elements from a single image by training both the\\nLoRAs simultaneously. UnZipLoRA ensures that the resulting LoRAs are\\ncompatible, i.e., they can be seamlessly combined using direct addition.\\nUnZipLoRA enables independent manipulation and recontextualization of subject\\nand style, including generating variations of each, applying the extracted\\nstyle to new subjects, and recombining them to reconstruct the original image\\nor create novel variations. To address the challenge of subject and style\\nentanglement, UnZipLoRA employs a novel prompt separation technique, as well as\\ncolumn and block separation strategies to accurately preserve the\\ncharacteristics of subject and style, and ensure compatibility between the\\nlearned LoRAs. Evaluation with human studies and quantitative metrics\\ndemonstrates UnZipLoRA's effectiveness compared to other state-of-the-art\\nmethods, including DreamBooth-LoRA, Inspiration Tree, and B-LoRA.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), Document(id_='cec0a1a1-2d48-423e-8685-3556915da7cd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='http://arxiv.org/pdf/2412.04455v1: Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection\\nAutomatic detection and prevention of open-set failures are crucial in\\nclosed-loop robotic systems. Recent studies often struggle to simultaneously\\nidentify unexpected failures reactively after they occur and prevent\\nforeseeable ones proactively. To this end, we propose Code-as-Monitor (CaM), a\\nnovel paradigm leveraging the vision-language model (VLM) for both open-set\\nreactive and proactive failure detection. The core of our method is to\\nformulate both tasks as a unified set of spatio-temporal constraint\\nsatisfaction problems and use VLM-generated code to evaluate them for real-time\\nmonitoring. To enhance the accuracy and efficiency of monitoring, we further\\nintroduce constraint elements that abstract constraint-related entities or\\ntheir parts into compact geometric elements. This approach offers greater\\ngenerality, simplifies tracking, and facilitates constraint-aware visual\\nprogramming by leveraging these elements as visual prompts. Experiments show\\nthat CaM achieves a 28.7% higher success rate and reduces execution time by\\n31.8% under severe disturbances compared to baselines across three simulators\\nand a real-world setting. Moreover, CaM can be integrated with open-loop\\ncontrol policies to form closed-loop systems, enabling long-horizon tasks in\\ncluttered scenes with dynamic environments.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are some of the newest discoveries related to Prompt Engineering:\n",
      "\n",
      "1. **PaintScene4D: Consistent 4D Scene Generation from Text Prompts**  \n",
      "   This research introduces PaintScene4D, a novel framework for generating photorealistic 4D scenes from text prompts. It leverages video generative models trained on diverse real-world datasets to create dynamic 4D scenes with spatial and temporal consistency. The method allows flexible camera control and does not require training, making it efficient for producing realistic 4D scenes. [Read more](http://arxiv.org/pdf/2412.04471v1)\n",
      "\n",
      "2. **UnZipLoRA: Separating Content and Style from a Single Image**  \n",
      "   UnZipLoRA is a method for decomposing an image into its subject and style using Low-Rank Adaptations (LoRAs). It enables independent manipulation and recontextualization of subject and style, allowing for the generation of variations and novel combinations. The method employs a novel prompt separation technique to ensure compatibility between the learned LoRAs. [Read more](http://arxiv.org/pdf/2412.04465v1)\n",
      "\n",
      "3. **Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection**  \n",
      "   This study presents Code-as-Monitor (CaM), a paradigm using vision-language models for detecting robotic failures. It formulates failure detection as spatio-temporal constraint satisfaction problems, using VLM-generated code for real-time monitoring. The approach enhances monitoring accuracy and efficiency, achieving higher success rates and reduced execution times in dynamic environments. [Read more](http://arxiv.org/pdf/2412.04455v1)\n",
      "\n",
      "These papers highlight advancements in generating complex scenes from text prompts, decomposing images for style and content manipulation, and using visual prompts for robotic failure detection.\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.arxiv.base import ArxivToolSpec\n",
    "\n",
    "arxiv_tool = ArxivToolSpec()\n",
    "\n",
    "agent = OpenAIAgent.from_tools(arxiv_tool.to_tool_list(), verbose=True,)\n",
    "\n",
    "print(agent.chat(\"Whats are the newest discoveries on Prompt Engineering?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) [DuckDuckGoSearch Tool](https://llamahub.ai/l/tools/llama-index-tools-duckduckgo?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/tools/llama-index-tools-duckduckgo/examples/duckduckgo_search.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-duckduckgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: what are the latest developments in machine learning\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: duckduckgo_full_search with args: {\"query\":\"latest developments in machine learning\",\"max_results\":5}\n",
      "INFO:primp:response: https://duckduckgo.com/?q=latest+developments+in+machine+learning 200 18991\n",
      "response: https://duckduckgo.com/?q=latest+developments+in+machine+learning 200 18991\n",
      "INFO:primp:response: https://links.duckduckgo.com/d.js?q=latest+developments+in+machine+learning&kl=wt-wt&l=wt-wt&p=&s=0&df=&vqd=4-146566751269094499179007859444480573369&bing_market=wt-WT&ex=-1 200 11621\n",
      "response: https://links.duckduckgo.com/d.js?q=latest+developments+in+machine+learning&kl=wt-wt&l=wt-wt&p=&s=0&df=&vqd=4-146566751269094499179007859444480573369&bing_market=wt-WT&ex=-1 200 11621\n",
      "Got output: [{'title': 'Latest Developments in Machine Learning: 2024 Update', 'href': 'https://waleed.dev/Blog/latest-developments-in-machine-learning-2024-update', 'body': \"Some of the latest developments in machine learning that are shaping the industry in 2024 include: Generative AI - Models like DALL-E 3, Stable Diffusion, and Google's Imagen are producing highly realistic synthetic images and videos. This has implications for content creation, entertainment, art, and more. ...\"}, {'title': '10 top AI and machine learning trends for 2024 - TechTarget', 'href': 'https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends', 'body': \"This year's trends reflect a deepening sophistication and caution in AI development and deployment strategies, with an eye to ethics, safety and the evolving regulatory landscape. Here are the top 10 AI and machine learning trends to prepare for in 2024. 1. Multimodal AI\"}, {'title': 'The latest in Machine Learning | Papers With Code', 'href': 'https://paperswithcode.com/', 'body': 'Papers With Code highlights trending Machine Learning research and the code to implement it. ... Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Read previous issues. Subscribe.'}, {'title': 'Machine learning | MIT News | Massachusetts Institute of Technology', 'href': 'https://news.mit.edu/topic/machine-learning', 'body': 'Machine learning. Download RSS feed: News Articles / In the Media / Audio. Displaying 1 - 15 of 974 news articles related to this topic. Show: News Articles. In the Media. Audio ... A new design tool uses UV and RGB lights to change the color and textures of everyday objects. The system could enable surfaces to display dynamic patterns, such as ...'}, {'title': \"What's next for AI in 2024 | MIT Technology Review\", 'href': 'https://www.technologyreview.com/2024/01/04/1086046/whats-next-for-ai-in-2024/', 'body': \"Its latest model, called Gen-2, still generates video just a few seconds long, but the quality is striking. The best clips aren't far off what Pixar might put out.\"}]\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.duckduckgo import DuckDuckGoSearchToolSpec\n",
    "\n",
    "tool_spec = DuckDuckGoSearchToolSpec()\n",
    "\n",
    "agent = OpenAIAgent.from_tools(DuckDuckGoSearchToolSpec().to_tool_list(), verbose=True,)\n",
    "response = agent.chat(\"what are the latest developments in machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some of the latest developments in machine learning:\n",
      "\n",
      "1. **Generative AI**: Models like DALL-E 3, Stable Diffusion, and Google's Imagen are producing highly realistic synthetic images and videos. This has significant implications for content creation, entertainment, and art. [Read more](https://waleed.dev/Blog/latest-developments-in-machine-learning-2024-update).\n",
      "\n",
      "2. **AI and Machine Learning Trends for 2024**: The trends reflect a deepening sophistication and caution in AI development, focusing on ethics, safety, and the evolving regulatory landscape. One of the key trends is Multimodal AI. [Read more](https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends).\n",
      "\n",
      "3. **Trending Machine Learning Research**: Papers With Code highlights trending machine learning research and provides the code to implement it. This includes the latest research developments, libraries, methods, and datasets. [Explore more](https://paperswithcode.com/).\n",
      "\n",
      "4. **MIT News on Machine Learning**: MIT News covers a wide range of machine learning topics, including new design tools that use UV and RGB lights to change the color and textures of everyday objects. [Learn more](https://news.mit.edu/topic/machine-learning).\n",
      "\n",
      "5. **AI in 2024**: The latest AI models, such as Gen-2, are generating high-quality video clips that are comparable to professional animations. [Discover more](https://www.technologyreview.com/2024/01/04/1086046/whats-next-for-ai-in-2024/).\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Who is Goethe?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: duckduckgo_instant_search with args: {\"query\":\"Goethe\"}\n",
      "INFO:primp:response: https://api.duckduckgo.com/?q=what+is+Goethe&format=json 200 19169\n",
      "response: https://api.duckduckgo.com/?q=what+is+Goethe&format=json 200 19169\n",
      "INFO:primp:response: https://api.duckduckgo.com/?q=Goethe&format=json 200 6629\n",
      "response: https://api.duckduckgo.com/?q=Goethe&format=json 200 6629\n",
      "Got output: [{'icon': None, 'text': \"Johann Wolfgang von Goethe was a German polymath, who is widely regarded as the greatest and most influential writer in the German language. His work has had a profound and wide-ranging influence on Western literary, political, and philosophical thought from the late 18th century to the present day. A poet, playwright, novelist, scientist, statesman, theatre director, and critic, his works include plays, poetry and aesthetic criticism, as well as treatises on botany, anatomy, and color. Goethe took up residence in Weimar in November 1775 following the success of his first novel, The Sorrows of Young Werther, and joined a thriving intellectual and cultural environment under the patronage of Duchess Anna Amalia that had already included Abel Seyler's theatre company and Christoph Martin Wieland, and that formed the basis of Weimar Classicism. He was ennobled by the Duke of Saxe-Weimar, Karl August, in 1782. Goethe was an early participant in the Sturm und Drang literary movement.\", 'topic': None, 'url': 'https://en.wikipedia.org/wiki/Johann_Wolfgang_von_Goethe'}, {'icon': 'https://duckduckgo.com/i/edd6fba6.jpg', 'text': 'Johann Wolfgang von Goethe A German poet, playwright, novelist, scientist, statesman, theatre director, and critic.', 'topic': None, 'url': 'https://duckduckgo.com/Johann_Wolfgang_von_Goethe'}, {'icon': 'https://duckduckgo.com/i/c819f955.png', 'text': 'Goethe University Frankfurt A university located in Frankfurt am Main, Germany.', 'topic': None, 'url': 'https://duckduckgo.com/Goethe_University_Frankfurt'}, {'icon': 'https://duckduckgo.com/i/www.goethe.de.ico', 'text': 'Goethe-Institut A non-profit German cultural association operational worldwide with 159 institutes, promoting the...', 'topic': None, 'url': 'https://duckduckgo.com/Goethe-Institut'}, {'icon': '', 'text': \"Goethe (grape) Goethe is one of the collection of grape varieties known as Rogers' Hybrids, created by E.S.\", 'topic': None, 'url': 'https://duckduckgo.com/Goethe_(grape)'}, {'icon': 'https://duckduckgo.com/i/6eff7e53.jpg', 'text': 'Goethe (train) An express train that, for most of its existence, linked Paris-Est in Paris, France, with...', 'topic': None, 'url': 'https://duckduckgo.com/Goethe_(train)'}, {'icon': 'https://duckduckgo.com/i/71aac73b.gif', 'text': '3047 Goethe A bright background asteroid from the central regions of the asteroid belt, approximately in...', 'topic': None, 'url': 'https://duckduckgo.com/3047_Goethe'}, {'icon': 'https://duckduckgo.com/i/c71989d7.jpg', 'text': 'Goethe! A 2010 German historical drama film directed by Philipp Stölzl and starring Alexander Fehling...', 'topic': None, 'url': 'https://duckduckgo.com/Young_Goethe_in_Love'}, {'icon': '', 'text': 'Mount Goethe A summit in Fresno County, California, in the United States.', 'topic': None, 'url': 'https://duckduckgo.com/Mount_Goethe'}, {'icon': '', 'text': 'Goethe Awards An American series of comic book fan awards, first presented in 1971 for comics published in 1970.', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Awards'}, {'icon': 'https://duckduckgo.com/i/b41b9fb4.jpg', 'text': 'Goethe Prize An award for achievement \"worthy of honour in memory of Johann Wolfgang von Goethe\" made by the...', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Prize'}, {'icon': '', 'text': 'Goethe Medal A yearly prize given by the Goethe-Institut honoring non-Germans \"who have performed outstanding...', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Medal'}, {'icon': '', 'text': 'Goethe Basin An impact basin at 81.4° N, 54.3° W on Mercury approximately 317 kilometers in diameter.', 'topic': 'See also', 'url': 'https://duckduckgo.com/Goethe_Basin'}, {'icon': '', 'text': \"Goethe (surname) See related meanings for the phrase 'Goethe (surname)'.\", 'topic': 'See also', 'url': 'https://duckduckgo.com/d/Goethe_(surname)'}, {'icon': '', 'text': \"Gote See related meanings for the word 'Gote'.\", 'topic': 'See also', 'url': 'https://duckduckgo.com/d/Gote'}]\n",
      "========================\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Johann Wolfgang von Goethe was a German polymath, widely regarded as the greatest and most influential writer in the German language. His work has had a profound and wide-ranging influence on Western literary, political, and philosophical thought from the late 18th century to the present day. Goethe was a poet, playwright, novelist, scientist, statesman, theatre director, and critic. His works include plays, poetry, aesthetic criticism, and treatises on botany, anatomy, and color.\n",
      "\n",
      "Goethe took up residence in Weimar in November 1775 following the success of his first novel, \"The Sorrows of Young Werther,\" and joined a thriving intellectual and cultural environment under the patronage of Duchess Anna Amalia. He was ennobled by the Duke of Saxe-Weimar, Karl August, in 1782. Goethe was an early participant in the Sturm und Drang literary movement.\n",
      "\n",
      "For more information, you can visit [his Wikipedia page](https://en.wikipedia.org/wiki/Johann_Wolfgang_von_Goethe).\n"
     ]
    }
   ],
   "source": [
    "agent.chat_history.clear()\n",
    "print(agent.chat(\"Who is Goethe?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) [Yahoo Finance Tool](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/)  \n",
    "[Github](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/tools/llama-index-tools-yahoo-finance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-yahoo-finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The current price of Apple Inc. (AAPL) stock is $242.84.\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.yahoo_finance import YahooFinanceToolSpec\n",
    "\n",
    "tool_spec = YahooFinanceToolSpec()\n",
    "agent = OpenAIAgent.from_tools(tool_spec.to_tool_list())\n",
    "\n",
    "print(agent.chat(\"What is the price of Apple stock?\").response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are the latest news headlines about Apple Inc. (AAPL):\n",
      "\n",
      "1. **Apple Inc. (AAPL) to Launch In-House Modem and AI-Powered iPhone SE in 2024, Reducing Reliance on Qualcomm** - Apple plans to introduce its own modem and an AI-powered iPhone SE next year.\n",
      "\n",
      "2. **Apple co-founder Steve Jobs reminded Gap's former CEO why micromanaging is OK** - A reflection on Steve Jobs' management style and its impact.\n",
      "\n",
      "3. **Dow Jones Futures: Nasdaq Near 20,000 But Risks Mount; Nvidia, Meta In Buy Zones** - A broader market update mentioning Apple in the context of Nasdaq's performance.\n",
      "\n",
      "4. **Prediction: This Artificial Intelligence (AI) Company Will Be Acquired in 2025** - Speculative news about potential acquisitions in the tech industry.\n",
      "\n",
      "5. **Advertising Firms Omnicom and Interpublic Nearing Merger That Would Reshape Industry** - Industry news that could indirectly affect Apple.\n",
      "\n",
      "6. **Give People What They Really Want: Digital Gifts** - A trend piece on digital gifting.\n",
      "\n",
      "7. **Bluesky promises to shake up social media. It might finally succeed.** - News about potential changes in the social media landscape.\n",
      "\n",
      "8. **2 key inflation prints loom ahead of Fed rate cut decision: What to know this week** - Economic news that could impact the stock market, including Apple.\n",
      "\n",
      "These headlines provide a mix of direct news about Apple's upcoming products and broader market and industry trends.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"What is the latest news about Apple?\").response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) [Open Weather Map Tool](https://llamahub.ai/l/tools/llama-index-tools-weather?from=tools)  \n",
    "[Github](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/tools/llama-index-tools-weather)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-tools-weather\n",
    "%pip install -q pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"In Paris, the current weather is as follows:\\n- Detailed status: moderate rain\\n- Wind speed: 7.2 m/s, direction: 290°\\n- Humidity: 77%\\n- Temperature: \\n  - Current: 14.88°C\\n  - High: 16.64°C\\n  - Low: 12.78°C\\n  - Feels like: 14.43°C\\n- Rain: {'1h': 0.12}\\n- Heat index: None\\n- Cloud cover: 75%\", sources=[ToolOutput(content='[Document(id_=\\'09ac82fa-8c96-472c-bac3-31727d21cc3b\\', embedding=None, metadata={\\'weather from\\': \\'Paris\\'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Paris, the current weather is as follows:\\\\nDetailed status: moderate rain\\\\nWind speed: 7.2 m/s, direction: 290°\\\\nHumidity: 77%\\\\nTemperature: \\\\n  - Current: 14.88°C\\\\n  - High: 16.64°C\\\\n  - Low: 12.78°C\\\\n  - Feels like: 14.43°C\\\\nRain: {\\'1h\\': 0.12}\\\\nHeat index: None\\\\nCloud cover: 75%\", start_char_idx=None, end_char_idx=None, text_template=\\'{metadata_str}\\\\n\\\\n{content}\\', metadata_template=\\'{key}: {value}\\', metadata_seperator=\\'\\\\n\\')]', tool_name='weather_at_location', raw_input={'args': (), 'kwargs': {'location': 'Paris'}}, raw_output=[Document(id_='09ac82fa-8c96-472c-bac3-31727d21cc3b', embedding=None, metadata={'weather from': 'Paris'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Paris, the current weather is as follows:\\nDetailed status: moderate rain\\nWind speed: 7.2 m/s, direction: 290°\\nHumidity: 77%\\nTemperature: \\n  - Current: 14.88°C\\n  - High: 16.64°C\\n  - Low: 12.78°C\\n  - Feels like: 14.43°C\\nRain: {'1h': 0.12}\\nHeat index: None\\nCloud cover: 75%\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')], is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.tools.weather import OpenWeatherMapToolSpec\n",
    "\n",
    "os.environ[\"OPENWEATHER_API_KEY\"]=\"your key\"\n",
    "\n",
    "## https://openweathermap.org/api\n",
    "tool_spec = OpenWeatherMapToolSpec(key=os.environ[\"OPENWEATHER_API_KEY\"])\n",
    "\n",
    "agent = OpenAIAgent.from_tools(tool_spec.to_tool_list())\n",
    "\n",
    "agent.chat(\"What is the temperature like in Paris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"In Vienna, the current weather is as follows:\\n- Detailed status: light rain\\n- Wind speed: 2.57 m/s, direction: 210°\\n- Humidity: 86%\\n- Temperature: \\n  - Current: 17.13°C\\n  - High: 18.93°C\\n  - Low: 15.64°C\\n  - Feels like: 17.14°C\\n- Rain: {'1h': 0.23}\\n- Heat index: None\\n- Cloud cover: 20%\", sources=[ToolOutput(content='[Document(id_=\\'5153a3c3-5dad-4193-b3e5-15d3e0bc10a6\\', embedding=None, metadata={\\'weather from\\': \\'Vienna\\'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Vienna, the current weather is as follows:\\\\nDetailed status: light rain\\\\nWind speed: 2.57 m/s, direction: 210°\\\\nHumidity: 86%\\\\nTemperature: \\\\n  - Current: 17.13°C\\\\n  - High: 18.93°C\\\\n  - Low: 15.64°C\\\\n  - Feels like: 17.14°C\\\\nRain: {\\'1h\\': 0.23}\\\\nHeat index: None\\\\nCloud cover: 20%\", start_char_idx=None, end_char_idx=None, text_template=\\'{metadata_str}\\\\n\\\\n{content}\\', metadata_template=\\'{key}: {value}\\', metadata_seperator=\\'\\\\n\\')]', tool_name='weather_at_location', raw_input={'args': (), 'kwargs': {'location': 'Vienna'}}, raw_output=[Document(id_='5153a3c3-5dad-4193-b3e5-15d3e0bc10a6', embedding=None, metadata={'weather from': 'Vienna'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=\"In Vienna, the current weather is as follows:\\nDetailed status: light rain\\nWind speed: 2.57 m/s, direction: 210°\\nHumidity: 86%\\nTemperature: \\n  - Current: 17.13°C\\n  - High: 18.93°C\\n  - Low: 15.64°C\\n  - Feels like: 17.14°C\\nRain: {'1h': 0.23}\\nHeat index: None\\nCloud cover: 20%\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')], is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"What is the temperature in Vienna today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- [OnDemandLoaderTool](https://docs.llamaindex.ai/en/stable/examples/tools/OnDemandLoaderTool/)  \n",
    "\n",
    "OnDemandLoaderTool is a powerful agent tool that allows for \"on-demand\" data querying from any data source on LlamaHub.  \n",
    "\n",
    "This tool takes in a BaseReader data loader, and when called will 1) load data, 2) index data, and 3) query the data.  \n",
    "\n",
    "In this walkthrough, we show how to use the OnDemandLoaderTool to convert our Wikipedia data loader into an accessible search tool for a LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-readers-wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools.ondemand_loader_tool import OnDemandLoaderTool\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tool¶\n",
    "\n",
    "First it is defined the WikipediaReader. Note that the load_data interface to WikipediaReader takes in a list of pages.   \n",
    "By default, this queries the Wikipedia search endpoint which will autosuggest the relevant pages.  \n",
    "Then it wraps it into our OnDemandLoaderTool.  \n",
    "By default since we don't specify the index_cls, a simple vector store index is initialized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolOutput(content=\"Berlin has a rich and diverse arts and culture scene. The city is known for its vibrant nightlife, with a history of being a hub for punk music and culture, and a premier nightlife venue for people from all over the world. It has many nightclubs, and is known for its uninhibited parties. Berlin also has a long history of gay culture and hosts a number of queer clubs and festivals.\\n\\nThe city is home to 44 theaters and stages, including the Deutsches Theater, the Volksbühne, and the Berliner Ensemble. It also has three major opera houses: the Deutsche Oper, the Berlin State Opera, and the Komische Oper. The city's main venue for musical theater performances are the Theater am Potsdamer Platz and Theater des Westens. Contemporary dance can be seen at the Radialsystem V.\\n\\nBerlin also hosts the Berlin International Film Festival, which is considered to be the largest publicly attended film festival in the world. Other cultural festivals include the Karneval der Kulturen, Berliner Festspiele, JazzFest Berlin, and Young Euro Classic. The city also hosts one of the largest New Year's Eve celebrations in the world.\\n\\nIn terms of cuisine, Berlin offers a wide variety, with 23 restaurants awarded one or more Michelin stars. The city is known for its vegetarian and vegan cuisine, as well as its street food. The cuisine reflects the city's immigrant history, with Turkish, Arab, Chinese, Vietnamese, Thai, Indian, Korean, Japanese, Spanish, Italian, and Greek food available in many parts of the city.\", tool_name='Wikipedia Tool', raw_input={'query': \"What's the arts and culture scene in Berlin?\"}, raw_output=Response(response=\"Berlin has a rich and diverse arts and culture scene. The city is known for its vibrant nightlife, with a history of being a hub for punk music and culture, and a premier nightlife venue for people from all over the world. It has many nightclubs, and is known for its uninhibited parties. Berlin also has a long history of gay culture and hosts a number of queer clubs and festivals.\\n\\nThe city is home to 44 theaters and stages, including the Deutsches Theater, the Volksbühne, and the Berliner Ensemble. It also has three major opera houses: the Deutsche Oper, the Berlin State Opera, and the Komische Oper. The city's main venue for musical theater performances are the Theater am Potsdamer Platz and Theater des Westens. Contemporary dance can be seen at the Radialsystem V.\\n\\nBerlin also hosts the Berlin International Film Festival, which is considered to be the largest publicly attended film festival in the world. Other cultural festivals include the Karneval der Kulturen, Berliner Festspiele, JazzFest Berlin, and Young Euro Classic. The city also hosts one of the largest New Year's Eve celebrations in the world.\\n\\nIn terms of cuisine, Berlin offers a wide variety, with 23 restaurants awarded one or more Michelin stars. The city is known for its vegetarian and vegan cuisine, as well as its street food. The cuisine reflects the city's immigrant history, with Turkish, Arab, Chinese, Vietnamese, Thai, Indian, Korean, Japanese, Spanish, Italian, and Greek food available in many parts of the city.\", source_nodes=[NodeWithScore(node=TextNode(id_='af87073a-a1a3-4d11-a28e-c951f32aae49', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3354', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='694dbc56c4449f00addfa9d97ba64df9b1bf7f32ce1ba3f61c2fc04e8b562baf'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b9824a06-6f30-4b01-98c0-175d1e18fe1b', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='794667dfdc2dfb766a086d1a3d64c811d1e86e682da58a1c4aababae3e81506c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0140ff4e-11d3-4368-bae2-d2ec323a24f1', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9e4d6a6c9670dd3861a30f0d72b7aae960b7adc667534f29664ca302c3dc73ec')}, text=\"=== Nightlife and festivals ===\\n\\nBerlin's nightlife has been celebrated as one of the most diverse and vibrant of its kind. In the 1970s and 80s, the SO36 in Kreuzberg was a center for punk music and culture. The SOUND and the Dschungel gained notoriety. Throughout the 1990s, people in their 20s from all over the world, particularly those in Western and Central Europe, made Berlin's club scene a premier nightlife venue. After the fall of the Berlin Wall in 1989, many historic buildings in Mitte, the former city center of East Berlin, were illegally occupied and re-built by young squatters and became a fertile ground for underground and counterculture gatherings. The central boroughs are home to many nightclubs, including the Watergate, Tresor and Berghain. The KitKatClub and several other locations are known for their sexually uninhibited parties.\\nClubs are not required to close at a fixed time during the weekends, and many parties last well into the morning or even all weekend. The Weekend Club near Alexanderplatz features a roof terrace that allows partying at night. Several venues have become a popular stage for the Neo-Burlesque scene.\\n\\nBerlin has a long history of gay culture, and is an important birthplace of the LGBT rights movement. Same-sex bars and dance halls operated freely as early as the 1880s, and the first gay magazine, Der Eigene, started in 1896. By the 1920s, gays and lesbians had an unprecedented visibility. Today, in addition to a positive atmosphere in the wider club scene, the city again has a huge number of queer clubs and festivals. The most famous and largest are Berlin Pride, the Christopher Street Day, the Lesbian and Gay City Festival in Berlin-Schöneberg, the Kreuzberg Pride.\\nThe annual Berlin International Film Festival (Berlinale) with around 500,000 admissions is considered to be the largest publicly attended film festival in the world. The Karneval der Kulturen (Carnival of Cultures), a multi-ethnic street parade, is celebrated every Pentecost weekend. Berlin is also well known for the cultural festival Berliner Festspiele, which includes the jazz festival JazzFest Berlin, and Young Euro Classic, the largest international festival of youth orchestras in the world. Several technology and media art festivals and conferences are held in the city, including Transmediale and Chaos Communication Congress. The annual Berlin Festival focuses on indie rock, electronic music and synthpop and is part of the International Berlin Music Week. Every year Berlin hosts one of the largest New Year's Eve celebrations in the world, attended by well over a million people. The focal point is the Brandenburg Gate, where midnight fireworks are centered, but various private fireworks displays take place throughout the entire city. Partygoers in Germany often toast the New Year with a glass of sparkling wine.\", start_char_idx=65875, end_char_idx=68743, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8748883465802275), NodeWithScore(node=TextNode(id_='0140ff4e-11d3-4368-bae2-d2ec323a24f1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3354', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='694dbc56c4449f00addfa9d97ba64df9b1bf7f32ce1ba3f61c2fc04e8b562baf'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='af87073a-a1a3-4d11-a28e-c951f32aae49', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='13a52a6eadaac5f23b46f425b978208ecb0fddc6651f3596176b8e06b7fb8c7c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5806991c-2497-4c7b-8923-940ba6b5e608', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1a49e873a004985fc911edc086f4b9d58ad65cd1556c83526d7237f4ef0d9e0b')}, text='=== Performing arts ===\\n\\nBerlin is home to 44 theaters and stages. The Deutsches Theater in Mitte was built in 1849–50 and has operated almost continuously since then. The Volksbühne at Rosa-Luxemburg-Platz was built in 1913–14, though the company had been founded in 1890. The Berliner Ensemble, famous for performing the works of Bertolt Brecht, was established in 1949. The Schaubühne was founded in 1962 and moved to the building of the former Universum Cinema on Kurfürstendamm in 1981. With a seating capacity of 1,895 and a stage floor of 2,854 square meters (30,720 sq ft), the Friedrichstadt-Palast in Berlin Mitte is the largest show palace in Europe. For Berlin\\'s independent dance and theatre scene, venues such as the Sophiensäle in Mitte and the three houses of the Hebbel am Ufer (HAU) in Kreuzberg are important. Most productions there are also accessible to an English-speaking audience. Some of the dance and theatre groups that also work internationally (Gob Squad, Rimini Protokoll) are based there, as well as festivals such as the international festival Dance in August.\\nBerlin has three major opera houses: the Deutsche Oper, the Berlin State Opera, and the Komische Oper. The Berlin State Opera on Unter den Linden opened in 1742 and is the oldest of the three. Its musical director is Daniel Barenboim. The Komische Oper has traditionally specialized in operettas and is also at Unter den Linden. The Deutsche Oper opened in 1912 in Charlottenburg.\\nThe city\\'s main venue for musical theater performances are the Theater am Potsdamer Platz and Theater des Westens (built in 1895). Contemporary dance can be seen at the Radialsystem V. The Tempodrom is host to concerts and circus-inspired entertainment. It also houses a multi-sensory spa experience. The Admiralspalast in Mitte has a vibrant program of variety and music events.\\nThere are seven symphony orchestras in Berlin. The Berlin Philharmonic Orchestra is one of the preeminent orchestras in the world; it is housed in the Berliner Philharmonie near Potsdamer Platz on a street named for the orchestra\\'s longest-serving conductor, Herbert von Karajan. Simon Rattle was its principal conductor from 1999 to 2018, a position now held by Kirill Petrenko. The Konzerthausorchester Berlin was founded in 1952 as the orchestra for East Berlin. Christoph Eschenbach is its principal conductor. The Haus der Kulturen der Welt presents exhibitions dealing with intercultural issues and stages world music and conferences. The Kookaburra and the Quatsch Comedy Club are known for satire and comedy shows. In 2018, the New York Times described Berlin as \"arguably the world capital of underground electronic music\".\\n\\n\\n=== Cuisine ===\\n\\nThe cuisine and culinary offerings of Berlin vary greatly. 23 restaurants in Berlin have been awarded one or more Michelin stars in the Michelin Guide of 2021, which ranks the city at the top for the number of restaurants having this distinction in Germany. Berlin is well known for its offerings of vegetarian and vegan cuisine and is home to an innovative entrepreneurial food scene promoting cosmopolitan flavors, local and sustainable ingredients, pop-up street food markets, supper clubs, as well as food festivals, such as Berlin Food Week.\\nMany local foods originated from north German culinary traditions and include rustic and hearty dishes with pork, goose, fish, peas, beans, cucumbers, or potatoes. Typical Berliner fare include popular street food like the Currywurst (which gained popularity with postwar construction workers rebuilding the city), Buletten and the Berliner donut, known in Berlin as Pfannkuchen (German: [ˈp͡fanˌkuːxn̩] ). German bakeries offering a variety of breads and pastries are widespread. One of Europe\\'s largest delicatessen markets is found at the KaDeWe, and among the world\\'s largest chocolate stores is Rausch.\\nBerlin is also home to a diverse gastronomy scene reflecting the immigrant history of the city. Turkish and Arab immigrants brought their culinary traditions to the city, such as the lahmajoun and falafel, which have become common fast food staples. The modern fast-food version of the doner kebab sandwich which evolved in Berlin in the 1970s, has since become a favorite dish in Germany and elsewhere in the world. Asian cuisine like Chinese, Vietnamese, Thai, Indian, Korean, and Japanese restaurants, as well as Spanish tapas bars, Italian, and Greek cuisine, can be found in many parts of the city.', start_char_idx=68746, end_char_idx=73210, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8711962382361889)], metadata={'af87073a-a1a3-4d11-a28e-c951f32aae49': {}, '0140ff4e-11d3-4368-bae2-d2ec323a24f1': {}}), is_error=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = WikipediaReader()\n",
    "\n",
    "tool = OnDemandLoaderTool.from_defaults(\n",
    "    reader,\n",
    "    name=\"Wikipedia Tool\",\n",
    "    description=\"A tool for loading and querying articles from Wikipedia\",\n",
    ")\n",
    "\n",
    "# run tool by itself\n",
    "tool([\"Berlin\"], query_str=\"What's the arts and culture scene in Berlin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.indices.vector_store import VectorStoreIndex\n",
    "\n",
    "reader = WikipediaReader()\n",
    "tool = OnDemandLoaderTool.from_defaults(\n",
    "    reader=reader,\n",
    "    index_cls=VectorStoreIndex,\n",
    "    index_kwargs={\"dim\": 768},\n",
    "    name=\"Wikipedia\",\n",
    "    description=\"A tool for querying Wikipedia articles.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tool([\"City of Vienna\"], query_str=\"What are the best universities in Vienna?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context information lists several universities in Vienna, including the Academy of Fine Arts Vienna, Central European University, Diplomatic Academy of Vienna, Medical University of Vienna, PEF Private University of Management Vienna, University of Applied Arts Vienna, University of Applied Sciences Campus Vienna, University of Music and Performing Arts Vienna, University of Veterinary Medicine Vienna, University of Vienna, Vienna University of Economics and Business, University of Natural Resources and Life Sciences, Vienna, University of Applied Sciences Technikum Wien, TU Wien, Webster Vienna Private University, and Sigmund Freud Private University. However, it does not rank them or specify which ones are considered the best.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also check [These Notebooks](https://github.com/run-llama/llama-hub/tree/main/llama_hub/tools/notebooks)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Indexing_Querying_LLamaIndex",
   "widgets": {}
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/rsouza/Prompt_Engineering_Course/blob/main/Notebooks/5_LlamaIndex/2-Indexing_Querying_LLamaIndex.ipynb",
     "timestamp": 1714082079174
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d311bf7ee564be781cfd48286066ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6efb132931b04655b350d09375a58bf1",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ad0d2d97514a2ab8dc2ab0a5591178",
      "value": " 10/10 [00:00&lt;00:00, 67.37it/s]"
     }
    },
    "1ece578683ef4f83b58288633c9bb975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2d2af3f1254498ca0ed0413fc2e3873",
      "placeholder": "​",
      "style": "IPY_MODEL_a87159485bc84f03889bd9ca3439d020",
      "value": "Parsing nodes: 100%"
     }
    },
    "2a51f4e1f37141848d9023722fe81e15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f735494c12145f28654994ad79a0832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ee0f3679a34d8482515e78b478283a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48c37d7e447d49a8b911134d287d1ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56344af539034c34b5e98563675e6ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1cdb05547004947986e416042a3c758",
      "placeholder": "​",
      "style": "IPY_MODEL_9a7cc7cb31fa4ea5afea4f3ef812e68d",
      "value": " 30/30 [00:01&lt;00:00, 28.29it/s]"
     }
    },
    "5a0c1216c09d45caae2855d23accd01a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68fc88da1157414192a92094331375ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ece578683ef4f83b58288633c9bb975",
       "IPY_MODEL_6d704507f27e42f8a89b4fe41f875b8a",
       "IPY_MODEL_1d311bf7ee564be781cfd48286066ba0"
      ],
      "layout": "IPY_MODEL_44ee0f3679a34d8482515e78b478283a"
     }
    },
    "6d704507f27e42f8a89b4fe41f875b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c37d7e447d49a8b911134d287d1ab8",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a0c1216c09d45caae2855d23accd01a",
      "value": 10
     }
    },
    "6efb132931b04655b350d09375a58bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c38119547645f591c78bcd8f67cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4f2c1a82f224dd0ba0faef7dca60d80",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce761a2a57694a4f80c6319cbe633693",
      "value": 30
     }
    },
    "9a7cc7cb31fa4ea5afea4f3ef812e68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ad0d2d97514a2ab8dc2ab0a5591178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ff4a0af9d444128c464b97cb9f13dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ccfb889b464e40c489f0a873681c3463",
       "IPY_MODEL_75c38119547645f591c78bcd8f67cc10",
       "IPY_MODEL_56344af539034c34b5e98563675e6ef1"
      ],
      "layout": "IPY_MODEL_3f735494c12145f28654994ad79a0832"
     }
    },
    "a87159485bc84f03889bd9ca3439d020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4f2c1a82f224dd0ba0faef7dca60d80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1cdb05547004947986e416042a3c758": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccfb889b464e40c489f0a873681c3463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5e9a34c12b5444db998dd9f3735f83d",
      "placeholder": "​",
      "style": "IPY_MODEL_2a51f4e1f37141848d9023722fe81e15",
      "value": "Generating embeddings: 100%"
     }
    },
    "ce761a2a57694a4f80c6319cbe633693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2d2af3f1254498ca0ed0413fc2e3873": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5e9a34c12b5444db998dd9f3735f83d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
