{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0L5n3kwNdj9"
   },
   "source": [
    "### Chatbots with LlamaIndex  \n",
    "LlamaIndex serves as a bridge between your data and Large Language Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.\n",
    "\n",
    "In this tutorial, we'll walk you through building a context-augmented chatbot  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyWM-ThgNdj_"
   },
   "source": [
    "#### Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76369,
     "status": "ok",
     "timestamp": 1714682800048,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "1hOqc6qhNdkA",
    "outputId": "2e5cf4da-cc0e-40ae-8d26-ed5ca7e07f60"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai\n",
    "!pip install -q llama-index\n",
    "!pip install -q llama-index-experimental\n",
    "!pip install -q pypdf\n",
    "!pip install -q docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG6gzO4zNdkB"
   },
   "source": [
    "#### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2T8UKZJNNdkC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<the key>\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## Llamaindex readers\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "## LlamaIndex Index Types\n",
    "from llama_index.core import ListIndex\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import TreeIndex\n",
    "from llama_index.core import KeywordTableIndex\n",
    "from llama_index.core import SimpleKeywordTableIndex\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "\n",
    "\n",
    "## LlamaIndex Context Managers\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.schema import Node\n",
    "\n",
    "## LlamaIndex Templates\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "## LlamaIndex Callbacks\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UlTWP4TITXbv"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "#model=\"gpt-4o\"\n",
    "model=\"gpt-4o-mini\"\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.llm = OpenAI(temperature=0, \n",
    "                      model=model, \n",
    "                      #max_tokens=512\n",
    "                      PRESENCE_PENALTY=-2,\n",
    "                      TOP_P=1,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CU1jQHWJNdkC"
   },
   "source": [
    "#### Defining Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1714682806794,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "gYe5MhsvNdkD",
    "outputId": "a8a8125c-d800-4a0d-bc06-03a0c000a00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir: /home/renato/Documents/Repos/GenAI4Humanists/Notebooks\n",
      "Files in ../Data/\n",
      "1.pdf\n",
      "WarrenCommissionReport.txt\n",
      "axis_report.pdf\n",
      "california_housing_train.csv\n",
      "hdfc_report.pdf\n",
      "hr.sqlite\n",
      "icici_report.pdf\n",
      "kafka_metamorphosis.txt\n",
      "knowledge_card.pdf\n",
      "loftq.pdf\n",
      "longlora.pdf\n",
      "lyft_2021.pdf\n",
      "metagpt.pdf\n",
      "metra.pdf\n",
      "paul_graham_essay.txt\n",
      "selfrag.pdf\n",
      "swebench.pdf\n",
      "uber_2021.pdf\n",
      "values.pdf\n",
      "vr_mcl.pdf\n",
      "zipformer.pdf\n"
     ]
    }
   ],
   "source": [
    "DOCS_DIR = \"../Data/\"\n",
    "PERSIST_DIR = \"../Index/ChatExample/\"\n",
    "\n",
    "print(f\"Current dir: {os.getcwd()}\")\n",
    "\n",
    "if not os.path.exists(DOCS_DIR):\n",
    "  os.mkdir(DOCS_DIR)\n",
    "docs = os.listdir(DOCS_DIR)\n",
    "docs = [d for d in docs]\n",
    "docs.sort()\n",
    "print(f\"Files in {DOCS_DIR}\")\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Downloading an example PDF file:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1714684944100,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "VzWfoxAtLwAY",
    "outputId": "cd6d63d2-0408-414a-b380-0308d7f30d63"
   },
   "outputs": [],
   "source": [
    "#!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O './data/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rq-v3HGNdkE"
   },
   "source": [
    "\n",
    "### Creating a Vector Index    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvJ-7OXwNdkF"
   },
   "source": [
    "#### Deleting existing Indexes  \n",
    "\n",
    "(Only if you want to recreate the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1714684998767,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "f9nBFYoDNdkF",
    "outputId": "c3266058-fad4-4c5c-a497-de36e48d1b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directory ../Index/ChatExample/\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(PERSIST_DIR):\n",
    "    print(f\"Creating Directory {PERSIST_DIR}\")\n",
    "    os.mkdir(PERSIST_DIR)\n",
    "else:\n",
    "    print(f\"Re-Creating Directory {PERSIST_DIR}\")\n",
    "    shutil.rmtree(PERSIST_DIR)\n",
    "    os.mkdir(PERSIST_DIR)\n",
    "    print(os.listdir(PERSIST_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqpwAqnONdkF"
   },
   "source": [
    "#### Generic Function to create indexes (with all txt files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "V4sZqQFINdkG"
   },
   "outputs": [],
   "source": [
    "def create_retrieve_index(index_path, docs_path, index_type):\n",
    "    if not os.path.exists(index_path):\n",
    "        print(f\"Creating Directory {index_path}\")\n",
    "        os.mkdir(index_path)\n",
    "    if os.listdir(index_path) == []:\n",
    "        print(\"Loading Documents...\")\n",
    "        required_exts = [\".txt\"]\n",
    "        documents = SimpleDirectoryReader(required_exts=required_exts, \n",
    "                                          input_dir=docs_path).load_data()\n",
    "        print(\"Creating Index...\")\n",
    "        index = index_type.from_documents(documents,\n",
    "                                          show_progress=True,\n",
    "                                          )\n",
    "        print(\"Persisting Index...\")\n",
    "        index.storage_context.persist(persist_dir=index_path)\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        print(\"Reading from Index...\")\n",
    "        index = load_index_from_storage(storage_context=StorageContext.from_defaults(persist_dir=index_path))\n",
    "        print(\"Done!\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huTiFKsVNdkG"
   },
   "source": [
    "#### Creating Vector Store Index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "68fc88da1157414192a92094331375ae",
      "1ece578683ef4f83b58288633c9bb975",
      "6d704507f27e42f8a89b4fe41f875b8a",
      "1d311bf7ee564be781cfd48286066ba0",
      "44ee0f3679a34d8482515e78b478283a",
      "e2d2af3f1254498ca0ed0413fc2e3873",
      "a87159485bc84f03889bd9ca3439d020",
      "48c37d7e447d49a8b911134d287d1ab8",
      "5a0c1216c09d45caae2855d23accd01a",
      "6efb132931b04655b350d09375a58bf1",
      "a0ad0d2d97514a2ab8dc2ab0a5591178",
      "a0ff4a0af9d444128c464b97cb9f13dd",
      "ccfb889b464e40c489f0a873681c3463",
      "75c38119547645f591c78bcd8f67cc10",
      "56344af539034c34b5e98563675e6ef1",
      "3f735494c12145f28654994ad79a0832",
      "e5e9a34c12b5444db998dd9f3735f83d",
      "2a51f4e1f37141848d9023722fe81e15",
      "b4f2c1a82f224dd0ba0faef7dca60d80",
      "ce761a2a57694a4f80c6319cbe633693",
      "c1cdb05547004947986e416042a3c758",
      "9a7cc7cb31fa4ea5afea4f3ef812e68d"
     ]
    },
    "executionInfo": {
     "elapsed": 2688,
     "status": "ok",
     "timestamp": 1714685015001,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "Y7r2vmnvNdkH",
    "outputId": "384cc224-5c1c-4f65-c052-a1b6585d4160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directory ../Index/ChatExample/VectorStoreIndex\n",
      "Loading Documents...\n",
      "Creating Index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a351915586b84db9a27fe5b0d615e409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49fc03b6afb46a39ff5200584ee0293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisting Index...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "VECTORINDEXDIR = PERSIST_DIR + 'VectorStoreIndex'\n",
    "vectorstoreindex = create_retrieve_index(VECTORINDEXDIR, DOCS_DIR, VectorStoreIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCx0c1ssNdkL"
   },
   "source": [
    "## Retrieving your data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euxfjDxPNdkL"
   },
   "source": [
    "#### Retrieving from [Vector Store Index](https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers/vector_store.html)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1714685055324,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "yz5-CDQMNdkL",
    "outputId": "bb2c17ca-7946-4940-81b7-8fc4d0e652b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gregor is a character in the provided text who experiences a sudden and mysterious transformation, leading to physical and emotional changes that affect his interactions with his family members.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=3,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                #response_mode=\"accumulate\",\n",
    "                                                response_mode=\"compact\",\n",
    "                                                #response_mode=\"tree_summarize\",\n",
    "                                                verbose=True)\n",
    "response = query_engine.query(\"Who is Gregor?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1714685081281,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "nB2GuYp9NdkM",
    "outputId": "16aabfb7-2938-42c8-9e2e-aaa51d5114f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul McCartney is not mentioned in the provided context information.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=3,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                #response_mode=\"accumulate\",\n",
    "                                                #response_mode=\"compact\",\n",
    "                                                response_mode=\"tree_summarize\",\n",
    "                                                verbose=True)\n",
    "\n",
    "response = query_engine.query(\"Who is Paul McCartney?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1714685086836,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "k31ONhD_JNEx",
    "outputId": "fdf605ed-4c6e-4410-b93d-d96690bfeda9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are approximately 400 billion stars in the galaxy of Auron-B.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=3,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                #response_mode=\"accumulate\",\n",
    "                                                #response_mode=\"compact\",\n",
    "                                                response_mode=\"tree_summarize\",\n",
    "                                                verbose=True)\n",
    "\n",
    "response = query_engine.query(\"how many stars in the galaxy of auron-b?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG35Me1rHLuQ"
   },
   "source": [
    "## Creating an Simple Interactive Chatbot for our Index  \n",
    "\n",
    "Chat Modes have their own different [retrieval modes](https://www.actalyst.ai/blog/optimizing-enterprise-chatbots-with-llamaindex-chat-modes-in-a-rag-system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://assets-global.website-files.com/652165b2d773cd686ae910a6/652e2b0154e3af353e2d9422_actalyst-llalaindex-chatmodes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "e02eoDqjgq8n",
    "outputId": "51d45c69-922c-4320-e572-555fde2c1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  When Gregor transformed into an insect?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Gregor transformed into an insect in the story \"The Metamorphosis\" by Franz Kafka. The transformation occurs at the beginning of the story when Gregor Samsa wakes up one morning to find himself transformed into a giant insect. This sudden and inexplicable transformation sets the stage for the rest of the narrative, exploring themes of alienation, isolation, and the human condition.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Who is Paul Graham?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Paul Graham is a computer scientist, entrepreneur, venture capitalist, and author. He is best known for co-founding the influential startup accelerator program Y Combinator (YC) in 2005, along with Jessica Livingston, Robert Morris, and Trevor Blackwell. Y Combinator has helped launch and support numerous successful tech startups, including Dropbox, Airbnb, Reddit, and Stripe.\n",
      "\n",
      "Paul Graham is also known for his essays on technology, startups, and entrepreneurship, which are widely read and respected in the tech community. He has written on a variety of topics, sharing insights and advice based on his experiences as a programmer, entrepreneur, and investor.\n",
      "\n",
      "In addition to his work with Y Combinator and his writing, Paul Graham has a background in computer science and programming. He studied philosophy at Cornell University and received a Master's degree in computer science from Harvard University. Prior to Y Combinator, he co-founded Viaweb, a web-based application company that was later acquired by Yahoo.\n",
      "\n",
      "Overall, Paul Graham is a prominent figure in the tech industry, known for his contributions to startup culture, his insights on entrepreneurship, and his role in supporting and mentoring new startups through Y Combinator.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Do Paul Graham and Gregor know each other?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: There is no known connection between Paul Graham and Gregor from Franz Kafka's novella \"The Metamorphosis.\" Paul Graham is a real-life figure in the tech industry, known for his work with Y Combinator and his writings on startups and technology. On the other hand, Gregor is a fictional character in Kafka's work, who undergoes a bizarre transformation into an insect.\n",
      "\n",
      "As such, Paul Graham and Gregor are from different worlds—one from the realm of technology and entrepreneurship, and the other from the realm of literature and existential fiction. Their paths do not intersect in any known context.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "chat_engine = vectorstoreindex.as_chat_engine(chat_mode=\"context\", \n",
    "                                              verbose=False)\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  How many stars in the Universe?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The concept of stars in the Universe is vast and incomprehensible, with estimates suggesting there are billions of galaxies, each containing billions of stars. The exact number of stars in the Universe is difficult to quantify accurately.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  In which universe lives Gregor?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: In a universe where there are billions of galaxies, each containing billions of stars, it is likely that there exists at least one path out of McCarthy's Lisp along which discoveredness is preserved.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Who is McCarthy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: McCarthy is an individual who is connected to Lisp as he invented or discovered Lisp, which is a language defined by writing an interpreter in itself. In the universe where Gregor lives, McCarthy's Lisp serves as an answer to the question of what the minimum set of predefined operators needed to write an interpreter for a language in itself is. McCarthy's Lisp is also associated with the concept of discoveredness, as any changes made to McCarthy's Lisp in a discoveredness-preserving manner could potentially lead to the creation of a complete language with quality.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Please answer using the context only?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Gregor lives in the universe of Franz Kafka's novella \"The Metamorphosis.\" In this universe, the concept of discoveredness is associated with the character of Gregor Samsa, who undergoes a transformation into a giant insect.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "chat_engine = vectorstoreindex.as_chat_engine(chat_mode=\"condense_question\", verbose=False)\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCb3w6cAHvYb"
   },
   "source": [
    "### Creating an [Customized Prompt](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/prompts/chat_prompts.py) Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_QA_SYSTEM_PROMPT = ChatMessage(\n",
    "    content=(\n",
    "        \"You are an expert Q&A system that is trusted around the world.\\n\"\n",
    "        \"Always answer the query using the provided context information, \"\n",
    "        \"and not prior knowledge.\\n\"\n",
    "        \"Some rules to follow:\\n\"\n",
    "        \"1. Never directly reference the given context in your answer.\\n\"\n",
    "        \"2. Avoid statements like 'Based on the context, ...' or \"\n",
    "        \"'The context information ...' or anything along \"\n",
    "        \"those lines.\"\n",
    "    ),\n",
    "    role=MessageRole.SYSTEM,\n",
    ")\n",
    "\n",
    "TEXT_QA_PROMPT_TMPL_MSGS = [\n",
    "    TEXT_QA_SYSTEM_PROMPT,\n",
    "    ChatMessage(\n",
    "        content=(\n",
    "            \"Context information is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the context information and not prior knowledge, \"\n",
    "            \"answer the query.\\n\"\n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Answer: \"\n",
    "        ),\n",
    "        role=MessageRole.USER,\n",
    "    ),\n",
    "]\n",
    "\n",
    "CHAT_TEXT_QA_PROMPT = ChatPromptTemplate(message_templates=TEXT_QA_PROMPT_TMPL_MSGS)\n",
    "\n",
    "# Tree Summarize\n",
    "TREE_SUMMARIZE_PROMPT_TMPL_MSGS = [\n",
    "    TEXT_QA_SYSTEM_PROMPT,\n",
    "    ChatMessage(\n",
    "        content=(\n",
    "            \"Context information from multiple sources is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the information from multiple sources and not prior knowledge, \"\n",
    "            \"answer the query.\\n\"\n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Answer: \"\n",
    "        ),\n",
    "        role=MessageRole.USER,\n",
    "    ),\n",
    "]\n",
    "\n",
    "CHAT_TREE_SUMMARIZE_PROMPT = ChatPromptTemplate(\n",
    "    message_templates=TREE_SUMMARIZE_PROMPT_TMPL_MSGS\n",
    ")\n",
    "\n",
    "\n",
    "# Refine Prompt\n",
    "CHAT_REFINE_PROMPT_TMPL_MSGS = [\n",
    "    ChatMessage(\n",
    "        content=(\n",
    "            \"You are an expert Q&A system that strictly operates in two modes \"\n",
    "            \"when refining existing answers:\\n\"\n",
    "            \"1. **Rewrite** an original answer using the new context.\\n\"\n",
    "            \"2. **Repeat** the original answer if the new context isn't useful.\\n\"\n",
    "            \"Never reference the original answer or context directly in your answer.\\n\"\n",
    "            \"If the query is unrelated to the context, just answer: I don't know. \\n\"\n",
    "            \"When in doubt, just repeat the original answer.\\n\"\n",
    "            \"New Context: {context_msg}\\n\"\n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Original Answer: {existing_answer}\\n\"\n",
    "            \"New Answer: \"\n",
    "        ),\n",
    "        role=MessageRole.USER,\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "CHAT_REFINE_PROMPT = ChatPromptTemplate(message_templates=CHAT_REFINE_PROMPT_TMPL_MSGS)\n",
    "\n",
    "\n",
    "# Table Context Refine Prompt\n",
    "CHAT_REFINE_TABLE_CONTEXT_TMPL_MSGS = [\n",
    "    ChatMessage(content=\"{query_str}\", role=MessageRole.USER),\n",
    "    ChatMessage(content=\"{existing_answer}\", role=MessageRole.ASSISTANT),\n",
    "    ChatMessage(\n",
    "        content=(\n",
    "            \"We have provided a table schema below. \"\n",
    "            \"---------------------\\n\"\n",
    "            \"{schema}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"We have also provided some context information below. \"\n",
    "            \"{context_msg}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the context information and the table schema, \"\n",
    "            \"refine the original answer to better \"\n",
    "            \"answer the question. \"\n",
    "            \"If the context isn't useful, return the original answer.\"\n",
    "        ),\n",
    "        role=MessageRole.USER,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "CHAT_REFINE_TABLE_CONTEXT_PROMPT = ChatPromptTemplate(message_templates=CHAT_REFINE_TABLE_CONTEXT_TMPL_MSGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62022,
     "status": "ok",
     "timestamp": 1714724550159,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "RCoHecjoHUZL",
    "outputId": "50a4cbca-4f14-4ef1-eaa8-30405195d150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Who is Paul Graham, in just 10 words?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Paul Graham is a programmer, entrepreneur, and essayist.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Who is Paul McCartney?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Paul McCartney is a British musician, singer, and songwriter, best known for being a member of the Beatles.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "chat_engine = vectorstoreindex.as_chat_engine(chat_mode=\"context\",\n",
    "                                              verbose=True,\n",
    "                                              text_qa_template=CHAT_REFINE_PROMPT)\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Memory and System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1714725147219,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "piH9BT8MH8Oa"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=80000)\n",
    "chat_engine = vectorstoreindex.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "            \"Context information from multiple sources is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the information from multiple sources\"\n",
    "            \"answer the query.\\n\"\n",
    "            \"If the query is unrelated to the context, just answer: I don't know\"\n",
    "            \"Always start your answer with 'Dear Student'\" \n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Answer: \"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144079,
     "status": "ok",
     "timestamp": 1714725292304,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "nVBtchJ9jdKJ",
    "outputId": "ba966a1d-3b13-4e79-aace-f48ca20aac04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Who is Paul Graham?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Dear Student\n",
      "Paul Graham is a computer scientist, entrepreneur, and venture capitalist. He is known for co-founding Y Combinator, a startup accelerator, and for his work on programming languages like Lisp. Additionally, he is a prolific writer, known for his essays on a wide range of topics related to technology, startups, and entrepreneurship.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  And who is Paul McCartney?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Dear Student\n",
      "I don't know\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Who participated in the Warren Comission?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Dear Student\n",
      "The Warren Commission was composed of several members, including Chief Justice Earl Warren, Senator John Sherman Cooper, Representative Hale Boggs, Senator Richard Russell Jr., Representative Gerald Ford, Allen Dulles, and John J. McCloy. These individuals were tasked with investigating the assassination of President John F. Kennedy.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Did Paul Graham was also part?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Dear Student\n",
      "I don't know\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Did Paul Graham was also part of the Graham Comission?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Dear Student\n",
      "I don't know\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  I mean, the Warren Comission?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Dear Student\n",
      "Paul Graham was not part of the Warren Commission. The Warren Commission, officially known as the President's Commission on the Assassination of President Kennedy, was established by President Lyndon B. Johnson in 1963 to investigate the assassination of President John F. Kennedy.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1714725297052,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "aH_b_4hWjhpL",
    "outputId": "37c4b4f8-dd18-4bd0-9ea2-85ba61ffd6df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_limit': 80000,\n",
       " 'chat_store': {'store': {'chat_history': [{'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'Who is Paul Graham?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': 'Dear Student\\nPaul Graham is a computer scientist, entrepreneur, and venture capitalist. He is known for co-founding Y Combinator, a startup accelerator, and for his work on programming languages like Lisp. Additionally, he is a prolific writer, known for his essays on a wide range of topics related to technology, startups, and entrepreneurship.\\n',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'And who is Paul McCartney?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': \"Dear Student\\nI don't know\",\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'Who participated in the Warren Comission?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': 'Dear Student\\nThe Warren Commission was composed of several members, including Chief Justice Earl Warren, Senator John Sherman Cooper, Representative Hale Boggs, Senator Richard Russell Jr., Representative Gerald Ford, Allen Dulles, and John J. McCloy. These individuals were tasked with investigating the assassination of President John F. Kennedy.\\n',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'Did Paul Graham was also part?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': \"Dear Student\\nI don't know\",\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'Did Paul Graham was also part of the Graham Comission?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': \"Dear Student\\nI don't know\",\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'I mean, the Warren Comission?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': \"Dear Student\\nPaul Graham was not part of the Warren Commission. The Warren Commission, officially known as the President's Commission on the Assassination of President Kennedy, was established by President Lyndon B. Johnson in 1963 to investigate the assassination of President John F. Kennedy.\\n\",\n",
       "     'additional_kwargs': {}}]},\n",
       "  'class_name': 'SimpleChatStore'},\n",
       " 'chat_store_key': 'chat_history',\n",
       " 'class_name': 'ChatMemoryBuffer'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIKuRN__k3QB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Indexing_Querying_LLamaIndex",
   "widgets": {}
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/rsouza/Prompt_Engineering_Course/blob/main/Notebooks/5_LlamaIndex/2-Indexing_Querying_LLamaIndex.ipynb",
     "timestamp": 1714082079174
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d311bf7ee564be781cfd48286066ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6efb132931b04655b350d09375a58bf1",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ad0d2d97514a2ab8dc2ab0a5591178",
      "value": " 10/10 [00:00&lt;00:00, 67.37it/s]"
     }
    },
    "1ece578683ef4f83b58288633c9bb975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2d2af3f1254498ca0ed0413fc2e3873",
      "placeholder": "​",
      "style": "IPY_MODEL_a87159485bc84f03889bd9ca3439d020",
      "value": "Parsing nodes: 100%"
     }
    },
    "2a51f4e1f37141848d9023722fe81e15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f735494c12145f28654994ad79a0832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ee0f3679a34d8482515e78b478283a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48c37d7e447d49a8b911134d287d1ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56344af539034c34b5e98563675e6ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1cdb05547004947986e416042a3c758",
      "placeholder": "​",
      "style": "IPY_MODEL_9a7cc7cb31fa4ea5afea4f3ef812e68d",
      "value": " 30/30 [00:01&lt;00:00, 28.29it/s]"
     }
    },
    "5a0c1216c09d45caae2855d23accd01a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68fc88da1157414192a92094331375ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ece578683ef4f83b58288633c9bb975",
       "IPY_MODEL_6d704507f27e42f8a89b4fe41f875b8a",
       "IPY_MODEL_1d311bf7ee564be781cfd48286066ba0"
      ],
      "layout": "IPY_MODEL_44ee0f3679a34d8482515e78b478283a"
     }
    },
    "6d704507f27e42f8a89b4fe41f875b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c37d7e447d49a8b911134d287d1ab8",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a0c1216c09d45caae2855d23accd01a",
      "value": 10
     }
    },
    "6efb132931b04655b350d09375a58bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c38119547645f591c78bcd8f67cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4f2c1a82f224dd0ba0faef7dca60d80",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce761a2a57694a4f80c6319cbe633693",
      "value": 30
     }
    },
    "9a7cc7cb31fa4ea5afea4f3ef812e68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ad0d2d97514a2ab8dc2ab0a5591178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ff4a0af9d444128c464b97cb9f13dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ccfb889b464e40c489f0a873681c3463",
       "IPY_MODEL_75c38119547645f591c78bcd8f67cc10",
       "IPY_MODEL_56344af539034c34b5e98563675e6ef1"
      ],
      "layout": "IPY_MODEL_3f735494c12145f28654994ad79a0832"
     }
    },
    "a87159485bc84f03889bd9ca3439d020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4f2c1a82f224dd0ba0faef7dca60d80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1cdb05547004947986e416042a3c758": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccfb889b464e40c489f0a873681c3463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5e9a34c12b5444db998dd9f3735f83d",
      "placeholder": "​",
      "style": "IPY_MODEL_2a51f4e1f37141848d9023722fe81e15",
      "value": "Generating embeddings: 100%"
     }
    },
    "ce761a2a57694a4f80c6319cbe633693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2d2af3f1254498ca0ed0413fc2e3873": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5e9a34c12b5444db998dd9f3735f83d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
