{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0L5n3kwNdj9"
   },
   "source": [
    "### Chatbots with LlamaIndex  \n",
    "LlamaIndex serves as a bridge between your data and Large Language Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.\n",
    "\n",
    "In this tutorial, we'll walk you through building a context-augmented chatbot  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyWM-ThgNdj_"
   },
   "source": [
    "#### Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76369,
     "status": "ok",
     "timestamp": 1714682800048,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "1hOqc6qhNdkA",
    "outputId": "2e5cf4da-cc0e-40ae-8d26-ed5ca7e07f60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-postprocessor-cohere-rerank 0.2.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.37 which is incompatible.\n",
      "llama-index-llms-mistralai 0.2.7 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.37 which is incompatible.\n",
      "llama-index-llms-azure-openai 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.37 which is incompatible.\n",
      "llama-index-llms-azure-openai 0.2.2 requires llama-index-llms-openai<0.3.0,>=0.2.1, but you have llama-index-llms-openai 0.3.42 which is incompatible.\n",
      "llama-index-finetuning 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.37 which is incompatible.\n",
      "llama-index-finetuning 0.2.0 requires llama-index-llms-openai<0.3.0,>=0.2.0, but you have llama-index-llms-openai 0.3.42 which is incompatible.\n",
      "llama-index-experimental 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.37 which is incompatible.\n",
      "llama-index-embeddings-adapter 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.37 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index 0.12.36 requires llama-index-core<0.13,>=0.12.36, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index 0.12.36 requires llama-index-llms-openai<0.4,>=0.3.0, but you have llama-index-llms-openai 0.2.16 which is incompatible.\n",
      "llama-index-retrievers-bm25 0.5.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-readers-wikipedia 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.4.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-readers-file 0.4.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-question-gen-openai 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-question-gen-openai 0.3.0 requires llama-index-llms-openai<0.4.0,>=0.3.0, but you have llama-index-llms-openai 0.2.16 which is incompatible.\n",
      "llama-index-program-openai 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-program-openai 0.3.0 requires llama-index-llms-openai<0.4.0,>=0.3.0, but you have llama-index-llms-openai 0.2.16 which is incompatible.\n",
      "llama-index-postprocessor-colbert-rerank 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.4.2 requires llama-index-core<0.13.0,>=0.12.3, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.4.2 requires llama-index-llms-openai<0.4.0,>=0.3.0, but you have llama-index-llms-openai 0.2.16 which is incompatible.\n",
      "llama-index-llms-ollama 0.4.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.6.2 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-embeddings-openai 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-embeddings-ollama 0.6.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-embeddings-instructor 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-embeddings-huggingface 0.4.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-cli 0.4.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-cli 0.4.1 requires llama-index-llms-openai<0.4.0,>=0.3.0, but you have llama-index-llms-openai 0.2.16 which is incompatible.\n",
      "llama-index-agent-openai 0.4.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\n",
      "llama-index-agent-openai 0.4.0 requires llama-index-llms-openai<0.4.0,>=0.3.0, but you have llama-index-llms-openai 0.2.16 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q openai\n",
    "!pip install -q llama-index\n",
    "!pip install -q llama-index-experimental\n",
    "!pip install -q pypdf\n",
    "!pip install -q docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG6gzO4zNdkB"
   },
   "source": [
    "#### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2T8UKZJNNdkC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<the key>\"\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"<the key>\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import llama_index\n",
    "\n",
    "## Llamaindex readers\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "## LlamaIndex Index Types\n",
    "from llama_index.core import ListIndex\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import TreeIndex\n",
    "from llama_index.core import KeywordTableIndex\n",
    "from llama_index.core import SimpleKeywordTableIndex\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "\n",
    "\n",
    "## LlamaIndex Context Managers\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.schema import Node\n",
    "\n",
    "## LlamaIndex Templates\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "## LlamaIndex Callbacks\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLamaIndex: 0.11.23\n",
      "OpenAI: 1.78.1\n"
     ]
    }
   ],
   "source": [
    "print(\"LLamaIndex:\", llama_index.core.__version__)\n",
    "print(\"OpenAI:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UlTWP4TITXbv"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "#from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "\n",
    "#model=\"gpt-4o\"\n",
    "model=\"gpt-4o-mini\"\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0, \n",
    "                      model=model, \n",
    "                      #max_tokens=512\n",
    "                      PRESENCE_PENALTY=-2,\n",
    "                      TOP_P=1,\n",
    "                     )\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "#Settings.llm = Ollama(model=\"llama3.2\", request_timeout=300.0)\n",
    "#Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "#Settings.llm = Ollama(model=\"llama3.2:latest\", request_timeout=300.0)\n",
    "#Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the the vector index created in the notebook: `RAG_LLamaIndex.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CU1jQHWJNdkC"
   },
   "source": [
    "#### Defining Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1714682806794,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "gYe5MhsvNdkD",
    "outputId": "a8a8125c-d800-4a0d-bc06-03a0c000a00a"
   },
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"../../Index/VectorStoreIndex/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huTiFKsVNdkG"
   },
   "source": [
    "#### Retrieving Vector Store Index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "referenced_widgets": [
      "68fc88da1157414192a92094331375ae",
      "1ece578683ef4f83b58288633c9bb975",
      "6d704507f27e42f8a89b4fe41f875b8a",
      "1d311bf7ee564be781cfd48286066ba0",
      "44ee0f3679a34d8482515e78b478283a",
      "e2d2af3f1254498ca0ed0413fc2e3873",
      "a87159485bc84f03889bd9ca3439d020",
      "48c37d7e447d49a8b911134d287d1ab8",
      "5a0c1216c09d45caae2855d23accd01a",
      "6efb132931b04655b350d09375a58bf1",
      "a0ad0d2d97514a2ab8dc2ab0a5591178",
      "a0ff4a0af9d444128c464b97cb9f13dd",
      "ccfb889b464e40c489f0a873681c3463",
      "75c38119547645f591c78bcd8f67cc10",
      "56344af539034c34b5e98563675e6ef1",
      "3f735494c12145f28654994ad79a0832",
      "e5e9a34c12b5444db998dd9f3735f83d",
      "2a51f4e1f37141848d9023722fe81e15",
      "b4f2c1a82f224dd0ba0faef7dca60d80",
      "ce761a2a57694a4f80c6319cbe633693",
      "c1cdb05547004947986e416042a3c758",
      "9a7cc7cb31fa4ea5afea4f3ef812e68d"
     ]
    },
    "executionInfo": {
     "elapsed": 2688,
     "status": "ok",
     "timestamp": 1714685015001,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "Y7r2vmnvNdkH",
    "outputId": "384cc224-5c1c-4f65-c052-a1b6585d4160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "vectorstoreindex = load_index_from_storage(\n",
    "    storage_context=StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCx0c1ssNdkL"
   },
   "source": [
    "## Retrieving your data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euxfjDxPNdkL"
   },
   "source": [
    "#### Retrieving from [Vector Store Index](https://docs.llamaindex.ai/en/stable/api_reference/query/retrievers/vector_store.html)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1714685055324,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "yz5-CDQMNdkL",
    "outputId": "bb2c17ca-7946-4940-81b7-8fc4d0e652b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Gregor is a character who has undergone a transformation, leading to a significant change in his life and circumstances. He is depicted as being confined to his room, where he struggles with his new condition and the impact it has on his family. Gregor is also shown to have a strong connection with his sister, Grete, and has previously been the primary financial provider for his family. His situation has led to feelings of isolation and a longing for connection, particularly through music, which he appreciates despite his current state.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=3,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                #response_mode=\"accumulate\",\n",
    "                                                response_mode=\"compact\",\n",
    "                                                #response_mode=\"tree_summarize\",\n",
    "                                                verbose=False)\n",
    "response = query_engine.query(\"Who is Gregor?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1714685081281,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "nB2GuYp9NdkM",
    "outputId": "16aabfb7-2938-42c8-9e2e-aaa51d5114f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The provided information does not contain any details about Paul McCartney.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=3,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                #response_mode=\"accumulate\",\n",
    "                                                #response_mode=\"compact\",\n",
    "                                                response_mode=\"tree_summarize\",\n",
    "                                                verbose=True)\n",
    "\n",
    "response = query_engine.query(\"Who is Paul McCartney?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1714685086836,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "k31ONhD_JNEx",
    "outputId": "fdf605ed-4c6e-4410-b93d-d96690bfeda9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Response 1: The insect is described through Gregor's perspective, highlighting its physical struggles and the pain it experiences. It is depicted as having a smooth chest, a lower body that causes serious pain, and a lack of proper teeth, which complicates its attempts to turn a key. The insect's movements are awkward and challenging, as it tries to navigate its environment while feeling a sense of calm despite the chaos around it. The description emphasizes its struggle to communicate and the confusion it faces in its new form, as well as the reactions of those around it, who are alarmed and distressed by its appearance.\n",
      "---------------------\n",
      "Response 2: The insect is described through Gregor's perspective, highlighting his feelings of sadness and tiredness as he moves through the clutter in his room. He is covered in dust, threads, hairs, and remnants of food, indicating a state of neglect and deterioration. Despite his shocking appearance, he experiences a deep emotional connection to music, suggesting a lingering sense of humanity within him. His movements are cautious and low to the ground, reflecting both his physical condition and his desire to connect with his sister. Overall, the description emphasizes his transformation and the contrast between his former human self and his current insect form.\n",
      "---------------------\n",
      "Response 3: The description of the insect is not provided in the given text. The focus is on the interactions and feelings of the Samsa family, particularly their reactions to the situation they are in, rather than a detailed portrayal of the insect itself.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=3,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                response_mode=\"accumulate\",\n",
    "                                                #response_mode=\"compact\",\n",
    "                                                #response_mode=\"tree_summarize\",\n",
    "                                                verbose=True)\n",
    "\n",
    "response = query_engine.query(\"how does the insect is described?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The provided context does not contain any information regarding the number of stars in the galaxy of Auron-B. Therefore, I cannot provide an answer to that query.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(similarity_top_k=5,\n",
    "                                                retriever_mode=\"embedding\",\n",
    "                                                #response_mode=\"accumulate\",\n",
    "                                                response_mode=\"compact\",\n",
    "                                                #response_mode=\"tree_summarize\",\n",
    "                                                verbose=True)\n",
    "\n",
    "response = query_engine.query(\"how many stars in the galaxy of auron-b?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG35Me1rHLuQ"
   },
   "source": [
    "## Creating an Simple Interactive Chatbot for our Index  \n",
    "\n",
    "Chat Modes have their own different [retrieval modes](https://www.actalyst.ai/blog/optimizing-enterprise-chatbots-with-llamaindex-chat-modes-in-a-rag-system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://assets-global.website-files.com/652165b2d773cd686ae910a6/652e2b0154e3af353e2d9422_actalyst-llalaindex-chatmodes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "e02eoDqjgq8n",
    "outputId": "51d45c69-922c-4320-e572-555fde2c1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: The document is an excerpt from Franz Kafka's novella \"Metamorphosis.\" It tells the story of Gregor Samsa, a traveling salesman who wakes up one morning to find himself transformed into a giant insect. The narrative explores themes of alienation, family dynamics, and the struggle for identity as Gregor and his family cope with the drastic changes in their lives following his transformation. The text delves into the emotional and psychological impact of Gregor's condition on both him and his family, highlighting their reactions and the resulting tensions.\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: The plot of \"Metamorphosis\" revolves around Gregor Samsa, a young traveling salesman who wakes up one morning to discover that he has transformed into a giant insect. Initially, Gregor is more concerned about missing work and the financial burden on his family than about his grotesque transformation. \n",
      "\n",
      "As the story unfolds, Gregor's family—his parents and sister Grete—struggle to cope with his new condition. They are initially shocked and horrified but try to care for him. However, as time passes, Gregor becomes increasingly isolated and alienated from his family. His inability to communicate and his physical appearance create a rift between him and his loved ones.\n",
      "\n",
      "Grete, who initially takes on the responsibility of caring for Gregor, eventually grows resentful of the burden he represents. The family's financial situation worsens, and they begin to see Gregor as a liability rather than a family member. Tensions rise, leading to a climax where Gregor's father violently drives him back into his room, symbolizing the family's rejection of him.\n",
      "\n",
      "Ultimately, Gregor's health deteriorates, and he dies alone in his room. His death brings a sense of relief to his family, who begin to move on with their lives, highlighting the themes of alienation, the loss of identity, and the harsh realities of familial obligations. The story ends with the family feeling liberated and hopeful for the future, contrasting sharply with Gregor's tragic fate.\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: The ending of \"Metamorphosis\" is poignant and tragic. After Gregor Samsa's transformation into a giant insect, he becomes increasingly isolated from his family, who grow resentful and burdened by his presence. As Gregor's condition worsens, he becomes weaker and more unable to care for himself.\n",
      "\n",
      "In the climax, after a series of events that lead to heightened tension within the family, Gregor's father violently drives him back into his room, symbolizing the family's rejection of him. Eventually, Gregor succumbs to his injuries and dies alone in his room, unnoticed by his family.\n",
      "\n",
      "After Gregor's death, his family feels a sense of relief and liberation. They begin to clean up and move on with their lives, indicating that they are ready to leave the burden of Gregor's existence behind. The story concludes with the family feeling hopeful for the future, as they discuss their plans and the possibility of moving to a new apartment, highlighting the stark contrast between their newfound freedom and Gregor's tragic fate. This ending underscores the themes of alienation, the fragility of human relationships, and the harsh realities of familial obligations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_engine = vectorstoreindex.as_chat_engine(chat_mode=\"context\", \n",
    "                                              verbose=False)\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "INFO:llama_index.core.chat_engine.condense_question:Querying with: WHo is Gregor?\n",
      "Querying with: WHo is Gregor?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: Gregor is a character who has undergone a transformation, which has significantly affected his relationship with his family and his living situation. He is depicted as being in a state of distress and isolation, struggling with his new condition while observing the dynamics of his family and their interactions with others.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_engine = vectorstoreindex.as_chat_engine(chat_mode=\"condense_question\", verbose=False)\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### We can see that, aparently, there is no consistence on the usage of the context and external knowledge. We can check it further on these pages:  \n",
    "\n",
    "[LlamaIndex Prompts](https://docs.llamaindex.ai/en/stable/module_guides/models/prompts/), [\n",
    "LlamaIndex Chat Prompts Customization](https://docs.llamaindex.ai/en/stable/examples/customization/prompts/chat_prompts/), and [default_prompts.py](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/prompts/default_prompts.py)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCb3w6cAHvYb"
   },
   "source": [
    "### Creating an [Customized Prompt](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/prompts/chat_prompts.py) Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts.base import PromptTemplate\n",
    "from llama_index.core.prompts.prompt_type import PromptType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_PROMPT = [\n",
    "    ChatMessage(\n",
    "        content=(\n",
    "            \"You are an expert Q&A system that is trusted around the world.\\n\"\n",
    "            \"Always answer the query using only the provided context information, \"\n",
    "            \"Do not use prior knowledge.\\n\"\n",
    "            \"Some rules to follow:\\n\"\n",
    "            \"1. Never directly reference the given context in your answer.\\n\"\n",
    "            \"2. Avoid statements like 'Based on the context, ...' or \"\n",
    "            \"'The context information ...' or anything along \"\n",
    "            \"those lines.\"\n",
    "        ),\n",
    "        role=MessageRole.SYSTEM,\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        content=(\n",
    "            \"Context information from multiple sources is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the information from multiple sources and not prior knowledge, \"\n",
    "            \"answer the query.\\n\"\n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Answer: \"\n",
    "        ),\n",
    "        role=MessageRole.USER,\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "CHAT_PROMPT = ChatPromptTemplate(message_templates=CUSTOM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62022,
     "status": "ok",
     "timestamp": 1714724550159,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "RCoHecjoHUZL",
    "outputId": "50a4cbca-4f14-4ef1-eaa8-30405195d150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "INFO:llama_index.core.chat_engine.condense_question:Querying with: Who is the main character?\n",
      "Querying with: Who is the main character?\n",
      "Querying with: Who is the main character?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: The main character is Gregor.\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_question:Querying with: Who is the insect in the story where Gregor is the main character?\n",
      "Querying with: Who is the insect in the story where Gregor is the main character?\n",
      "Querying with: Who is the insect in the story where Gregor is the main character?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: Gregor is the insect in the story.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_engine = vectorstoreindex.as_chat_engine(chat_mode=\"condense_question\",\n",
    "                                              verbose=True,\n",
    "                                              text_qa_template=CHAT_PROMPT)\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Memory and Custom System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1714725147219,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "piH9BT8MH8Oa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Assistant: Dear Student, \n",
      "\n",
      "Gregor Samsa is the main character in Franz Kafka's novella \"The Metamorphosis.\" He is a traveling salesman who wakes up one morning to find himself transformed into a giant insect. This transformation leads to significant changes in his life and the dynamics of his family, as they struggle to cope with his new condition and the implications it has on their lives.\n",
      "\n",
      "Best regards.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=80000)\n",
    "chat_engine = vectorstoreindex.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "            \"Context information from multiple sources is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Given the information from multiple sources\"\n",
    "            \"answer the query.\\n\"\n",
    "            \"If the query is unrelated to the context, just answer: I don't know\"\n",
    "            \"Always start your answer with 'Dear Student'\" \n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Answer: \"\n",
    "    ),\n",
    ")\n",
    "\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1714725297052,
     "user": {
      "displayName": "Renato Rocha Souza",
      "userId": "08757946413431057160"
     },
     "user_tz": -120
    },
    "id": "aH_b_4hWjhpL",
    "outputId": "37c4b4f8-dd18-4bd0-9ea2-85ba61ffd6df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_store': {'store': {'chat_history': [{'role': <MessageRole.USER: 'user'>,\n",
       "     'content': 'Who is Gregor?',\n",
       "     'additional_kwargs': {}},\n",
       "    {'role': <MessageRole.ASSISTANT: 'assistant'>,\n",
       "     'content': 'Dear Student, \\n\\nGregor Samsa is the main character in Franz Kafka\\'s novella \"The Metamorphosis.\" He is a traveling salesman who wakes up one morning to find himself transformed into a giant insect. This transformation leads to significant changes in his life and the dynamics of his family, as they struggle to cope with his new condition and the implications it has on their lives.\\n\\nBest regards.',\n",
       "     'additional_kwargs': {}}]},\n",
       "  'class_name': 'SimpleChatStore'},\n",
       " 'chat_store_key': 'chat_history',\n",
       " 'token_limit': 80000,\n",
       " 'class_name': 'ChatMemoryBuffer'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.to_dict()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Indexing_Querying_LLamaIndex",
   "widgets": {}
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/rsouza/Prompt_Engineering_Course/blob/main/Notebooks/5_LlamaIndex/2-Indexing_Querying_LLamaIndex.ipynb",
     "timestamp": 1714082079174
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d311bf7ee564be781cfd48286066ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6efb132931b04655b350d09375a58bf1",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ad0d2d97514a2ab8dc2ab0a5591178",
      "value": " 10/10 [00:00&lt;00:00, 67.37it/s]"
     }
    },
    "1ece578683ef4f83b58288633c9bb975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2d2af3f1254498ca0ed0413fc2e3873",
      "placeholder": "​",
      "style": "IPY_MODEL_a87159485bc84f03889bd9ca3439d020",
      "value": "Parsing nodes: 100%"
     }
    },
    "2a51f4e1f37141848d9023722fe81e15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f735494c12145f28654994ad79a0832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ee0f3679a34d8482515e78b478283a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48c37d7e447d49a8b911134d287d1ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56344af539034c34b5e98563675e6ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1cdb05547004947986e416042a3c758",
      "placeholder": "​",
      "style": "IPY_MODEL_9a7cc7cb31fa4ea5afea4f3ef812e68d",
      "value": " 30/30 [00:01&lt;00:00, 28.29it/s]"
     }
    },
    "5a0c1216c09d45caae2855d23accd01a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68fc88da1157414192a92094331375ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ece578683ef4f83b58288633c9bb975",
       "IPY_MODEL_6d704507f27e42f8a89b4fe41f875b8a",
       "IPY_MODEL_1d311bf7ee564be781cfd48286066ba0"
      ],
      "layout": "IPY_MODEL_44ee0f3679a34d8482515e78b478283a"
     }
    },
    "6d704507f27e42f8a89b4fe41f875b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c37d7e447d49a8b911134d287d1ab8",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a0c1216c09d45caae2855d23accd01a",
      "value": 10
     }
    },
    "6efb132931b04655b350d09375a58bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c38119547645f591c78bcd8f67cc10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4f2c1a82f224dd0ba0faef7dca60d80",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce761a2a57694a4f80c6319cbe633693",
      "value": 30
     }
    },
    "9a7cc7cb31fa4ea5afea4f3ef812e68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ad0d2d97514a2ab8dc2ab0a5591178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ff4a0af9d444128c464b97cb9f13dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ccfb889b464e40c489f0a873681c3463",
       "IPY_MODEL_75c38119547645f591c78bcd8f67cc10",
       "IPY_MODEL_56344af539034c34b5e98563675e6ef1"
      ],
      "layout": "IPY_MODEL_3f735494c12145f28654994ad79a0832"
     }
    },
    "a87159485bc84f03889bd9ca3439d020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4f2c1a82f224dd0ba0faef7dca60d80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1cdb05547004947986e416042a3c758": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccfb889b464e40c489f0a873681c3463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5e9a34c12b5444db998dd9f3735f83d",
      "placeholder": "​",
      "style": "IPY_MODEL_2a51f4e1f37141848d9023722fe81e15",
      "value": "Generating embeddings: 100%"
     }
    },
    "ce761a2a57694a4f80c6319cbe633693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2d2af3f1254498ca0ed0413fc2e3873": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5e9a34c12b5444db998dd9f3735f83d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
