{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018d40c2-d808-4dbe-ac07-726f4d390a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Using [Ministral-8B](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) - [Mistral AI](https://mistral.ai/)  \n",
    "\n",
    "##### Running on g5.2xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2ffc1e9-e90e-4de6-8571-cf102efa9402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_launched on 16.10.24_\n",
    "\n",
    "two models available: Ministral 3B and Ministral 8B, both of them support up to 128k context length and Ministral 8B has a special interleaved sliding-window attention pattern for faster and memory-efficient inference.\n",
    "\n",
    "Ministral 8B is available for research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2209995f-28f2-4651-b595-ade526089d8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa9e7190-71a8-4345-929b-6cf53f8075fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U vllm\n",
    "%pip install -U mistral_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac79bfb-399e-4e9d-b194-7b6e68dd8324",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "huggingface_token = \"<your token>\"\n",
    "\n",
    "login(token=huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5750af5-6a37-4de6-b87e-fe10f73e7611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13d55f6c-0969-4575-9271-66d0d07f24bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from vllm import LLM\n",
    "from vllm.sampling_params import SamplingParams\n",
    "\n",
    "model_name = \"mistralai/Ministral-8B-Instruct-2410\"\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=400)\n",
    "\n",
    "llm = LLM(model=model_name, tokenizer_mode=\"mistral\", config_format=\"mistral\", load_format=\"mistral\",     max_model_len=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d427de-cd62-4058-98e1-5b5088374815",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "prompt_generation = \"Write me all about Arthur Schopenhauer.\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt_generation\n",
    "    },\n",
    "]\n",
    "\n",
    "#Tracking the time\n",
    "start_time = time.time()\n",
    "response = llm.chat(messages, sampling_params=sampling_params)\n",
    "print(response[0].outputs[0].text)\n",
    "end_time = time.time()\n",
    "latency = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "112e550f-8a98-4dc2-9a06-5236a1fc474a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('Latency of the model is', latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fc52ad5-b822-4e8a-aaba-ae77958964ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e058286-f2ff-420a-b69c-9917e02265c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Write a short summary of this article for a business expert:\n",
    "\n",
    "{article}\n",
    "\"\"\"\n",
    "\n",
    "cameroon = \"\"\"The economic fallout from the COVID-19 pandemic and the subsequent global shocks provoked by the war in Ukraine have hit African countries hard, denting economic growth and aggravating their sovereign debt positions. The International Monetary Fund (IMF) forecasts that Cameroon, a Central African oil producer, will record 4.3% economic growth this year after it slumped to 0.5% in 2020. The Fund has classified Cameroon as being at high risk of debt distress, though in its most recent review of the country's loan programme it stated that, with active fiscal reforms and management, the debt could be sustainable. \"Our debt service coverage from exports needs to be improved. That's the reason why we are ranked in a high risk debt distress position,\" said Alamine Ousmane Mey, Cameroon's minister of economy, planning and regional development. He was speaking at an event organised by the Atlantic Council think tank on the sidelines of the IMF and World Bank's Spring Meetings in Washington. \"We're working to be able to improve our exports through import substitution policies to reduce imports, produce more and export more. This will give us better room for debt service coverage,\" he said. Cameroon has also relaunched talks with the U.S. to end its suspension from the Africa Growth and Opportunities Act (AGOA) initiative, which grants qualifying African countries tariff-free access to the U.S. market. Former President Donald Trump suspended Cameroon from the programme in late 2019 over \"persistent gross violations of internationally recognised human rights\" by Cameroonian security forces. Since 2017, factions of secessionist militias have been battling government troops in the majority Francophone country's two English-speaking regions. The conflict has killed thousands and displaced nearly 800,000 people. \"All the issues that have been raised, we're working on in a very transparent open manner to be able to iron them out and solve the problems,\" Mey said, referring to the talks with U.S. officials to rejoin AGOA. Our Standards: The Thomson Reuters Trust Principles.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": template.format(article=cameroon)\n",
    "    },\n",
    "]\n",
    "\n",
    "response = llm.chat(messages, sampling_params=sampling_params)\n",
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bd36046-dac4-45eb-9336-36b16c1208ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3debc886-5526-43fc-91bf-53ba8b6fd6e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bff1ab-76d5-40a5-b770-fc78ed4c2140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "translation_template = \"\"\"Translate into Russian:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "translate_to_rus = \"\"\"Mr. Bingley was good-looking and gentlemanlike: he had a pleasant countenance, and easy, unaffected manners. His sisters were fine women, with an air of decided fashion. His brother-in-law, Mr. Hurst, merely looked the gentleman; but his friend Mr. Darcy soon drew the attention of the room by his fine, tall person, handsome features, noble mien, and the report, which was in general circulation within five minutes after his entrance, of his having ten thousand a year. The gentlemen pronounced him to be a fine figure of a man, the ladies declared he was much handsomer than Mr. Bingley, and he was looked at with great admiration for about half the evening, till his manners gave a disgust which turned the tide of his popularity; for he was discovered to be proud, to be above his company, and above being pleased; and not all his large estate in Derbyshire could save him from having a most forbidding, disagreeable countenance, and being unworthy to be compared with his friend.\"\"\"\n",
    "\n",
    "response = llm.chat(messages=[{\"role\": \"user\", \"content\": translation_template.format(text=translate_to_rus)}], sampling_params=sampling_params)\n",
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccc22dfe-5fb8-4d0c-8061-9035ab840822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_The model hallucinates a lot with this translation task._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aeaf2a7-4ccc-4ae7-9f80-4438ca832f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Coding Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "477c199b-b125-4b63-9e8d-73c48bd83244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_Code challenge from: https://edabit.com/challenge/ZdnwC3PsXPQTdTiKf_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba93e458-a61c-4680-8fe5-7460c5850c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coding_template = \"\"\"Write a code in Python to solve the following task:\n",
    "\n",
    "{task}\n",
    "\n",
    "Starter: \n",
    "\n",
    "{starter}\n",
    "\"\"\"\n",
    "\n",
    "coding_test = \"\"\"Create a Python function that takes two numbers and a mathematical operator + - / * and will perform a calculation with the given numbers. \"\"\"\n",
    "\n",
    "# examples = \"\"\"calculator(2, \"+\", 2) ➞ 4\n",
    "\n",
    "# calculator(2, \"*\", 2) ➞ 4\n",
    "\n",
    "# calculator(4, \"/\", 2) ➞ 2\"\"\"\n",
    "\n",
    "starter = \"\"\"def calculator(num1, operator, num2):\"\"\"\n",
    "\n",
    "\n",
    "response = llm.chat(messages=[{\"role\": \"user\", \"content\": coding_template.format(task=coding_test, starter=starter)}], sampling_params=sampling_params)\n",
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee1c4ea5-dcd0-49cf-971e-08b7fc37279c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "_Coding challenge from: https://edabit.com/challenge/3A3mHS5B3NNZddQL2_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e697fe-2c3b-4073-8088-04b969ce5e21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coding_template = \"\"\"Write a code in Python to solve the following task:\n",
    "\n",
    "{task}\n",
    "\n",
    "Starter:\n",
    "\n",
    "{starter}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "coding_test = \"\"\"Create a function:\n",
    "    \n",
    "to check if a candidate is qualified in an imaginary coding interview of an imaginary tech startup.\n",
    "\n",
    "The criteria for a candidate to be qualified in the coding interview is:\n",
    "The candidate should have complete all the questions.\n",
    "The maximum time given to complete the interview is 120 minutes.\n",
    "The maximum time given for very easy questions is 5 minutes each.\n",
    "The maximum time given for easy questions is 10 minutes each.\n",
    "The maximum time given for medium questions is 15 minutes each.\n",
    "The maximum time given for hard questions is 20 minutes each.\n",
    "If all the above conditions are satisfied, return \"qualified\", else return \"disqualified\".\n",
    "\n",
    "You will be given a list of time taken by a candidate to solve a particular question and the total time taken by the candidate to complete the interview.\n",
    "\n",
    "Given a list , in a true condition will always be in the format [very easy, very easy, easy, easy, medium, medium, hard, hard].\n",
    "\n",
    "The maximum time to complete the interview includes a buffer time of 20 minutes.\"\"\"\n",
    "\n",
    "starter = \"\"\"def interview(lst, tot):\"\"\"\n",
    "\n",
    "\n",
    "response = llm.chat(messages=[{\"role\": \"user\", \"content\": coding_template.format(task=coding_test, starter=starter)}], sampling_params=sampling_params)\n",
    "print(response[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddbc3157-73a9-48d6-bd8e-404b8f78b534",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The minimum cluster configuration needed to run the model is **g5.2xlarge[A10G]** - 32 GB memory, 1 GPU.\n",
    "\n",
    "Cost: 1.64 dbu/h.\n",
    "\n",
    "Latency of the model: 14s."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ministral_8B",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
