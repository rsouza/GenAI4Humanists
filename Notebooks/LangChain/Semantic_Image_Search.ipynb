{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdac04e7-ffd5-49c2-98d4-1be75fd5b3c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Semantic_Image_Search\n",
    "[source](https://github.com/emily-gibbs/articles/blob/main/image_semantic_search_with_vectors/code_walkthrough.ipynb)\n",
    "\n",
    "Have you ever taken forever trying to find a specific photo in a photo folder? Or tried to search an image repository for just the right image for a presentation and can't seem to find what you're looking for? It may be that the technology underlying your image search is based on outdated methods. \n",
    "\n",
    "The most straightforward and traditional way to perform an image search is with tagsâ€Š-â€Šeach image is assigned relevant tags, and when someone searches the tag those images are returned. However, there are several problems with this approach:\n",
    "\n",
    "Can't handle synonymsâ€Š-â€Šwhat if the tag is 'funny', but the user searches with 'silly'? It would be very hard to tag an image with ALL of the ways a user could phrase their search. \n",
    "No sense of degreeâ€Š-â€Šwith thousands of images, a user would likely prefer to see images ranked by how closely they match the query (e.g. from most silly to least silly)\n",
    "Time consumingâ€Š-â€ŠIt takes time and effort to make sure all images are correctly tagged and that relevant tags are assigned when new images are added. \n",
    "What a user really wants is to be able to search based upon meaning, not a finite set of words. This is where vectors embeddings come to the rescue! ğŸ¥³\n",
    "\n",
    "a vector embedding is a list of numbers that represents features of something. They represent the semantic meaning of unstructured data such as chunks of text, images, videos, etc. We can measure how similar two vectors are (are therefore how similar their source objects are) with the cosine similarity formula.\n",
    "\n",
    "What if we leveraged this idea for an image search? Rememberâ€Š-â€Šonce an object is embedded into the meaning space it doesn't matter what form it took before (text, image, audio, etc.). The only thing that matters is it's meaning. So if we create vectors for all of our images, then create a vector for our search text, we should be able to use cosine similarity to compare them and find what images best match our search!\n",
    "\n",
    "Sound kind of confusing? Let's walk through the code implementation step-by-step so we can see what a proof of concept of this would look like.\n",
    "\n",
    "First, we must ensure that the image embeddings and the text embeddings are in the same meaning space. This is important! Models that create vector embeddings from inputs each create their own unique meaning space. This is because the features of the vector are unique to the model (and the number of features may be different too!). We can't just embed an image with a random image model then embed our search text with a different random text model and compare the two to each other -even if they did have the same number of features, its like comparing apples to orangutans and you'll get back nonsense results!\n",
    "\n",
    "Fortunately there are models that have been trained on multiple input modalities and embed them into the same meaning space. The one we'll be using today is called [OpenCLIP](https://huggingface.co/docs/hub/en/open_clip), an open-source implementation of the CLIP model created by OpenAI. \n",
    "\n",
    "OpenCLIP actually has several model versions that you can load and use. We'll be using the \"ViT-g-14\" model for this tutorial, but I encourage you to explore the other models that are available. \n",
    "\n",
    "Let's start by installing some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8a34984-db08-4793-b312-ef8390a3990f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: pdf2image in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from pdf2image) (11.1.0)\n",
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: torch>=2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from open_clip_torch) (2.7.0)\n",
      "Collecting torchvision (from open_clip_torch)\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: regex in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from open_clip_torch) (2024.11.6)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tqdm in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from open_clip_torch) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from open_clip_torch) (0.32.2)\n",
      "Requirement already satisfied: safetensors in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from open_clip_torch) (0.5.3)\n",
      "Collecting timm>=1.0.17 (from open_clip_torch)\n",
      "  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: pyyaml in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from timm>=1.0.17->open_clip_torch) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torch>=2.0->open_clip_torch) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0->open_clip_torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
      "Requirement already satisfied: requests in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from huggingface-hub->open_clip_torch) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from huggingface-hub->open_clip_torch) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests->huggingface-hub->open_clip_torch) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from requests->huggingface-hub->open_clip_torch) (2025.4.26)\n",
      "Requirement already satisfied: numpy in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torchvision->open_clip_torch) (2.2.4)\n",
      "Collecting torch>=2.0 (from open_clip_torch)\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/renato/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages (from torchvision->open_clip_torch) (11.1.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.5.1.17->torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch>=2.0->open_clip_torch)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m  \u001b[33m0:07:33\u001b[0mm0:00:01\u001b[0m00:12\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m  \u001b[33m0:05:06\u001b[0mm0:00:01\u001b[0m00:08\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:44\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m  \u001b[33m0:05:57\u001b[0mm0:00:01\u001b[0m00:09\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:01:37\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m  \u001b[33m0:00:35\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:02:13\u001b[0mm0:00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:02:23\u001b[0mm0:00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:02:25\u001b[0mm0:00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m  \u001b[33m0:02:48\u001b[0mm0:00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:22\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:01:01\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:01:28\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, timm, open_clip_torch\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "\u001b[2K  Attempting uninstall: tritonâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/21\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: triton 3.3.0[0m \u001b[32m 0/21\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling triton-3.3.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/21\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.0â”\u001b[0m \u001b[32m 0/21\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/21\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77â”â”â”â”â”\u001b[0m \u001b[32m 1/21\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/21\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/21\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/21\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\u001b[0m \u001b[32m 3/21\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.6.85:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85â”â”\u001b[0m \u001b[32m 4/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2â”â”â”â”â”â”\u001b[0m \u001b[32m 4/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77â”\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77â”â”â”\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.11.1.6â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.11.1.6:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/21\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/21\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77m \u001b[32m 7/21\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/21\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77[0m \u001b[32m 7/21\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/21\u001b[0m [nvidia-cufile-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77â”â”â”\u001b[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77â”\u001b[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80â”\u001b[0m \u001b[32m 9/21\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/21\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1â”â”\u001b[0m \u001b[32m10/21\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/21\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/21\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/21\u001b[0m [ftfy]a-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2â”â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2â”â”â”â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12â•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4â”â”â”â”â”\u001b[0m \u001b[32m13/21\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu121mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/21\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17â”â”â”\u001b[0m \u001b[32m14/21\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/21\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17â”â”â”â”â”\u001b[0m \u001b[32m14/21\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15/21\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\u001b[0m \u001b[32m15/21\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15/21\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2â”â”\u001b[0m \u001b[32m15/21\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: torchâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.0\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/21\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.0:â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m17/21\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.090mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m17/21\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21/21\u001b[0m [open_clip_torch] [open_clip_torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-adapter 0.3.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.14.12 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 open_clip_torch-3.2.0 timm-1.0.24 torch-2.9.1 torchvision-0.24.1 triton-3.5.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -qU pip\n",
    "!pip install -qU openai\n",
    "!pip install -qU google-genai\n",
    "!pip install python-dotenv\n",
    "!pip install pdf2image\n",
    "!pip install -q langchain\n",
    "!pip install -q langchain-experimental\n",
    "!pip install -qU matplotlib\n",
    "\n",
    "!pip install open_clip_torch\n",
    "#dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63567bd4-0bfc-4274-a975-f03d1edf4835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "import requests\n",
    "import textwrap\n",
    "#from pdf2image import convert_from_path\n",
    "import PIL\n",
    "\n",
    "from IPython.display import Image, Audio, Markdown, Math\n",
    "\n",
    "import openai\n",
    "from google import genai\n",
    "\n",
    "load_dotenv(\"../../.env\", override=True)\n",
    "\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings # requires that open_clip_torch is installed\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08b65434-66e6-4320-bf31-aa0583c9ecda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Loading model using LangChain wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a6c54f-158a-4a54-8eaf-da955c131931",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f6496935484f6c85d014aaf18d13b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/5.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"ViT-g-14\"\n",
    "checkpoint = \"laion2b_s34b_b88k\"\n",
    "clip_embd = OpenCLIPEmbeddings(model_name=model_name, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc156dd-f79c-476e-96ca-1ccd3b2ac734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we need to create a vector embedding for all of the images that we want to search. I have a folder of ~40 bird images in a folder simply called \"Images\" that you can find at the Github repo for this project, or you can use your own set of images. Below is a function to create an embedding for each image in our folder and store them in a JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d59d8643-2fc1-47ea-b852-9903953a9417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding image ../../Data/RAG_images/OIP (1).jpg\n",
      "Embedding image ../../Data/RAG_images/owl-6884773_640.jpg\n",
      "Embedding image ../../Data/RAG_images/eagle-377202_640.jpg\n",
      "Embedding image ../../Data/RAG_images/OIP.jpg\n",
      "Embedding image ../../Data/RAG_images/Ramphastos_vitellinus_-Birds_of_Eden,_South_Africa-8a.jpg\n",
      "Embedding image ../../Data/RAG_images/gosling-7938445_640.jpg\n",
      "Embedding image ../../Data/RAG_images/peafowl-816981_640.jpg\n",
      "Embedding image ../../Data/RAG_images/tucan-743047_640.jpg\n",
      "Embedding image ../../Data/RAG_images/bird-7116272_640.jpg\n",
      "Embedding image ../../Data/RAG_images/chicken-3741129_640.jpg\n",
      "Embedding image ../../Data/RAG_images/bird-7917250_640.jpg\n",
      "Embedding image ../../Data/RAG_images/vulture-2441638_640.jpg\n",
      "Embedding image ../../Data/RAG_images/Ramphastos_vitellinus_-Matsue_Vogel_Park-8a-4c.jpg\n",
      "Embedding image ../../Data/RAG_images/1548d06a49fccb050deaf74b443a0a59.jpg\n",
      "Embedding image ../../Data/RAG_images/600px-Tucano-de-bico-preto_do_Parque_Nacional_da_AmazÃ´nia.jpg\n",
      "Embedding image ../../Data/RAG_images/hummingbird-1854225_640.jpg\n",
      "Embedding image ../../Data/RAG_images/peacock-8440548_640.jpg\n",
      "Embedding image ../../Data/RAG_images/african-gray-parrot-6604630_640.jpg\n",
      "Embedding image ../../Data/RAG_images/bird-8579496_640.jpg\n",
      "Embedding image ../../Data/RAG_images/bird-8200917_640.jpg\n",
      "Embedding image ../../Data/RAG_images/crazy_owl.jpg\n",
      "Embedding image ../../Data/RAG_images/9b676ca511484c774ade4a308d04a518.jpg\n",
      "Embedding image ../../Data/RAG_images/bird-8510323_640.jpg\n",
      "Embedding image ../../Data/RAG_images/R.png\n",
      "Embedding image ../../Data/RAG_images/white-cockatoo-7985434_640.jpg\n",
      "Embedding image ../../Data/RAG_images/bird-4728857_640.jpg\n",
      "Embedding image ../../Data/RAG_images/john+pow_-4.jpg\n",
      "Embedding image ../../Data/RAG_images/valk-4538878_640.jpg\n",
      "Embedding image ../../Data/RAG_images/R.jpg\n",
      "Embedding image ../../Data/RAG_images/great-egret-8902495_640.jpg\n",
      "Embedding image ../../Data/RAG_images/850526cb36a67e3548d023a6ac14d7ec.jpg\n",
      "Embedding image ../../Data/RAG_images/rag_dataset.json\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '../../Data/RAG_images/rag_dataset.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnidentifiedImageError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mimage_vectors.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     31\u001b[39m         json.dump(new_image_vectors, file, indent=\u001b[32m4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43membed_all_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../../Data/RAG_images/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(json.load(\u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mimage_vectors.json\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images embedded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36membed_all_images\u001b[39m\u001b[34m(images_dir)\u001b[39m\n\u001b[32m     23\u001b[39m         new_image_vectors[image_uri] = old_image_vectors[image_uri]\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     25\u001b[39m         \u001b[38;5;66;03m# Create the vector embedding for this image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         image_vector = \u001b[43mclip_embd\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_uri\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     27\u001b[39m         new_image_vectors[image_uri] = {\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m: image_vector}\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Write the dictionary to a JSON file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages/langchain_experimental/open_clip/open_clip.py:76\u001b[39m, in \u001b[36mOpenCLIPEmbeddings.embed_image\u001b[39m\u001b[34m(self, uris)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease install the PIL library: pip install pillow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Open images directly as PIL images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m pil_images = [\u001b[43m_PILImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m uri \u001b[38;5;129;01min\u001b[39;00m uris]\n\u001b[32m     78\u001b[39m image_features = []\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pil_image \u001b[38;5;129;01min\u001b[39;00m pil_images:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Preprocess the image for the model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repos/GenAI4Humanists/.venv/lib/python3.12/site-packages/PIL/Image.py:3532\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3530\u001b[39m     warnings.warn(message)\n\u001b[32m   3531\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[32m-> \u001b[39m\u001b[32m3532\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[31mUnidentifiedImageError\u001b[39m: cannot identify image file '../../Data/RAG_images/rag_dataset.json'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a JSON file with data in the format of\n",
    "{\n",
    "    image_uri: \n",
    "        'embedding': image_vector\n",
    "}\n",
    "\"\"\"\n",
    "def embed_all_images(images_dir: str):\n",
    "\n",
    "    # Check if we already have some image vectors made (if we do, don't want to remake them every time we add a new image)\n",
    "    old_image_vectors = {}\n",
    "    if os.path.exists('image_vectors.json'):\n",
    "        with open('image_vectors.json', 'r') as file:\n",
    "            old_image_vectors = json.load(file)\n",
    "\n",
    "    image_files = os.listdir(images_dir)\n",
    "    image_uris = [os.path.join(images_dir, image_file) for image_file in image_files]\n",
    "    new_image_vectors = {}\n",
    "    for image_uri in image_uris:\n",
    "        print(f\"Embedding image {image_uri}\")\n",
    "        if image_uri in old_image_vectors:\n",
    "            # Reuse the vector embedding created before\n",
    "            new_image_vectors[image_uri] = old_image_vectors[image_uri]\n",
    "        else:\n",
    "            # Create the vector embedding for this image\n",
    "            image_vector = clip_embd.embed_image([image_uri])[0]\n",
    "            new_image_vectors[image_uri] = {'embedding': image_vector}\n",
    "\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open('image_vectors.json', 'w') as file:\n",
    "        json.dump(new_image_vectors, file, indent=4)\n",
    "\n",
    "embed_all_images(images_dir = \"../../Data/RAG_images/\")\n",
    "print(f\"{len(json.load(open('image_vectors.json')))} images embedded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7f75a9-f4c8-440e-b89d-5540cf53f042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading the JSON file for use with the rest of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db58a522-71ba-4bb0-8a69-5d3fecc033ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the image vectors from the JSON file\n",
    "with open(file=\"./image_vectors.json\", mode='r') as file:\n",
    "    image_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684d7785-a291-48b5-b63f-3307d14b1582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we need a function that allows us to pass in a search text and get back the images that best fit that search. It must:\n",
    "\n",
    "+ Create the vector embedding for the search text\n",
    "+ Calculate the cosine similarity between that search text and all of the image vector embeddings\n",
    "+ Return the images that are most similar to that search vector\n",
    "\n",
    "\n",
    "Here's the code for that below. We're actually going to create the search vector outside of this function (we'll see why in just a bitâ€¦):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc57fb9-c88d-4dbe-8e69-10a076e0fa03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_top_search_results(\n",
    "    query_vector: list[float], image_data: dict[str, list[float]], num_results: int = 5\n",
    "):\n",
    "\n",
    "    # Calculate the cosine similarity between the query vector and all image vectors and add that to the image_info dict\n",
    "    for image_uri, data in image_data.items():\n",
    "        similarity = cosine_similarity(\n",
    "            np.array([query_vector]), np.array([data[\"embedding\"]])\n",
    "        )[0][0]\n",
    "        data[\"query_similarity\"] = similarity\n",
    "\n",
    "    # Sort the image_info dict by the similarity value and return the top num_results\n",
    "    top_results = dict(\n",
    "        sorted(\n",
    "            image_data.items(),\n",
    "            key=lambda item: item[1][\"query_similarity\"],\n",
    "            reverse=True,\n",
    "        )[:num_results]\n",
    "    )\n",
    "    \n",
    "    # Display the images with their scores in a grid with 3 columns\n",
    "    # Calculate number of rows and columns needed\n",
    "    num_cols = 3\n",
    "    num_rows = (num_results + num_cols - 1) // num_cols  # Ceiling division\n",
    "\n",
    "    # Create subplot grid\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "    axs = axs.ravel()  # Flatten the 2D array of axes to make indexing easier\n",
    "\n",
    "    # Display images\n",
    "    for i, (image_uri, data) in enumerate(top_results.items()):\n",
    "        axs[i].imshow(PIL.Image.open(image_uri))\n",
    "        axs[i].set_title(f\"Score: {data['query_similarity']:.2f}\")\n",
    "        axs[i].axis(\"off\")\n",
    "\n",
    "    # Hide any empty subplots\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c7d5e7c-0b0c-4312-abce-07cdfe73a110",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's test this out by asking for the top 3 images that match the search for a 'funny bird':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "987d58a1-78d6-42ed-a6b8-53e4da9789c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_text = \"funny bird\"\n",
    "query_vector = clip_embd.embed_documents([search_text])[0]\n",
    "display_top_search_results(query_vector, image_data, num_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc0a8ba8-2b88-4b85-b49c-7ede6ac1541f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Those look pretty funny to me! Now let's see if it can handle synonyms by searching instead for 'silly bird':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f190b862-4485-4d70-8dff-266d4dbf562b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_text = \"silly bird\"\n",
    "query_vector = clip_embd.embed_documents([search_text])[0]\n",
    "display_top_search_results(query_vector, image_data, num_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5728fb21-acb0-4e74-9fc9-227f985a6a6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Perfect! Now let's try something much more abstract that would likely never end up in an image tagâ€Š-â€Š'bad hair day':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c3f375-068f-455a-86c4-0d06b81d3ed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_text = \"bad hair day\"\n",
    "query_vector = clip_embd.embed_documents([search_text])[0]\n",
    "display_top_search_results(query_vector, image_data, num_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "469a9c00-3766-49a8-bd07-ae8f8c845053",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Our search can even handle this more abstract search pretty well!\n",
    "\n",
    "#### Reverse Image Search\n",
    "This setup is actually more flexible than you might think. Rememberâ€Š-â€Šas long as we have a search vector in the same meaning space, it doesn't really matter what that vector was made from. It could be made from audio, text, or another imageâ€Š-â€Ša vector is a vector! \n",
    "\n",
    "Imagine you already have an image, and you want to find images that are similar (perhaps you've taken a picture of a bird and want to look up what species it is). We can do that, and we don't even have to change our function! Here's the image we're going to use for our search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04c4fdfc-3d8d-410e-8104-4821ac0838fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_image(image_uri):\n",
    "    image = PIL.Image.open(image_uri)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "display_image(\"../../Data/Images/toucan-4185361_640.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8ecd2d-46b5-4a5b-bbb2-28489d4a73bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To search for similar images we just create a search vector from this image instead of from a search text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81c2263-1ba6-4259-b744-9873e96e3106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_image = \"../../Data/Images/toucan-4185361_640.jpg\"\n",
    "query_vector = clip_embd.embed_image([search_image])[0]\n",
    "display_top_search_results(query_vector, image_data, num_results=3)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Semantic_Image_Search",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
