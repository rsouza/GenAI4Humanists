{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Claude Introduction\n",
    "\n",
    "This notebook provides an introduction to using Anthropic Claude models through the Anthropic API.\n",
    "\n",
    "## Prerequisites\n",
    "- An Anthropic account\n",
    "- API key from Anthropic Console (https://console.anthropic.com/)\n",
    "- ANTHROPIC_API_KEY environment variable set\n",
    "\n",
    "## Available Models\n",
    "- Claude 3.7 Sonnet (default)\n",
    "- Claude 3.5 Sonnet\n",
    "- Claude 3 Opus\n",
    "- Claude 3 Haiku\n",
    "\n",
    "More info: https://docs.anthropic.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pip\n",
    "!pip install -qU anthropic\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "\n",
    "load_dotenv(\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Instantiating a connection to the API\n",
    "\n",
    "Note: [Official documentation](https://docs.anthropic.com/en/docs/api-clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "client = anthropic.Anthropic(api_key=anthropic_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Using Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-sonnet-4-20250514\"\n",
    "\n",
    "prompt = \"\"\"What is the size of Earth?\"\"\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Using System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-sonnet-4-20250514\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1024,\n",
    "    system=\"You are a Physics teacher. Explain concepts as if the user were 10 years old.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain why the sky is blue\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-sonnet-4-20250514\"\n",
    "\n",
    "prompt = \"\"\"Write a short poem about artificial intelligence and its impact on humanity.\"\"\"\n",
    "\n",
    "stream = client.messages.stream(\n",
    "    model=model,\n",
    "    max_tokens=500,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.type == \"content_block_delta\":\n",
    "        print(chunk.delta.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Conversation with History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-sonnet-4-20250514\"\n",
    "\n",
    "# First message\n",
    "message1 = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am a student learning about history.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(\"Assistant:\", message1.content[0].text)\n",
    "\n",
    "# Second message with context\n",
    "message2 = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am a student learning about history.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message1.content[0].text\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was the most important event in the 20th century?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nAssistant:\", message2.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"claude-sonnet-4-20250514\", temperature=0.5, system=None):\n",
    "    \"\"\"Helper function to interact with Claude models.\"\"\"\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=2048,\n",
    "        temperature=temperature,\n",
    "        system=system,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - Example Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Summarization\n",
    "text = \"\"\"The University of Vienna (German: Universitat Wien) is a public research university located in Vienna, Austria. \n",
    "It was founded in 1365 and is the oldest university in the German-speaking world and the third oldest in \n",
    "Central Europe after the Charles University in Prague and the Jagiellonian University in Krakow. \n",
    "With about 85,000 students and over 10,000 employees, it is the largest university in Austria \n",
    "and the German-speaking world, and one of the largest in Europe.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Summarize the text delimited by triple backticks into a single sentence with maximum 15 words.\n",
    "```{text}```\"\"\"\n",
    "\n",
    "response = get_completion(prompt, temperature=0.3)\n",
    "print(\"Summary:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "text = \"\"\"The new AI technology has revolutionized how we interact with computers. \n",
    "While it offers incredible opportunities, it also raises important ethical questions \n",
    "about privacy, bias, and the future of work.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Analyze the sentiment of the following text. Is it positive, negative, or neutral?\n",
    "Text: {text}\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Generation\n",
    "prompt = \"\"\"Write a Python function that calculates the factorial of a number.\"\"\"\n",
    "\n",
    "response = get_completion(prompt, temperature=0.3)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "text = \"\"\"Generative AI is transforming the way we interact with technology.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the following English text to German, French, and Spanish:\n",
    "```{text}```\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 - Using Claude with Tools (Extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude can use tools - example with simple calculation\n",
    "prompt = \"\"\"What is 123 * 456? Calculate it step by step.\"\"\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"A simple calculator for mathematical operations\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The mathematical expression to evaluate\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 - Claude 3.5 Haiku (Fast and Affordable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haiku is faster and cheaper - great for simple tasks\n",
    "prompt = \"\"\"List 5 key benefits of using Large Language Models in education.\"\"\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=512,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Anthropic Documentation](https://docs.anthropic.com/)\n",
    "- [Claude API Reference](https://docs.anthropic.com/en/docs/api-clients)\n",
    "- [Anthropic Python SDK](https://github.com/anthropics/anthropic-sdk-python)\n",
    "- [Model Versions](https://docs.anthropic.com/en/docs/about-claude/models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}