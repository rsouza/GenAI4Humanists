{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Gemini Introduction\n",
    "\n",
    "This notebook provides an introduction to using Google Gemini models through the Google Generative AI API.\n",
    "\n",
    "## Prerequisites\n",
    "- A Google Cloud account with Gemini API access\n",
    "- API key from Google AI Studio (https://aistudio.google.com/app/apikey)\n",
    "- GEMINI_API_KEY environment variable set\n",
    "\n",
    "## Available Models\n",
    "- Gemini 2.0 Flash\n",
    "- Gemini 2.0 Flash-Lite\n",
    "- Gemini 1.5 Pro\n",
    "- Gemini 1.5 Flash\n",
    "\n",
    "More info: https://ai.google.dev/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pip\n",
    "!pip install -qU google-genai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to use\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "load_dotenv(\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Instantiating a connection to the API\n",
    "\n",
    "Note: This is not the only way to configure the API. [Official documentation](https://google.github.io/python-genai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "client = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Using a Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "",
    "prompt = \"\"\"What is the size of Earth?\"\"\"",
    "",
    "response = client.models.generate_content(",
    "    model=MODEL,",
    "    contents=prompt,",
    ")",
    "",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Chat with System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types",
    "",
    "",
    "prompt = \"\"\"Explain me why the sky is blue\"\"\"",
    "",
    "response = client.models.generate_content(",
    "    model=MODEL,",
    "    contents=prompt,",
    "    config=types.GenerateContentConfig(",
    "        system_instruction=\"You are a Physics teacher. Explain as if I were 10 years old.\",",
    "        temperature=0.5,",
    "        max_output_tokens=800,",
    "    ),",
    ")",
    "",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Using Chat with History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types",
    "",
    "",
    "chat = client.chats.create(",
    "    model=MODEL,",
    "    history=[",
    "        types.Content(",
    "            role=\"user\",",
    "            parts=[types.Part(text=\"I am a student learning about physics.\")],",
    "        ),",
    "        types.Content(",
    "            role=\"model\",",
    "            parts=[types.Part(text=\"Great! I'll explain concepts in a simple way. What would you like to learn about?\")],",
    "        ),",
    "    ],",
    ")",
    "",
    "response = chat.send_message(\"Why is the sky blue?\")",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chat history:\")",
    "for message in chat.history:",
    "    print(f\"{message.role}: {message.parts[0].text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gemini-2.0-flash\", temperature=0.5, system_instruction=None):",
    "    \"\"\"Helper function to interact with Gemini models.\"\"\"",
    "    config = types.GenerateContentConfig(",
    "        temperature=temperature,",
    "    )",
    "    ",
    "    if system_instruction:",
    "        config.system_instruction = system_instruction",
    "    ",
    "    response = client.models.generate_content(",
    "        model=MODEL,",
    "        contents=prompt,",
    "        config=config,",
    "    )",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Example Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Summarization",
    "text = \"\"\"",
    "The University of Vienna (German: Universitat Wien) is a public research university located in Vienna, Austria. ",
    "It was founded in 1365 and is the oldest university in the German-speaking world and the third oldest in ",
    "Central Europe after the Charles University in Prague and the Jagiellonian University in Krakow. ",
    "With about 85,000 students and over 10,000 employees, it is the largest university in Austria ",
    "and the German-speaking world, and one of the largest in Europe.",
    "\"\"\"",
    "",
    "prompt = f\"\"\"",
    "Summarize the text delimited by triple backticks into a single sentence with maximum 15 words.",
    "```{text}```",
    "\"\"\"",
    "",
    "response = get_completion(prompt, temperature=0.3)",
    "print(\"Summary:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis",
    "text = \"\"\"",
    "The new AI technology has revolutionized how we interact with computers. ",
    "While it offers incredible opportunities, it also raises important ethical questions ",
    "about privacy, bias, and the future of work.",
    "\"\"\"",
    "",
    "prompt = f\"\"\"",
    "Analyze the sentiment of the following text. Is it positive, negative, or neutral?",
    "Text: {text}",
    "\"\"\"",
    "",
    "response = get_completion(prompt)",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation",
    "text = \"\"\"",
    "Generative AI is transforming the way we interact with technology.",
    "\"\"\"",
    "",
    "prompt = f\"\"\"",
    "Translate the following English text to German, French, and Spanish:",
    "```{text}```",
    "\"\"\"",
    "",
    "response = get_completion(prompt)",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Multimodal Input (Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types",
    "",
    "# Upload an image",
    "image_path = \"../../Data/imgs/handwritten.jpg\"",
    "",
    "my_file = client.files.upload(file=image_path)",
    "",
    "prompt = \"\"\"",
    "Describe what you see in this image.",
    "\"\"\"",
    "",
    "response = client.models.generate_content(",
    "    model=\"gemini-2.0-flash\",",
    "    contents=[my_file, prompt],",
    ")",
    "",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"",
    "Write a short story about a curious student discovering artificial intelligence for the first time.",
    "\"\"\"",
    "",
    "response = client.models.generate_content(",
    "    model=\"gemini-2.0-flash\",",
    "    contents=prompt,",
    "    config=types.GenerateContentConfig(",
    "        temperature=0.7,",
    "        max_output_tokens=500,",
    "    ),",
    ")",
    "",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Google AI for Developers](https://ai.google.dev/)\n",
    "- [Gemini API Documentation](https://ai.google.dev/docs)\n",
    "- [Google GenAI Python Library](https://google.github.io/python-genai/)\n",
    "- [Model Reference](https://ai.google.dev/docs/model_reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}